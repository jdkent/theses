% cSpell:disable
% you should only have one "documentclass" line.  the following lines
% are samples that give various options.  the nofrontmatter option is
% nice because it suppresses the title and signature pages when you want
% to focus only on the main body of the thesis
%
% Friday April 10 2010 Ray Hylock <ray-hylock@uiowa.edu>
% documentclass options:
%   abstractpage            if you want to add an internal abstract (optional)
%   ackpage                 if you would like to add an acknowledgements page (optional)
%   algorithms              if you want a list of algorithms (optional)
%   appendix                if you have an appendix (optional)
%   copyrightpage           if you wish to copyright your thesis (optional)
%   dedicationpage          if you wish to make a dedication (optional)
%   epigraphpage            if you would like to add an epigraph to the beginning of your thesis (optional)
%   examples                if you want a list of examples (this uses the ntheorem package)
%   exampleslemmas          if you want a combined list of examples and lemmas (this uses the ntheorem package) (optional)
%   examplestheorems        if you want a combined list of examples and theorems (this uses the ntheorem package) (optional)
%   exampleslemmastheorems  if you want a combined list of examples, lemmas, and theorems (this uses the ntheorem package) (optional)
%   figures                 if you have any figures (this is required if you have even one figure)
%   lemmas                  if you want a list of lemmas (this uses the ntheorem package) (optional)
%   lemmastheorems          if you want a combined list of lemmas and theorems (this uses the ntheorem package) (optional)
%   nofrontmatter           suppresses the title and signiture pages for working on the body
%   tables                  if you have any tables (this is required if you have even one table)
%   theorems                if you want a list of theorems (this uses the ntheorem package) (optional)
%   phd                     if phd student; this will add the doctoral abstract (mandatory for PhD and DMA thesis candidates only)
%

% full options
%\documentclass[phd,abstractpage,copyrightpage,dedicationpage,epigraphpage,ackpage,figures,tables,lemmas,appendix]{uithesis}

% common options
%\documentclass[phd,dedicationpage,ackpage,figures,tables,appendix]{uithesis}

% example
\documentclass[phd,figures,tables,ackpage,abstractpage,publicabstractpage]{uithesis}

%=============================================================================
% User packages
%=============================================================================
\usepackage{bookmark}	% [recommended] for PDF bookmark generation
\usepackage{blindtext} 	% example text generation
\usepackage[ruled,chapter]{algorithm}  % display algorithms
\usepackage[super,comma,sort,numbers]{natbib}
\usepackage{amssymb}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% to place figures/subfigures
\usepackage{graphicx}
\usepackage{subfig}
% path to figures
\graphicspath{{notebooks/}{img/}{img/Aim1/}{img/Aim2/}{img/Aim3/}{img/CurrentStudy/}{img/GeneralDiscussion/}{img/GeneralMethods/}{img/Introduction/}{./betaSeriesSimulations/outputs/}{./BetaSeriesRealDataAnalysis/nibsAnalysis/outputs/}{./BetaSeriesRealDataAnalysis/firstLevelAnalysis/outputs/}{./BetaSeriesRealDataAnalysis/introductionFigures/outputs/}{./BetaSeriesRealDataAnalysis/PPITest/outputs/}}
\usepackage{forloop} % for loops display images
\usepackage{hyperref} % to insert hyperlinks
\usepackage{textcomp} % to write degree symbols
\usepackage{float} % image placement
% for smaller captions
\usepackage[labelfont=bf]{caption}
\captionsetup{font=footnotesize}
% for including csvs
\usepackage{csvsimple}
\usepackage{array}
% multiline equations
\usepackage{mathtools}
% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% https://tex.stackexchange.com/questions/370278/is-there-any-reason-to-use-inputenc
\usepackage[utf8]{inputenc} % for non-ascii characters
\newcommand{\comment}[1]{}
%=============================================================================
% prelude
%=============================================================================

\title{Statistical Comparison of Methods Measuring Context Dependent Functional Connectivity}
\author{James Kent}
\dept{Neuroscience}

% multipleSupervisors=true for two advisors
\setboolean{multipleSupervisors}{false}
\advisor{Assistant Professor Dr. Michelle Voss}
% for multiple advisors; change <value> to line up the names
%\setboolean{multipleSupervisors}{true}
%\advisor{Advisor 1\\\hspace{<value>mm}Advisor 2...}
%
% edit the names below to have your committee members names appear
% on the signature page.  memberOne should be your advisor.
%
\memberOne{Michelle Voss}
\memberTwo{Eliot Hazeltine}
\memberThree{Vincent Magnotta}
\memberFour{Jatin Vaidya}
\memberFive{Jan Wessel}
\submitdate{July 2020}
\copyrightyear{2020}

\Abstract{
As the field of cognitive neuroscience generates methods to answer
questions about brain configuration during tasks, those methods
need to be held to the fire to ensure they measure what they advertise
and to help researchers
understand under what circumstances the methods are appropriate to use.
Without solid testing and validation of methods, the field could be
led astray towards detrimental theories of brain function.
I battle-tested several methods that measure \textit{context-dependent
functional connectivity} between brain areas.
The methods were Beta Series Correlations (BSC) and Psychophysiological
Interaction (PPI) analysis.
In Aim 1 I compared two BSC variants---Least Squares All (LSA) and
Least Squares Separate (LSS)---
using both simulated and real data to ascertain which variant
has more power to detect a change in context-dependent functional
connectivity.
While the simulations concluded LSS was the more powerful method,
the real data painted a more nuanced picture.
LSS appeared to have a disadvantage relative to LSA when 
the experimental contexts are interleaved with each other
(as opposed to contexts being in separate blocks).
LSS did not identify more false positives than expected when
isolating brain areas highly involved in a task, whereas LSA
did have a larger number of false positives than expected.
I was also able to identify the optimal circumstances to use
the BSC variants by simulating a variety of experimental designs.
The simulations suggested at least 30 events per condition
(with 45 being optimal),
with each event being separated by an average of 6 seconds.
In Aim 2, I compared BSC variants with a more established method named
"Psychophysiological Interaction" (PPI) analysis to identify
whether the BSC variants are more powerful than PPI analyses.
PPI analysis was more powerful in the task I investigated.
Additionally, the estimates from LSS are more correlated with
PPI analysis than LSA, suggesting LSS and PPI analysis are
more similar to each other.
Overall, I found both BSC and PPI can likely detect differences
in context-dependent functional connectivity and can be used
with confidence when the experimental design meets recommendations.
}

\publicAbstract{
We want to understand how the brain is organized,
but we do not know how well we can trust the methods
that help us answer that question.
If we do not ensure our methods are accurate, we
could lead researchers astray towards ideas about
brain organization that are not useful.
In this thesis, I create simplistic
conditions where I know the truth
to evaluate several methods that can measure
how the brain is organized.
I found under certain situations we can trust these
methods which can help researchers
move towards useful theories of how the brain is organized.
}
%\dedication{Dedication here (optional)}

%\epigraph{Epigraph here (optional)}

%\acknowledgements{Acknowledgements here (optional)}

\begin{document}

\frontmatter
% cSpell:enable
%=============================================================================
\chapter{Introduction}
%=============================================================================

At the heart of any cognitive neuroscientist is the desire to relate the physical
processes of the brain to cognition.
Cognitive neuroscientists couple clever experimental manipulations
of how we are thinking or feeling with a measure of brain function
(such as functional Magnetic Resonance Imaging (fMRI)) to provide a nuanced
analysis of how the brain enables cognition and behavior.
fMRI analysis typically identifies brain areas that are more
active than other brain areas between two (or more) conditions in a task.
A complementary and equally important analysis evaluates how brain areas
are working together during a condition.
The communication between brain areas during a condition is known as
\textit{context-dependent functional connectivity}.
While several methods to detect context-dependent functional connectivity
were developed around the turn of the century, they have primarily
been used for directed hypotheses within a small number of brain areas, or
exploratory analyses observing how one brain area changes its relationship
with the rest of the brain.
However, these methods have not been extensively used to investigate large numbers of defined
brain areas which is the bedrock of analyzing brain networks.
To fill this gap, \textbf{I compared three methods that measure context-dependent functional connectivity
and provide recommendations on which method to use.}

To illustrate the difference between the typical fMRI analysis and context-dependent
functional connectivity, imagine a task where participants are reading words
or nonwords.
If we compare word reading to nonword reading as we would in a typical
fMRI analysis, we could be isolating the cognitive process of lexical processing,
since the presentation of alphabetic characters
remains constant in both conditions.
Ideally the only difference between the two conditions is the cognitive process
of interest such that when they are subtracted the active brain areas are
the areas involved in the cognitive process, such as lexical processing.
Isolating the cognitive process of interest through subtraction of two conditions
is known as "cognitive subtraction"~\cite{Sartori2000,Friston1996b}.
Even with careful design multiple cognitive processes may be
different between conditions or the cognitive process may represent multiple
neural processes.
For example, lexical processing could involve word retrieval and priming motor functions
to speak (if nonwords are not pronounceable), or word retrieval could be implemented
using several neural systems, or the nonword condition could make participants focus more
on the individual characters than the whole word resulting in another difference between conditions.
Thus a typical fMRI analysis could identify all active brain areas,
but it is impossible to tell whether all active brain areas
are working together to complete the hypothesized cognitive function
(e.g., lexical processing) or if smaller networks of brain areas
are working together to complete separate functions (e.g., word retrieval and
motor function preparation).
As a solution to imperfect cognitive subtractions, fMRI research has
developed methods to measure context-dependent functional connectivity.
Although many brain areas may be active from a cognitive subtraction,
smaller groups of brain areas may form a network to complete a specific
cognitive function included from the subtraction, giving additional
insight between cognition and brain function, such as a network for word retrieval and
a network for motor preparation.

The core of these methods depends on the peculiarities of fMRI, which deserves some exposition.
The advent of fMRI presented an amazing opportunity
to pursue the brain/cognition relationship~\cite{ogawa1990,Ogawa1992}.
Ogawa et al. observed the ratio of oxygenated blood to the de-oxygenated blood changed the transverse
relaxation time ($T_2$) of the MRI signal~\cite{ogawa1990}.
The change in MR signal due to the ratio of oxygenated to de-oxygenated blood was named the
Blood Oxygen Level-Dependent (BOLD) contrast. 
Moreover, Ogawa et al. observed the BOLD contrast in
response to external stimuli with regional specificity, laying the path for fMRI as a non-invasive tool
to indirectly observe activity in the brain~\cite{Ogawa1992}.
Later, experiments with concurrent electrophysiological and BOLD measurements showed that 
the BOLD contrast is more correlated to the inputs of
neuronal populations and local processing within those areas (as opposed to large bursts of activity
associated with spiking activity in populations of neurons)~\cite{Logothetis2001}.
This neurovascular coupling is staggered in time, where the neural activity occurs
first, then the BOLD contrast is observed 2-3 seconds later
and peaks around 6 seconds after the neuronal population activity.
Unfortunately, changes in overall blood flow, housekeeping functions of neurons and glial cells,
venous drainage, head movement, respiration, cardiac rhythms, and other factors unrelated
to neural activity also influence the BOLD contrast~\cite{Attwell2002,Kim2012,Liu2016}.
Thus it is important to keep in mind that any endeavor using fMRI is attempting to measure
a signal in a sea of potential noise sources.

Despite the limitations of the BOLD contrast, the demonstrable neurovascular 
connection provided the backdrop for exploring how different
cognitive tasks affect brain activation patterns and how the brain acts as a
network.
These investigations were largely completed separately, where activation patterns
were discovered through engagement during a task, whereas network analyses
occurred while the participant was not engaged in any external task.
The network analyses of participant brain function during no explicit task
(also known as resting state) is supported by the observation of synchronous fMRI activity
across spatially distributed brain areas at low frequencies forming networks while
participants are not engaged in any explicit task~\cite{Greicius2003,Raichle2009}.
Instead of observing brain networks while there is no explicit task or observing
whether a particular area is strongly active, observing context-dependent functional
connectivity deepens our understanding of how our brain operates during different contexts.
Whether it's writing an email, playing a card game, talking with colleagues; we are
often engaged in different contexts throughout the day in which our brain has to process
and share information between areas quickly and efficiently, and we cannot
measure this sharing of information by solely looking at which brain areas are active.
Nor can we fully understand how brain areas communicate during a task when observing a
participant at rest.
It is the context-dependent functional connectivity between brain areas observed during a task
that gives us the specific insight of which brain areas communicate during a task~\cite{Friston1997}.
Thus, investigating context-dependent functional connectivity grants a deeper understanding
of how we operate in daily life.

\section{Event/Block/Mixed Designs}

Writing emails and playing card games are not the typical experiments performed with fMRI.
Experimental paradigms fall under three main categories: subtractive, parametric, and factorial~\cite{Friston1994}.
Subtractive experiments allow for "cognitive subtraction" as previously mentioned,
parametric experiments vary the condition continuously, like the length of the word being read, and finally
factorial experiments take the interaction of separate conditions~\cite{Friston1994}.
The focus of this thesis will be on subtractive experiments to emphasize differences
in context-dependent functional connectivity, such as the word versus nonword lexical processing example.
With the type of experiment in place, there is still the choice of how often and
what order we would like to place the word/nonword stimuli.
Again, there are three main choices for experimental designs:
event-related, block, or mixed~\cite{Friston1995b,Buckner1996,Petersen2012} (Figure~\ref{fig:example_designs}).
\begin{figure}[H]
  \centering
  \subfloat[][]{\includegraphics[width=0.31\linewidth]{event_design} 
  \label{fig:event_design}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.202\linewidth]{block_design} 
  \label{fig:block_design}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.37\linewidth]{mixed_design} 
  \label{fig:mixed_design}}
  \caption[Example experimental designs]{
    Example experimental designs for event-related~\ref{fig:event_design},
    block~\ref{fig:block_design},
    and mixed block/event-related designs~\ref{fig:mixed_design}.
    The green contrast represents the expected amount of activation, and the darker
    colors represent decreases in the expected amount of activation.
    The above designs have been convolved with a model of the BOLD
    response, highlighting the block design's consistent activity,
    and the event-related/mixed design's variability.
  }
  \label{fig:example_designs}
\end{figure}
Event-related designs are when the word and nonword conditions are interleaved with each other (Figure~\ref{fig:event_design}).
During one event the participant may read a word, but the next event several seconds later may be
a nonword.
Event-related designs are well suited to define the shape of the BOLD response to a stimulus (slow event-related),
and when the experimental paradigm requires rapid intermixing of conditions
(fast event-related) where events are separated by less than 8 seconds on average.
For example, if the researcher
was interested in measuring the brain's response towards unexpectedness of seeing a nonword
in a predominantly word sequence, they would use a fast event-related design.
Thus the presentation of the unexpected nonword creates a temporary context where a network of brain areas relating
to salience may be activated.
Less contrived examples come from many tasks that measure cognitive control (defined vacuously
as a process is not automatic) such as the: Stroop task~\cite{Stroop1935},
Flanker task~\cite{Eriksen1974a}, Stop-signal task~\cite{Logan1982},
Simon task~\cite{Simon1963}, and others.
Block designs show all events belonging to one condition (e.g., word) together in a sequence,
then after allowing the BOLD contrast to return to baseline, showing all events belonging
to another condition (e.g., nonword) together in a sequence~\ref{fig:block_design}.
Block designs are well suited to detect differences between conditions, as long as the cognitive process of interest
does not depend on the intermixing of the conditions~\cite{Friston1999}.
The mixed design combines both the event-related and block design approaches, where certain blocks
could only contain one condition, but
other blocks may contain both conditions interleaved with each other (Figure~\ref{fig:mixed_design}).
Mixed designs can be used to test more complex hypotheses concerning transient changes in brain function
relative to sustained changes in brain function.
A primary difference between typical block designs and mixed designs is the jittering of onset times.
In block designs, the inter event interval (IEI) is consistent and often short, whereas
in a mixed block, the IEI is jittered such that it could be 1 second or 10 seconds within the same block.
The primary data-set leveraged in this thesis was mixed event/block design, so I was
able to make contrasts within blocks and between blocks.

\section{Context-Dependent Functional Connectivity}

Context-dependent functional connectivity refers to the 
statistical dependency between two or more brain areas during a specific context
(i.e., reading a book, identifying tools, tapping your finger, etc.)~\cite{Friston1997}.
However, I have not mentioned the exact methods that can measure context-dependent functional connectivity.
There are (at least) four classes of methods that measure context-dependent functional connectivity:
sliding windows~\cite{Shine2015}, residual correlations~\cite{Cole2014a},
Psycho-Physiological Interaction (PPI)
analysis~\cite{Friston1997}, and Beta Series Correlations (BSC)~\cite{Rissman2004}.
Of these classes of methods, only BSC and PPI analysis can purportedly measure the differences
between interleaved contexts (e.g., event-related designs).
Sliding window and residual correlation approaches can only detect contexts that are
temporally separable and not interleaved with each other as with block designs.
A large swath of existing cognitive neuroscience literature relies on interleaved
contexts so the focus of this work will pertain to classes of methods
that can in theory detect differences in event-related designs (BSC and PPI).

\section{Network Analysis}

I have used the phrase brain networks several times, but I have avoided an explicit definition.
In this thesis, brain networks refer to a collection spatially distributed brain areas
that are strongly communicating with each other, as measured by either a
statistical or physical dependency between
brain areas like a Pearson's correlation or a white matter tract~\cite{Uddin2019}.
A predominant way to describe large scale brain networks is through network science~\cite{Rubinov2010}.
The network perspective partitions the brain into anatomically/functionally relevant areas (named nodes)
that are connected via a physical or statistical dependency (named edges).
fMRI enables the study of the entire brain simultaneously with regional specificity (creating nodes),
and measures the BOLD contrast over time which can be compared between nodes by a Pearson's correlation (creating edges).
This Pearson's correlation gives us the notion of \textit{functional connectivity} between brain areas,
which implies two brain areas process information at similar time intervals, but does not imply
the directionality or how many mediating brain areas exist between the two brain areas.
From our understanding of the BOLD contrast, we can measure which brain areas
typically receive inputs and/or locally process information within a similar time frame.
Instead of comparing the overall activation of brain areas separately, the network perspective
gives a more mechanistic description of which brain areas are either directly/indirectly
communicating during task performance.

For example, Seeley et al. (2007) were able to dissociate two brain networks that are typically
co-activated during tasks: Salience and Executive Networks~\cite{Seeley2007}.
Traditional task analysis showed these two networks are often both activated
during tasks, but were undifferentiable.
Observing functional connectivity during rest dissociated the Salience and Executive networks,
and their relationship to different cognitive functions was determined by correlating
participant behavioral performance with the strength of functional connectivity in the network.
Specifically, Seeley, et al. (2007) found the Salience network correlated with pre-scan anxiety
ratings and the Executive network correlated with the trail making test (a measure of executive
performance).
Dissociating these networks allowed researchers to ascribe more specific cognitive functions
to each network which would not be possible if one were to only observe activation of brain areas.
A limitation to Seeley et al. (2007) is that the networks were separated in resting state data,
the separation of the networks would be even more convincing if shown during task performance
with context-dependent functional connectivity as implemented by the methods I am
investigating.

Regardless, the ability to draw dissociations between networks of regions that are all active
during a task provides a more mechanistic description of how the brain accomplishes a task
through correlating the networks with specific behavioral outcomes.
This more mechanistic perspective furthers insights in cognitive neuroscience by identifying
which brain regions are working together versus working independently while engaging
in several cognitive processes of interest and potentially relate networks to more specific
cognitive processes.

\section{Methodological Rigor}

While it is exciting to understand brain organization during tasks,
the excitement has outpaced the investigations of the methods to understand brain organization.
Understanding and comparing the methods we use is critical to move the field of
human neuroscience forward.
There are innumerable choices in every step of the analysis process in
fMRI within and between software packages~\cite{Bowring2019,Carp2012}.
Even the choice of operating system can have a non-trivial impact on
analysis outcomes~\cite{Glatard2015}.
Analysis variability is not only theoretically concerning; it impacts
results when researchers attempt to answer the same experimental questions.
An enormous study by Botvinik-Nezer et al. (2020) asked 70 independent research teams
to answer 9 scientific hypotheses when given the same data-set~\cite{Botvinik-Nezer2020}.
They found the consistency of results across teams were halfway between
being completely consistent and completely random.
While not necessarily reaching the level of crisis,
analytical variability is cause for serious consideration.
Methods that purportedly measure the same underlying biological process
should be held to the fire to evaluate whether they are as similar
as they imply.
In this thesis, I perform the necessary method comparisons
to test how similar BSC and PPI methods are and provide a foundation
for future studies to know how much confidence they should
place in each method or if their results may be idiosyncratic
because of the method they chose.

\section{General Linear Models}

To understand BSC and PPI analyses, a gentle introduction to the
General Linear Model (GLM) is required.
GLMs are an extension of the more familiar linear regression.
The main goal of both linear regression and GLMs is to take
a series of observations ($X$) and scale the observations by
multiplying them by a scalar ($\beta$) that makes the observations
look like the outcome data ($Y$).
Through scaling $X$ by the scalar $\beta$,
$\beta$ represents the strength of the relationship
between $X$ and $Y$.
In traditional task analysis, one $\beta$ is assigned per condition
to indicate the strength of the relationship between event occurrences
($X$) and the observed BOLD signal ($Y$). 
Since it is often impossible for the observations to look exactly like
the outcome data, there is some error $\epsilon$.
The general form of the equation is shown in Equation~\ref{eq:glm}.
\begin{equation}
  Y = \beta X + \epsilon
  \label{eq:glm}
\end{equation}
A difficulty in GLMs (and linear regression) is when separate observations are very similar to one another.
In fMRI, observations are very similar to each other when they occur close in time.
Using the example word versus nonword experiment, if a word ($X_{word}$) always immediately
followed a nonword ($X_{nonword}$), it is difficult to say whether
a brain area ($Y_{brain}$) is responding solely to the word event
or if the brain area is responding to the nonword event.
Thus there could be many possible numbers given to $\beta_{word}$ and $\beta_{nonword}$
to multiply with $X_{word}$ and $X_{nonword}$ that would make a solution look similar to
the observed BOLD signal from $Y_{brain}$.
Broadly, this problem is known as \textit{collinearity} between $X_{word}$ and $X_{nonword}$. 
Problematic collinearity occurs frequently when contexts are interleaved as in event-related designs and
BSC and PPI analysis methods have different approaches to tackle collinearity
which we will revisit for each method.
% For example, if I measured how many cats people owned
% and their current stress level, I could have the following observations:
% $PersonA(3 cats, 2 stress)$, $PersonB(1 cats, 5 stress)$, and
% $PersonA(5 cats, 1 stress)$.
% Now, if I wanted to predict stress ($Y_{stress}$) from the number
% of cats a person owns ($X_{cats}$), I need to find some number
% ($\beta_{cats}$) that when multiplied with the number of cats ($X_{cats}$),
% looks most like that person's stress level ($Y_{stress}$).
% In this example, the optimal $\beta_{cats}$ is $-1$,
% suggesting for each additional cat acquired a person's stress
% is predicted to go down by one level.

% The GLM follows the same pattern, but instead of stress and cats,
% we use the BOLD response and experimental designs
% (and sometimes other BOLD responses).
% The difference is the BOLD response is not linear, it oscillates
% due to intrinsic patterns of activity and in response to external stimuli.
% Luckily, we have an approximation of what the BOLD response looks like
% in response to a stimulus~\cite{Glover1999}.
% With the approximate shape of the BOLD response, we can transform our observations ($X$) to look
% like the BOLD responses seen in the brain $Y$.
% After the transformation, we can treat the problem similarly to linear regression, where
% we are looking for a number ($\beta$) to multiply with our observations ($X$) to look
% like our outcome BOLD data ($Y$)
% For example, I have an experiment where I show participants multiple pictures of
% 1 or 5 cats at varying times while I measure their brain activity through an fMRI scan.
% I predict the BOLD response in the visual cortex when viewing 1 cat will be different than
% viewing 5 cats.
\section{Psychophysiological Interactions}

Psychophysiological Interaction (PPI) analyses are designed to 
identify brain areas that are differently functionally connected
during specific contexts relative to others~\cite{Friston1997}.
The motivating question Friston et al. (1997) answered was whether
two areas in the visual cortex were more functionally connected during a state
of high attention versus low attention.
There are three necessary components to any PPI.
The first is the psychological variable of interest, such as a stimulus (e.g., word or nonword)
in a task.
The second is the physiological variable, such as the BOLD signal from
a brain area.
The third variable is the PPI itself, which represents a multiplication
between the psychological variable and the physiological variable.
If our dependent variable is the BOLD signal in the medial frontal gyrus,
then we can answer the question if our brain area of interest and the medial frontal gyrus
are differently functionally connected during the word context relative
to the nonword context.

PPI analyses have undergone several transformations since their inception in 1997 including:
1) deconvolution~\cite{Gitelman2003}, 2) multi-conditional psychological variables~\cite{McLaren2012},
and 3) correcting imperfect deconvolution~\cite{Di2017}.
The necessity of deconvolution was investigated by Gitelman~\cite{Gitelman2003} who demonstrated
that calculating a PPI at the BOLD level is not equivalent to calculating
a PPI at the neural level.
The interaction of interest occurs at the neural level, not at the level of the BOLD signal
because our behaviors are determined by neural activity and not the blood flow that peaks 6 seconds
after the stimulus.
While it would appear one could convolve the psychological variable with the BOLD response and
multiply the psychological variable with the physiological BOLD signal from the brain area of interest,
this is not mathematically equivalent to deconvolving the BOLD signal and multiplying the physiological
neural signal with the psychological variable.
The amount of error incurred from using the former option is dependent on the experimental
design employed.
For block designs, the difference appears inconsequential, but for event-related designs
the difference is more substantial~\cite{Gitelman2003}.
If different cognitive processes occur close to each other such as word and nonword
reading, deconvolution of the BOLD signal is essential.

The second transformation of PPI analyses came from McLaren et al. (2012)~\cite{McLaren2012}.
Their goal was to properly represent experiments with more than two experimental conditions, like
the above example where there were cue, delay, and probe event conditions.
Traditionally, the psychological variable was a contrast between two event conditions, such as
$word - nonword$ to create one PPI for analyses.
In experiments with more than two conditions, calculating only one PPI did not account
for the unmodelled condition and resulted in incorrect estimates of the effect~\cite{McLaren2012}.
McLaren et al. (2012) presented that instead of using contrasts, researchers could
calculate a separate PPI for each psychological variable independently and then
perform contrasts between the $\beta$ estimates to find differences in context-dependent functional connectivity.
This method is known as generalized PPI (gPPI) analysis.
The implementation used in this thesis work performs gPPI.

The third transformation of PPI analyses to date involves a peculiarity from the combination of
deconvolution and not centering the psychological variable when computing a PPI~\cite{Di2017}.
To conceptually understand this process we need to accept that deconvolution is imperfect, and if I
deconvolved and reconvolved the physiological BOLD signal, I would not get the exact same BOLD signal.
Additionally, we need to accept that a non-centered variable is a centered variable plus a constant.
Thus, if we deconvolve the physiological BOLD signal and multiply the deconvolved
BOLD signal with a centered psychological variable and a constant, we have the neural PPI
as well as scaled multiple of the physiological deconvolved BOLD signal.
When we reconvolve the neural PPI (and the implicit scaled neural signal a part of the PPI),
we have the PPI we want and a deconvolved/reconvolved physiological BOLD signal that is not equivalent to the
original physiological BOLD signal.
It turns out this non-equivalence gives the PPI term information about the physiological BOLD signal that
reflects how well the physiological BOLD signal correlates overall with the outcome brain area BOLD signal, and not just
during the psychological context.
If deconvolution is not a part of the process, centering the psychological variable does not impact the interpretation
of the PPI term because the physiological signal represented in the PPI is equivalent to the main effect of the physiological
signal that is also included in the model so their shared variance removes their impact on the PPI term.
Thus to create correct PPIs using deconvolution, the psychological variables must be centered.
The implementation used in this thesis work demeans the psychological variables.

\section{Beta Series Correlations}

Rissman et al. (2004)~\cite{Rissman2004} were the first to publish on BSC,
describing their usage in a working memory task.
In this task, participants saw a cue, a delay, and a probe, all occurring
within a short period (~9 seconds).
The cue was presented for one second, a delay occurred for seven seconds,
and a probe was presented for one second.
If Rissman et al. (2004) chose a sliding window or residual approach to measure context-dependent functional connectivity,
they would not be able to dissociate the processes of visually encoding a stimulus,
maintaining the stimulus in working memory over a delay and the decision process when comparing a
probe to the stimulus in working memory.
Additionally, deconvolution for PPI was proposed around the same time as BSC,
suggesting PPI at the time was subject to the same limitations as
the sliding window and residual approaches.
To identify the brain areas working together to complete those individual cognitive tasks,
Rissman et al. (2004) developed BSC.
Instead of having a single regressor to describe all the cue events,
a single regressor for all the delay events, and a single regressor for all the
probe events (as is done in traditional task analysis),
there is an individual regressor for every event in the experiment.
For example, if your experiment has 40 events, each with a cue, delay, and
probe event, the model will have a total of 120 regressors, fitting a $\beta$
(i.e., parameter) estimate for each event.
Once you calculate a $\beta$ estimate for each event of a given type
(e.g., cue), you will have a four-dimensional data-set where each BOLD volume
represents the $\beta$ estimates for a particular cue event.

Having one regressor per event in a single model is known as "least squares- all" (LSA).
This method, however, has limitations in the context of fast event-related
designs.
Since each event has its own regressor, events that occur very close in time
are collinear (e.g., are overlapping and look similar).

Jeanette Mumford's and Benjamin Turner's work~\cite{Turner2010,Mumford2012} derived a solution for
the high collinearity observed in LSA by using another
type of regression known as "least squares- separate" (LSS).
Instead of having one GLM with a regressor per event,
LSS implements a GLM per event with a minimum of two regressors:
1) one for the event of interest, and 2) one for every other event in the
experiment.
In the above LSA example, instead of having 1 GLM with 120 regressors,
LSS will create 120 GLMs with 2 regressors each.
This process reduces the collinearity of the regressors and creates a more reliable
estimate for each event, but also combines all other events into a single regressor
within the design matrix, which will reduce model fit.

Benjamin Turner's subsequent work~\cite{Turner2012a} improved LSS by retaining
the original event conditions in the design matrix.
In this updated version, the event of interest is given its own regressor, but all
other events retain their position.
Again, leveraging the above example with cue, delay, and probe events,
this new LSS method would create 120 GLMs with 4 regressors each (event of interest, cue, delay, and probe).
I am referring to the improved version of LSS throughout the remainder of the thesis.

While LSS addresses the immediate problem of high collinearity between regressors,
it does not come without cost.
LSS $\beta$ estimates are influenced by adjacent events such that if an event in condition A
was flanked by two events in condition B, the $\beta$ estimate for the event in condition A
is likely biased (i.e., not orthogonal) to the adjacent events in condition B.
BSC methods have primarily been tested with multivariate approaches in mind, univariate
differences in context-dependent correlations have been relatively ignored.
The present work seeks to further validate BSC as PPI analyses have already had
extensive validation.

\section{Overall Research Aims}

There are at least two points of difference between BSC and PPI analyses.
1) BSC correlates $\beta$ estimates from the same condition, whereas PPI analyses define
the interaction between condition and BOLD responses within the $\beta$ estimate.
2) Correlations (as calculated in BSC) are different than changes in regression slopes
(as used in PPI analysis)~\cite{Di2019}.

The first difference presents a potential advantage of PPI analyses creating more reliable
estimates of context-dependent functional connectivity because when contrasting the $\beta$ estimates
within the PPI framework, the standard errors of the $\beta$ estimates provide the level of
confidence in the $\beta$ estimate.
BSC on the other hand do not typically incorporate the standard error of the $\beta$ estimate
when calculating correlations potentially leading to unreliable and high variance $\beta$
estimates.

The second difference acknowledges that correlation is different from regression.
This is relevant if one event condition has a higher variance than the other event condition,
which would impact the correlations in BSC, but not the regression slope in PPI analyses.

With the differences between the BSC methods (LSA and LSS)
and PPI, it is difficult to ascertain whether
they will all produce very similar or divergent results, and if they 
diverge, it is unknown which method researchers should have more confidence in.
Furthermore, to my knowledge, no other research exists that formally compares
LSA, LSS, and PPI using the same data-set.
Thus, I compared LSS, LSA, and PPI to discover to what extent the methods converge and provide
recommendations on which method is potentially more sensitive to detect
differences in context-dependent functional connectivity.
\newline
\newline
\textbf{Specific Aim 1}: Evaluate whether LSS or LSA has more power to detect
differences in context-dependent functional connectivity.
\newline
\newline
\textit{Rationale}: Should researchers reach to LSA for their analysis of
context dependent functional connectivity differences
or should they use the more computationally intensive LSS?
Previous literature suggests LSS performs better on machine learning applications, and giving
more precise correlations relative to LSA in certain contexts~\cite{Abdulrahman2016,Mumford2012,Turner2012a,Cisler2012}.
However, multivariate machine learning measures and precision of correlations do not translate to
univariate correlation differences.
Machine learning identifies the unique fingerprint of an event condition, which may not be related
to a correlation between two brain areas.
If we define precision as the absolute difference between the observations and the reality,
Correlations that are systematically biased may not be precise, but if both event conditions are
impacted similarly, the precision of the correlation is independent of its ability to
detect differences between event conditions.
For example, LSS may give more precise correlations, while LSA could give
correlations that are systematically 0.2 greater than reality.
While LSS would be deemed more precise, both LSS and LSA could perform similarly
when looking at context-dependent functional connectivity differences.
\newline
\newline
\textit{Hypothesis}:
LSS will detect more context-dependent functional correlation differences in a mixed event/block task.
\newline
\newline
\textit{Method}:
I used both simulations and data from participants to compare LSS/LSA.
I simulated two voxels that responded to two conditions where the conditions
could have different correlations in their BOLD responses.
Simulations were generated for a variety of event-related experimental parameters and
signal to noise properties that cover common usage in cognitive neuroscience.
From these simulations, I was able to contrast the two conditions with different
underlying correlations for 10,000  iterations to count how many times
each BSC method (LSS/LSA) was able to detect the correlation difference between conditions.

The participant data included a mixed event-related/block design task and resting
state data used as a null model.
With the mixed event/block design, I was able to perform contrasts from events
between and within blocks so I could examine how each BSC method performs
in a block or event-related contrast.
The resting state data were modeled as though the participant had completed the task
to measure how likely LSS or LSA would detect context-dependent functional correlation
differences when no such differences are predicted to exist.
\newline
\newline
\textbf{Specific Aim 2}: Evaluate whether BSC methods or PPI analysis has
more power to detect differences in context-dependent functional connectivity.
\newline
\newline
\textit{Rationale}: Researchers may not want to use BSC methods
to detect context dependent functional correlation differences if
PPI analyses are superior.
Preliminary evidence from Xi et al. (2019) suggests PPI detects more
context-dependent functional correlation differences relative to LSS,
but this observation was not thoroughly investigated~\cite{Di2019}.
Additionally, while BSC and PPI analyses purport to measure the same underlying
biological process, they take different approaches which could lead to large differences
in their estimates.
\newline
\newline
\textit{Hypothesis}:
PPI will detect more context-dependent functional correlation differences than BSC methods.
\newline
\newline
\textit{Methods}:
Both the task and resting state participant data from Aim 1 are used to perform
the same block/event-related contrasts.
I correlated the BSC estimates with the PPI analysis estimates to identify which BSC method
correlated more with PPI.


%=============================================================================
\chapter{Comparing LSS/LSA}
%=============================================================================

\section{Introduction}
\label{intro}

Cognitive neuroscience blends cognitive tasks with measures of brain activity to drive discoveries.
These cognitive tasks often incorporate multiple conditions interleaved with each other,
and the cognitive process of interest is manifested as the difference between those conditions.
The most common analysis of tasks completed during functional magnetic resonance imaging (fMRI)
examines the magnitude of brain activity.
More recently, the importance of examining how brain regions act together as networks has become increasingly evident.
Broadly defined, a brain network is a collection of brain regions that share information~\cite{Uddin2019}.
Brain networks have primarily been investigated while participants are at rest, but there
is a rising interest in observing brain networks while participants perform tasks~\cite{Cole2014a}.
There is also increasingly popular to measure dynamically changing correlations
within and between brain networks over time~\cite{Sakoglu2008,Hindriks2016}.
However, there has not been investigation and validation of brain networks
when participants engage in tasks with interleaved conditions that could induce
different brain networks dynamically~\cite{Di2019a}.
In other words, measuring context-dependent brain networks has not been validated within fast event-related designs~\cite{Buckner1998}.
We seek here to validate and compare two methods that may measure brain responses to events that occur
close in time.

The overarching method being investigated is beta series correlations (BSC)~\cite{Rissman2004,Mumford2012,Turner2012a,Abdulrahman2016}
There are two main approaches to estimate the beta series for BSC: Least Squares All (LSA) and Least Squares Separate (LSS)~\cite{Mumford2012}.
Both approaches of beta series estimation seek to derive single event estimates that represent a brain region's
(or voxel's) activity at each individual event.
An event is defined as "a stimulus or participant response recorded during a task."~\cite{Gorgolewski2016}
Where task is defined as "a set of structured activities performed by the participant."~\cite{Gorgolewski2016}
The single event estimates become difficult to estimate when events occur close together (Figure~\ref{fig:introhrf}).
Such designs are called fast event-related designs and are commonly
used in cognitive neuroscience.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{introduction-hrf}
  \caption[Model of the Hemodynamic Response Function (HRF)]{
    Model of the Hemodynamic Response Function (HRF)~\cite{Glover1999} at a
    typical resolution of an fMRI scan (2 seconds). The x-axis represents time in seconds and the y-axis is arbitrary units.
    Fast event-related designs with inter event intervals (IEIs) at or faster than time to peak
    response (e.g., 4-6 seconds), need to account for the overlapping signals.
  }
  \label{fig:introhrf}
\end{figure}

The BOLD response is an indirect measure of neuronal activity that takes approximately 6 seconds to
peak and around 16-32 seconds to effectively return to baseline~\cite{Glover1999}.
If events occur (on average) 4 seconds apart, the difficulty of single event estimation
becomes apparent.
In this situation, it is difficult to ascertain whether BOLD activity should be attributed to a target event or an
adjacent event.
LSA and LSS approach this problem differently.
LSA ignores this problem by calculating a high variance, but low bias measure by enforcing orthogonality
between events,
whereas LSS calculates a lower variance, but more biased measure, relaxing the orthogonality restriction.
To understand how LSA and LSS differ in their restrictions of orthogonality in single event estimation,
it is necessary to introduce the General Linear Model (GLM).
GLMs are a mainstay in the neuroimaging literature, allowing researchers to model
a curve that approximates the BOLD response shape and linearly scale the curve
to best match the data~\cite{Friston1995a}.
The multiplicative that linearly scales the model BOLD response is known as a beta
and provides the namesake for beta series.
This beta is often interpreted as the amplitude of the response, which is true when the
model approximates the shape of the BOLD response well and becomes less clear when
the model does not match the shape of the BOLD response.
In a traditional GLM, events of the same type will be grouped together
to provide a robust estimate of whether a particular region or set of regions are
active relative to some baseline or another condition (Figure~\ref{fig:introGLM}).

\begin{figure}[H]
  \centering
  \includegraphics[width=0.2\textwidth]{introduction-normalGLM}
  \caption[Example GLM design matrix]{
    An example of a design matrix seen in a traditional GLM used in fMRI~\cite{Friston1995a}.
    There is a single column for each condition, resulting in two columns (intercept column ignored for clarity).
    With this design you can answer questions about which voxels are more or less active in one condition
    versus another, but you cannot see which voxels vary together over stimulus presentations.
  }
  \label{fig:introGLM}
\end{figure}

Grouping together events of the same type, however, does not tell you which regions are acting in concert
in response to the event type.
The traditional GLM produces a single beta estimate per event type, but to measure which regions
are acting in concert; you would need a beta estimate per event.
For example, it could be the case that for half of the events of the same type regions $A$ and $B$ are active,
and for the other half, regions $A$ and $C$ are active.
The traditional GLM will not be able to differentiate the different pairs of regions.
LSS and LSA, on the other hand, propose to be able to identify region $A+B$ and $A+C$.
LSA takes a variant of the traditional GLM whereby instead of providing a beta
estimate for a group of events, each event gets its own beta estimate in a single GLM (Figure~\ref{fig:introlsa}).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-lsa}
  \caption[Example LSA design matrix and analysis]{
    Left shows an example design matrix for LSA where each event gets its own column.
    Since we receive a beta estimate per column, we end up with as many beta estimates as there
    are events.
    We can combine those beta estimates to create a beta series (Right) for each condition.
    In this example we measured beta series for 2 voxels, allowing us to
    correlate the beta series from one voxel to another.
    We can perform the correlation for the 2 conditions (Condition 0 and Condition 1).
    The arrows on the design matrix (left) correspond to the beta estimates of those events
    on the shaded regions (right).
  }
  \label{fig:introlsa}
\end{figure}

LSS differs from LSA by fitting a separate GLM for each event, where in each model a target
event is fit and the rest of the events are grouped together and given separate beta estimates (Figure~\ref{fig:introlss}).
LSS was introduced by placing all other events into a single regressor, but as shown in Figure~\ref{fig:introlss},
each event type has its own regressor, which is referred to as LSS-N in other papers~\cite{Rissman2004,Abdulrahman2016,Mumford2012}.
We will refer to LSS-N as LSS for the remainder of the manuscript.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-lss}
  \caption[Example LSS design matrix and analysis]{
    Left shows an example design matrix for LSS where each event gets its own model
    (intercept excluded for clarity).
    The target event (outlined in red) comes from either condition 0 or 1.
    For example, if the target event is from condition 1, the remaining condition 1 events
    get their own column, and all of the condition 0 events get their own column.
    Since we receive a beta estimate per model, we end up with as many beta estimates as there
    are events.
    We can combine those beta estimates to create a beta series (Right) for each condition.
    In this example we measured a beta series for 2 voxels, allowing us to
    correlate the beta series from one voxel to another.
    We can perform the correlation for the 2 conditions.
    The arrows on the design matrix (left) correspond to the beta estimates of those events
    on the shaded regions (right).
  }
  \label{fig:introlss}
\end{figure}

The target event estimate from each GLM is taken to form a beta series.
Hearkening back to the sluggish BOLD response, LSA suffers when the events are close together,
since the GLM cannot reliably attribute which BOLD response should correspond to which event (Figure~\ref{fig:introGLM}).
LSS attempts to reduce the model confusion by having one event estimate per model,
so the non-target events have their beta estimate influenced by multiple observations, loosening the
constraint that adjacent events to the target event need to be orthogonal (i.e., independent) from each other.
While previous work has simulated beta series and evaluated beta series on participant data,
several key gaps remain~\cite{Mumford2014a,Mumford2012,Turner2012a,Abdulrahman2016,Cisler2012,Arco2018}.
One, simulations have not taken into account realistic noise structure of fMRI data such as autocorrelations, movement, and physiological noise.
Two, simulations have not used optimized fast event-related designs, only randomly selected designs. 
Three, empirical selections of signal to noise ratios have not been considered,
ratios were chosen without justification in previous work~\cite{Abdulrahman2016,Mumford2012}.
Four, a quantitative comparison of LSA and LSS condition contrasts for BSC has not been done.
The present work fills these gaps and provides recommendations for further research
using LSA and LSS.
Important terms used throughout the paper are presented in Table \ref{table0}.

\begin{table}[H]
  \centering
  \caption[Acronym definitions]{
  {\bf Acronym Definitions}}
  \begin{tabular}{|l|l|p{60mm}|}
  \hline
  Name & Acronym & Definition\\
  Least Squares All & $LSA$ & beta estimation method where each event gets a regressor in the same model\\ \hline
  Least Squares Separate & $LSS$ & beta estimation method where each event gets a separate model\\ \hline
  Contrast Noise Ratio & $CNR$ & $A_S/\sigma_N$, amplitude of signal ($A_S$) divided by standard deviation of the noise ($\sigma_N$)\\ \hline
  Activation Variation Noise Ratio & $AVNR$ & $\sigma_S/\sigma_N$, standard deviation of signal ($\sigma_S$) divided by standard deviation of the noise ($\sigma_N$)\\ \hline
  \end{tabular}

  Definitions of the main acronyms use in this paper.
  $CNR$ and $AVNR$ definitions are found in Welvaert (2013)\cite{Welvaert2013a}.
  \label{table0}
\end{table}

\section{Materials and Methods}
\label{methods}

Testing and validation of beta series correlations followed three stages.
First, beta series correlations were tested in simulations across different
optimized experimental designs.
Second, beta series correlations were tested in simulations using an experimental
design that was used to collect participant data.
Third, beta series correlations were validated in task data collected from
participants.
Resting state data collected from the same participants were used as a null
control for beta series correlations in stage three.
The null control measures the number of spurious results found
with BSC since there is no expectation of BSC to change
during resting state.

\subsection{Beta Series Correlation Simulations}
\label{methods:bsc-simulations}

To assess the validity and power of beta series correlations,
we simulated 2 voxels of fMRI time-series data and convolved short (0.2 second)
task onsets with a double gamma function
and added the responses to the time-series~\cite{Glover1999,Welvaert2011}.
We used fmrisim from the brainiak toolbox\cite{Ellis2020} to generate a
2 voxel fMRI time-series containing drift, autocorrelation ($\rho$ = 0.5), physiological noise,
task related movement, and scanner noise (Figure~\ref{fig:simulation_example}).
Noise features were all weighted equally in the simulations.

\begin{figure}[H]
  \centering
  \includegraphics{methods-simulation_example}
  \caption[Illustration of simulated data]{
    Example of predicted BOLD from a task design (thick grey line), real BOLD
    from a participant (see \nameref{methods:task-switch}), and simulated BOLD
    from fmrisim~\cite{Ellis2020}.
    The simulated BOLD appears similar to real BOLD.
  }
  \label{fig:simulation_example}
\end{figure}

For all simulations the time of repetition was set to 2 seconds.
We varied the contrast-to-noise ratio (CNR) using the amplitude of the activation
divided by the standard deviation of the noise~\cite{Welvaert2013a}.
Another parameter deemed critical by previous work is the standard deviation
of the raw beta estimates relative to the standard deviation of the noise~\cite{Abdulrahman2016},
so this measure was also varied in our analysis.
To distinguish the measure from our use of CNR,
we've decided to rename it as Activation Variance to Noise Ratio (AVNR).

To generate realistic numbers for simulating time-series at varying CNRs and AVNRs
we used an unpublished data-set on task switching in older adults (N=40).
We ran LSS/LSA to get both event estimates of activation (i.e., betas)
as well as residuals from the model.
To calculate CNR, several steps were taken.
First, we masked the beta series using two different atlases:
an "Activation" atlas based on peak BOLD responses seen in the data,
and the Schaefer Atlas\cite{Schaefer2017}(see \nameref{methods:atlas-corr-analysis}).
Second, we extracted the absolute value of all masked beta estimates for a participant.
Third, we measured the median beta estimates over all events resulting
in a median beta estimate amplitude for all regions of interest (ROIs).
Fourth, we calculated the standard deviation of the residuals for each ROI.
Fifth, we divided the median amplitude beta estimates by the standard deviation of the residuals
for each ROI.
Sixth, we selected either the mean or max CNR across all ROIs to provide a reasonable estimate
and upper bound of CNR.
Calculating AVNR followed the same procedure as CNR with the exception of the first two steps.
First, we calculated the standard deviation of the beta estimates, then we followed steps three through six above
on the standard deviation of the beta estimates (as opposed to the amplitude).
Based on these calculations used on participant data, we chose to move forward using CNR and
AVNR values of 1 and 2 as reasonable representative values (Table~\ref{table1}).
We performed subsequent analyses in parallel using all combinations of these representative values to probe the relative importance of AVNR and CNR
in influencing the power of beta series correlations.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/cnr_trial_variability.ipynb}{see here for the relevant code})

\begin{table}[H]
	\centering
	\caption[Summary of AVNR and CNR measures in participant data]{
	{\bf Summary of AVNR and CNR measures in participant data}}
	\begin{tabular}{|l+l+l|l|l|l|}
	\hline
	Atlas & Method & CNR (mean) & CNR (max) & AVNR (mean) & AVNR (max)\\
	$Schaefer$ & $LSS$ & 0.71 & 1.81 & 1.03 & 2.33\\ \hline
	$Activation$ & $LSS$ & 0.99 & 1.58 & 1.42 & 2.18\\ \hline
	$Schaefer$ & $LSA$ & 1.02 & 2.48 & 1.54 & 3.61\\ \hline
	$Activation$ & $LSA$ & 1.42 & 2.18 & 2.15 & 3.26\\ \hline
	\end{tabular}
	The average and maximum CNR and AVNR for both atlases (Schaefer and Activation)
	as well as estimation method (LSS and LSA).
	LSS tends to give lower CNR/AVNR since the measure sacrifices
	variance for bias, unlike LSA, which retains a high variance and a low bias.
	\label{table1}
\end{table}

The choice of onset times was varied based on average inter-event-interval (IEIs).
The IEI is the time from the previous event onset to the next event onset.
We chose average IEIs at 2, 4, 6, and 8 seconds to reflect a common range of IEIs
for fast event-related design experiments~\cite{Hennigan2015,Dichter2007,Goghari2009}.
We also varied the number of events, choosing 15, 30, 45, and 60 events per condition,
which also appears to be common selections for fast event-related design experiments.
The optimization of event onsets was done with neurodesign~\cite{Durnez2018}.
We chose to optimize A-Optimality for onset selection using the genetic algorithm implemented
in neurodesign, selecting onsets with an exponential distribution.
The top 20 designs were chosen from neurodesign to reduce the likelihood
that the simulation results would be an artifact of idiosyncrasies
of the optimized experimental design.

The beta weights for each voxel pair were chosen from a multivariate normal distribution
with a mean of 1 and with a fixed ground truth correlation between the 2 voxels 
(varying between 0.0-0.9) with AVNR of either 1 or 2.
The ground truth correlation was varied to ensure the ground truth correlations were above
and below the correlations of the noise time-series between the 2 voxels
since both voxels had shared noise sources from simulated motion.
The beta weights were convolved with a hemodynamic response function and scaled
relative to the noise standard deviation to CNRs of 1 or 2.
(\href{https://github.com/jdkent/betaSeriesSimulations/tree/34bf1ff5b05c0eeae855f0e8e1267765bf14999a/beta_sim}{see here for simulation code})

200 simulations were run for each combination of event number
(15, 30, 45, 60) IEI (2, 4, 6, 8),  CNR (1, 2), AVNR (1, 2), condition (c0, c1),
and ground truth correlation
(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
resulting in 256,000 total simulations.
Within each 200 simulation combination, the 20 top task designs specified by
neurodesign were evenly applied to the simulations, resulting in 10 simulations
using the same design.
Each simulation of 2 voxels can be imagined as a unique participant or run from
the same participant.

To ensure the interpretability of our power analyses, we tested
the expected false positive rate when there is no difference between samples.
we took 2 samples (n=50) with the same ground truth correlation (e.g., 0.1)
matching on event number, IEI, CNR, and AVNR, and ran a t-test to measure if the samples
were statistically significantly different (p $<$ 0.05).
Since the ground truth correlation is the same between samples,
we expect a false positive rate of \%5 at an alpha of 0.05.
We repeated this process 10,000 times to measure the false positive rate as
the number of statistically significant t-tests.

Once the false positive rate was established, we established power with the same method as above,
but with samples containing different ground truth correlations.
We selected 2 samples for which there was a 0.1 (Pearson's r) correlation difference.
A 0.1 correlation difference was chosen based on reported differences found in other published
reports as well as the task used in this report~\cite{Katsura2014,Lee2017,Turner2017,Lin2019,Huang2019}.
This process was also repeated 10,000 times to establish power.
Thus we detected efficacy with which correlation differences could be detected
using different task design and noise parameters.

Simulating data using the same task design as the participant data followed the same
procedure as above, varying CNR (1, 2), AVNR (1, 2), condition,
and ground truth correlation (0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9).
IEI and event number were not varied since those parameters are fixed by the
task design.
Each parameter combination was simulated 1000 times resulting in a total of 240,000 simulations.
False positive rate and power were evaluated using the same procedure as the other simulated data.

\subsection{Participant Data Validation}
\label{methods:task-switch}

To validate the beta series simulations we used an unpublished data-set
of older adults ($N$=61, 31 female, age=71.75$\pm$4.77, education=17.07$\pm$2.66)
performing a mixed design task switching task.
Numbers reported are mean$\pm$standard deviation.
Before any experimentation, participants provided verbal and written consent
to participate in the research presented in this manuscript, which was approved
by the University of Iowa's Institutional Review Board.
N=21 participants were excluded in the primary analysis for having over
0.5mm of total movement (framewise displacement) in 100 volumes or more,
resulting in a final $N$ of 40.
We chose 100 volumes to keep the number of regressors in LSA
(which already includes as many regressors as events) a reasonable size
for single event beta estimation since we included each outlier volume
as a regressor as well.
Task switching was performed in a mixed block/event-related design containing
5 blocks (2 single task blocks and 3 dual task blocks).
There was a 30 second rest between each block.
There were 30 events during each single event block,
and for the 3 dual blocks there were 48 repeat events and 39 switch events total.
The single tasks consisted of identifying a number between
1 and 10 (excluding 5) as high/low or odd/even, using their left and right index fingers
on a fiber optic response pad.
Participants were cued to which task they were performing by the color of the square
the number was presented on (blue or pink).
Each stimulus was presented for 1.5 seconds, and participants were allowed
to respond within 2.0 seconds of stimulus onset.
The average IEI was 3.5 seconds following an exponential distribution.
All stimuli were presented using E-Prime.
Participants practiced an abridged version of this task in a mock scanner
before the real scan and had 4 practice events in the real scanner immediately
before performing the task to ensure proper finger placement and data acquisition.

Participants' average accuracy and reaction time were:
single, (92\%$\pm$27\%, 792ms$\pm$225ms); repeat, (89\%$\pm$31\%, 1001ms$\pm$278ms);
and switch, (83\%$\pm$36.8\%, 1108ms$\pm$289ms).
Due to data collection error, behavioral data were not collected for 3 participants
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/summarizeBehavior/summarize_behavior.ipynb}{see here for relevant code})

The task switch bold \emph{fmriprep} output in MNI152NLin2009cAsym space
was analyzed with \emph{Nistats} for first and second level analyses.
We used mean white matter signal, mean cerebrospinal fluid signal,
discrete cosine basis filter (high pass filter), framewise displacement, the first four non-steady volumes, and
all identified motion outliers as regressors in the first level model for each participant
in addition to event onsets convolved with a double gamma function~\cite{Glover1999}.
Each image was smoothed with a 6mm full-wide half-max kernel.
We derived 3 contrasts of interest: $switch - repeat$, $dual- single$, and $repeat - single$.
The $dual$ condition is the weighted average of $switch$ and $repeat$ to represent the
dual cost (the cost of performing two tasks at once relative to one)~\cite{Wylie2000,Verhaeghen2003}.
We ignored the correctness of the participant's response since it was not essential to
separate condition and error processing to validate BSC.

Second level analyses were a summary of the first level results presenting which
regions were robustly activated among participants.
For each contrast, the alpha was set to 0.01 with a cluster threshold of 10 voxels using
false discovery rate error control (Figure~\ref{fig:stat_maps}).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth,height=0.8\paperheight,keepaspectratio]{contrast_summary}
  \caption[Univariate statistical maps]{
    Univariate statistical maps of second level results representing
    all contrasts of interest, $dual - single$, $repeat - single$, $switch - repeat$}
  \label{fig:stat_maps}
\end{figure}

In addition to the task switching task, participants also completed
two 8 minute resting state runs.
We used the resting state runs as a null model for task switching as done
in other reports validating analyses~\cite{Eklund2016,Olszowy2019}.
While the task switch data had 471 volumes, each resting state run only had
240 volumes.
To match the length of the resting state data with the task data, we concatenated
the two resting state runs while cutting off the first 10 volumes of the second run
and interpolating 1 volume between the two runs, resulting in 471 volumes.
The interpolation helps transition the bold series from one run to the next,
analogous to interpolation performed when scrubbing high motion volumes~\cite{Power2014a}. 
This null task data was treated equivalently to the task switching data for the
beta series correlation analysis.
(\href{https://github.com/jdkent/validateBetaSeries/tree/195ad5b4201971038dbbf8f73a3c537caf032743}{see relevant code here})

\subsection{Scanner Parameters}
\label{methods:scanner}

MRI data were collected on a 3T GE Discovery 750w using a 32 channel head coil.
The anatomical T1w images were collected using a SPoiled Gradient-Recalled (SPGR) sequence
sagittally with a flip angle of 8$^{\circ}$, echo time of 3.168ms,
repetition time of 8.388ms, inversion time of 900ms, isometric voxel sizes of 1mm,
[256x256] acquisition matrix with 196 slices, field of view 25.6cm x 25.6cm.
The functional bold images were collected using a Gradient Echo sequence axially from
the bottom up sequentially with a flip angle of 80$^{\circ}$, echo time of 30ms,
repetition time of 2000ms, voxel sizes of 3.44x3.44x4.00mm on a [64x64] acquisition matrix
with 37 slices, field of view 22cm x 22cm.

\subsection{Preparing fMRI}
\label{methods:fmriprep}

Results included in this manuscript come from preprocessing performed
using \emph{fMRIPrep} 1.5.7 (\cite{fmriprep1}; \cite{fmriprep2}; RRID:SCR\_016216),
which is based on \emph{Nipype} 1.4.0
(\cite{nipype1}; \cite{nipype2}; RRID:SCR\_002502).


\subsubsection{Anatomical data preprocessing}
\label{methods:anat}

The T1-weighted (T1w) image was corrected for intensity non-uniformity
(INU) with \texttt{N4BiasFieldCorrection} \cite{n4}, distributed with
ANTs 2.2.0 \cite[RRID:SCR\_004757]{ants}, and used as T1w-reference
throughout the workflow.
The T1w-reference was then skull-stripped with a \emph{Nipype} implementation
of the \texttt{antsBrainExtraction.sh} workflow (from ANTs), using OASIS30ANTs
as a target template.
Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and
gray-matter (GM) was performed on the brain-extracted T1w using
\texttt{fast} \cite{fsl_fast} [FSL 5.0.9, RRID:SCR\_002823,][].
Brain surfaces were reconstructed using \texttt{recon-all} \cite{fs_reconall},
[FreeSurfer 6.0.1, RRID:SCR\_001847,][] and the brain mask estimated
previously was refined with a custom variation of the method to
reconcile ANTs-derived and FreeSurfer-derived segmentations of the
cortical gray-matter of Mindboggle \cite[RRID:SCR\_002438,]{mindboggle}.
Volume-based spatial normalization to standard space (MNI152NLin2009cAsym)
was performed through nonlinear registration with \texttt{antsRegistration}
(ANTs 2.2.0), using brain-extracted versions of both T1w reference and the T1w template.
The following templates were selected for spatial normalization: \emph{ICBM 152 Nonlinear
Asymmetrical template version 2009c} {[}\cite{mni152nlin2009casym},
RRID:SCR\_008796; TemplateFlow ID: MNI152NLin2009cAsym{]}.

\subsubsection{Functional data preprocessing}
\label{methods:func}

For each of the two BOLD runs (task switch and null data) per subject,
the following preprocessing was performed.
First, a reference volume and its skull-stripped version were generated
using a custom methodology of \emph{fMRIPrep}.
Susceptibility distortion correction (SDC) was omitted.
The BOLD reference was then co-registered to the T1w reference using \texttt{bbregister}
(FreeSurfer) which implements boundary-based registration \cite{bbr}.
Co-registration was configured with 6 degrees of freedom.
Head-motion parameters with respect to the BOLD reference (transformation matrices,
and 6 corresponding rotation and translation parameters) are estimated before any
spatiotemporal filtering using \texttt{mcflirt} \cite[FSL 5.0.9,]{mcflirt}.
The BOLD time-series were resampled into a standard space, correspondingly
generating the following \emph{spatially-normalized, preprocessed BOLD runs}:
MNI152NLin2009cAsym.
Several confounding time-series were calculated based on the \emph{preprocessed BOLD}:
% only used a subset of the confounding variables
framewise displacement and two region-wise global signals.
framewise displacement was calculated for each functional run, using its
implementation in \emph{Nipype} following the definitions
by Power et al. (2014)\cite{power_fd_dvars}.
The two global signals were extracted within the
cerebrospinal fluid and the white matter masks.
High-pass filtering of the \emph{preprocessed BOLD} time-series was done using
a discrete cosine filter with 128s cut-off.
The head-motion estimates calculated in
the correction step were also placed within the corresponding confounds file. 
Frames that exceeded a threshold of 0.5 mm framewise displacement or 1.5 standardized DVARS
were annotated as motion outliers.
An additional 4 frames at the beginning of each run were also
annotated as outliers to allow the magnet to reach equilibrium.

All resamplings were performed with \emph{a single interpolation step} by composing all the pertinent
transformations (i.e.~head-motion transform matrices, co-registrations to anatomical
and output spaces).
Gridded (volumetric) resamplings were performed using \texttt{antsApplyTransforms} (ANTs),
configured with Lanczos interpolation to minimize the smoothing effects of other kernels
\cite{lanczos}.

\subsection{Beta Series Correlations}
\label{methods:bsc}

\subsubsection{Beta Series Modeling}
\label{methods:bsc_model}

The LSS models were generated for each event in
the task following the method described in \cite[Turner (2012)]{Turner2012a}, using
Nistats 0.0.1b2.\\
Before modeling, preprocessed data were masked, and mean-scaled over
time.
Mean scaling was not applied when calculating CNR and AVNR so the
beta estimates would be in the original BOLD units.
For each event, preprocessed data were subjected to a GLM
in which the event was modeled with its own regressor, while
all other events from that condition were modeled in a second regressor,
and other conditions were modeled in their own regressors.
So if the task has 3 conditions, 
a single GLM would have 4 event regressors, 1 for the target
event, and 3 for the remaining conditions.

The LSA model was generated following the method described in
\cite[Rissman (2004)]{Rissman2004}, using Nistats 0.0.1b2.
Each event was given its own regressor in a single GLM, such that
if the experiment had 100 events, there would be 100 regressors in the GLM.

Each event regressor was convolved with a Glover hemodynamic response
function~\cite{Glover1999}.
In addition to event regressors, average white matter signal, average CSF signal,
cosine basis set high pass regressors, the initial four non steady-state volumes, 
and motion outliers were included
in the model as calculated in \nameref{methods:func}.
AR(1) prewhitening was applied in each model to account
for temporal autocorrelation.

After fitting each model, the parameter estimate (i.e., beta) map
associated with the target event's regressor was retained and
concatenated into a 4D image with all other events from the same
condition, resulting in a set of $X$ 4D images where $X$ refers to the
number of conditions in the task.
The number of volumes in each 4D beta series image
represents the number of events in that condition.

\subsubsection{Atlas Correlation Analysis}
\label{methods:atlas-corr-analysis}

The 4D beta series image for each condition in the task was subjected to
an ROI-to-ROI correlation analysis
to produce condition specific correlation matrices.
For the simulation data, ROI-to-ROI correlations were calculated by
treating each voxel as an ROI.
In the participant data; two atlases were used to generate ROI-to-ROI correlation matrices.
We created an activation atlas representing regions that were
consistently activated across event conditions (see \nameref{methods:task-switch}).
This atlas has coverage across several cortical and subcortical regions.
The second atlas, Schaefer Atlas (400 parcels, 17 networks)\cite{Schaefer2017}, was
used to comprehensively cover the cortex and test robustness of results.

An activation atlas was generated based on an F-test across the switch, repeat, and single conditions
to identify regions that were reliably activated for all participants (Table~\ref{table:clusters}).
5mm spheres were drawn around each statistical peak (21 peaks total) (Figure~\ref{fig:methroimap}).

\begin{table}[H]
  \csvautotabular[separator=tab, no check column count]{./data/cluster_table.tsv}
  \caption[Peak activation coordinates]{
    The peak MNI coordinates/Z-statistic identifying clusters/sub-clusters from the overall
    response contrast.
    These peaks were used to create regions of interest (ROIs) to form an atlas representative
    of the most consistently activated regions across conditions.
  }
  \label{table:clusters}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{stat-map-overall_resp_with_rois}
  \caption[Activation atlas]{
    ROIs drawn from the peak Z-score table, placing a sphere with a 5mm radius
    at each peak coordinate.
    The clusters are identified in their approximate locations
    with their ID.
  }
  \label{fig:methroimap}
\end{figure}

\begin{table}[H]
  \csvautotabular[separator=tab]{./data/schaeferbest_rois.tsv}
  \caption[Top CNR coordinates]{
    The top 20 ROIs from the Schaefer 400 (17 Network) identified with a highest CNR as measured by
    both LSS and LSA.
  }
  \label{table:parcels}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{schaefer_high_cnr_rois}
  \caption[Schaefer Top 20 ROIs atlas]{
    20 ROIs selected from the Schaefer 400 parcels; 17 network atlas for having the
    highest CNR for both LSS and LSA.
  }
  \label{fig:schaefertopmap}
\end{figure}

To increase the likelihood of being able to detect a real result using the Schaefer atlas,
we selected the top 25 ROIs with the highest CNR using LSA and LSS separately
(see \nameref{methods:bsc-simulations} for how we calculated CNR).
We then took the intersection of the two ROI sets resulting in 20 ROIs that have a high CNR
as measured by LSA and LSS (Table~\ref{table:parcels},Figure~\ref{fig:schaefertopmap}).
We refer this subset of ROIs as the SchaeferTop20 Atlas for the rest of the manuscript.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/cnr_trial_variability.ipynb}{see here for relevant code}).
The results for the entire 400 ROI atlas are shown in the supplementals.

Outlier beta estimate volumes were identified and discarded using a
modified Nipype function for outlier detection
(\href{https://github.com/HBClab/NiBetaSeries/blob/a45c0a1f/src/nibetaseries/interfaces/nilearn.py#L153}{see here}) \cite{Crosby1994}.
The correlation coefficient estimator used for generating correlation matrices
was empirical covariance, as implemented in Nilearn 0.4.2~\cite{nilearn}.
Correlation coefficients were converted to normally-distributed z-values using
Fisher's r-to-z conversion~\cite{Fisher1915}.

In the participant data, BSC generated correlation matrices for each condition (dual, switch, repeat, single),
each method, (LSA and LSS), each data type (real and null), and each participant (N=40).
The first check performed was contrasting the real dual condition and null dual condition
to ensure BSC from a task are different than BSC from null data.
A paired t-test was run on each ROI-ROI pair for the activation atlas, totaling 210 comparisons
between task and null.
We next contrasted $dual - single$, $repeat - single$, and $switch - repeat$, for LSS/LSA in both
real and null data.

Since we do not have a ground truth for which ROI-ROI pairs should be different between conditions,
we used a binomial test across all ROI-ROI pairs to discover if the number of observed significant ROI-ROI pairs was greater
than 5\%.
We did not use false discovery rate correction on the observed p-values since we were not interested in
which specific ROI-ROI pair correlations were likely to be true positives, but rather if the number of positives
observed would be expected by chance alone or if LSS/LSA likely detected an overall difference between event conditions.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/beta_series_analysis.ipynb}{see here for relevant code})

\subsection{Software Dependencies}
\label{methods:software-dependencies}

The results in this manuscript are dependent on many open source
libraries, while we have inevitably missed providing all due credit,
we would like to acknowledge some of the main libraries used in 
\emph{fMRIPrep} 1.5.7\cite{fmriprep1} and \emph{NiBetaSeries} 0.6.0\cite{Kent2018}.

Many internal operations of \emph{fMRIPrep} use \emph{Nilearn} 0.6.1
\cite[RRID:SCR\_001362]{nilearn}, mostly within the functional
processing workflow. For more details of the pipeline, see
\href{https://fmriprep.readthedocs.io/en/latest/workflows.html}{the
section corresponding to workflows in \emph{fMRIPrep}'s documentation}.

Additional libraries used in the \emph{NiBetaSeries} workflow include
\emph{Pybids} 0.9.5 \cite{Yarkoni2019}, \emph{Niworkflows} 1.0.4,
\emph{Nibabel} 2.4.1, \emph{Pandas} 0.24.2 \cite{McKinney2010}, and
\emph{Numpy} 1.18.1 \cite{VanDerWalt2011, Oliphant2006}.

In addition to the data analysis, visualization of results depended
on matplotlib\cite{Hunter2007}, seaborn\cite{Waskom2020}, nilearn,
jupyter notebooks\cite{Kluyver2016a}, and the packages they depend on.

%%%%%%%%%%%%%%%%%%%%%%%%
%% RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{results}

\subsection{Beta Series Correlation Simulations}
\label{results:bsc-simulations}

The first stage of BSC testing focused on simulations with varying event numbers,
IEIs, CNRs, AVNRs, and estimation methods.
For proper interpretation of the power analyses, we first established whether
a 5\% false positive rate was found across all combinations of
event numbers, IEIs, CNRs, AVNRs, and estimation method.
We found a nominal \%5 false positive rate held across all combinations
of parameters (Figure~\ref{fig:res_sim_fpr}).
With the false positive rate established, we next observed how detectable a
correlation difference of 0.1 was across all parameters.

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{avnr-1_smalldiff}}

  \subfloat{\includegraphics[width=\textwidth]{avnr-2_smalldiff}}

  \caption[Simulation results for LSA/LSS]{
    Detection power of a small difference between conditions (r=0.1).
    LSS at least marginally outperforms LSA in most simulated experimental
    designs, with a large difference in power when IEI is 4 seconds and
    CNR is high.
    LSS appears to have an advantage in low CNR scenarios across the longer IEIs
    when AVNR is high.
    Each bar represents a sample of 50 pairs of correlations
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:res_sim_smalldiff}
\end{figure}

At an IEI of 2 seconds, there is no discernible difference between LSS and LSA.
Since the simulated data were sampled at 2 second intervals, the result
corresponds to effectively presenting a stimulus during each frame.
With such overlapping simulated BOLD responses detecting a difference between conditions
is unlikely.
From an IEI of 4 seconds and upwards, LSS has greater detection power than LSA.
Increasing the number of events beyond 30 appears to increase detection power only if the CNR is greater than 1.
Increasing the CNR improves detection power more than increasing the AVNR, although increasing either
CNR or AVNR improves detection power.
% add the numbers to say what the difference between CNR and AVNR
For LSS, the 8 second IEI does not appear to greatly increase detection power beyond a 6 second IEI.

\subsection{Participant Data Beta Series Correlations}
\label{results:bsc-taskswitch}

We simulated data using the task switching design for stage two of beta series
validation and found comparable
results to the previous simulations, with LSS outperforming LSA.
To achieve 80\% power assuming a CNR of 2 and AVNR of 2, 50 participants were sufficient for LSS, but LSA
% say what percent power 
did not approach 80\% power within our tested range of 5-60 participants.
However, it is important to note that the present analysis only included 40 participants with adequate data,
indicating all subsequent analyses will be moderately under powered.

\begin{figure}[H]
  \includegraphics[width=\textwidth]{taskswitch-switchXrepeat_smalldiffparticipants}
  \caption[Simulation power analysis using real task design]{
    Simulations from the task design used to collect the real data.
    LSS achieves 80\% power when N=50, but LSA only achieves \~60\% power at N=60.
    CNR and AVNR were set to 2, meaning this is an optimistic power analysis
    for a correlation difference of 0.1.
  }
  \label{fig:taskswitch-simulation}
\end{figure}

% reword this sentence
We looked at task switching data from the most lenient
contrast ($task - null$) to several block contrasts ($dual - single$ and $repeat - single$)
to an event-related contrast ($switch - repeat$)
to assess how well LSS and LSA detect ROI-ROI correlation differences between conditions.
We performed the same contrasts (excluding $task - null$)
using null data to measure the specificity of each method.

We found both LSS and LSA had a greater number of statistically significant ROI-ROI pairs than expected by chance
for the contrasts in the activation atlas $task - null$ (LSS: 12.86\%; p $<$ 0.001, LSA: 11.90\%; p = 0.001).
LSS had a greater number of statistically significant ROI-ROI pairs than expected by chance within the 
$dual - single$ contrast (LSS: 9.05\%; p = 0.010, LSA: 4.29\%; p = 0.727).
LSA had a greater number of statistically significant ROI-ROI pairs than expected by chance for the
$repeat - single$ contrast (LSS: 7.62\%; p = 0.063, LSA: 10.00\%, p = 0.002) (Figure~\ref{fig:main-result}).
Surprisingly, LSS found fewer significant ROI-ROI pairs than expected by chance
for the contrast $switch - repeat$ in both the real data and null data. 

The contrasts performed on the SchaeferTop20 atlas show qualitatively similar results,
with LSS and LSA achieving a greater number of significant ROI-ROI pairs
than expected by chance for the contrasts
$task - null$ (LSS: 14.74\%, p $<$ 0.001; LSA: 21.05\%, p $<$ 0.001) and
$repeat - single$ (LSS: 11.05\%, p $<$ 0.001; LSA: 12.63\% p $<$ 0.001).
LSS alone showed a greater number of significant ROI-ROI pairs than expected
for the contrast
$dual - single$ (LSS: 10.53\%, p = 0.001; LSA: 7.90\%, p = 0.055).
Both LSS and LSA did not deviate from the expected false positive rate for the contrast
$switch - repeat$.
The results concerning the null data for the SchaeferTop20 atlas demonstrate
the possibility that LSA detects a greater number of significant ROI-ROI
pairs than expected by chance when there is no response to the model, but since this finding did not
replicate in the activation atlas, there may be an interaction between using the LSA method with
high CNR ROIs.
Those two contrasts indicate the success of LSS and LSA to measure
context dependant functional connectivity differences
in ROI-ROI correlations when the events are in different blocks.
The full Schaefer atlas has qualitatively similar results with two notable exceptions:
1) the $switch - repeat$ contrast using LSA found more statistically significant
ROI-ROI pair correlation differences between conditions relative to chance,
but LSS did not and
2) LSS has higher false positive rate than LSA (Figure~\ref{fig:significant-contrasts6}).

\begin{figure}[H]
  \centering
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-activation_participants-filtered_permutation_summary} 
  \label{fig:real-activation}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-activation_participants-filtered_permutation_summary} 
  \label{fig:null-activation}}
  \vfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-schaeferbest_participants-filtered_permutation_summary} 
  \label{fig:real-schaeferbest}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-schaeferbest_participants-filtered_permutation_summary} 
  \label{fig:null-schaeferbest}}
  \caption[Comparison of LSS/LSA in participant data]{
    Percentage of statistically significant ROI-ROI pairs found
    in the contrasts $task - null$, $dual - single$, $repeat - single$, and
    $switch - repeat$.
    The red dotted line represents the expected 5\% false positive rate
    and the shaded red region is the 95\% confidence interval.
    Left panels \ref{fig:real-activation} and \ref{fig:real-schaeferbest}
    are results from the real data with the contrast $task - null$ subtracting the
    ROI-ROI correlation found in the null data from the ROI-ROI correlation found in the
    real data for the $dual$ condition.
    Right panels \ref{fig:null-activation} and \ref{fig:null-schaeferbest} are results
    from the null data.
    While in the activation atlas both LSS and LSA show similar performance;
    in the SchaeferTop20 atlas, LSA has an increase in false positives
    whereas LSS is closer to an expected number of false positives.
  }
\label{fig:main-result}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{
    data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle}
  \caption[SchaeferTop20 atlas, real data, repeat - single]{
    Visualization of the significant ROI-ROI pairs detected in Figure \ref{fig:real-schaeferbest}
    for the contrast $repeat - single$.
    While LSA detected 21 significant ROI-ROI pairs and LSS detected 18 significant
    ROI-ROI pairs, the two methods only had 3 overlapping results.
  }
\label{fig:non-overlap}
\end{figure}

Although both LSS and LSA detected context dependent functional connectivity differences;
the significant ROI-ROI pairs found with LSS are largely non-overlapping with LSA (Figure~\ref{fig:non-overlap}).

\section{Discussion}
\label{discussion}

We provide here the first in-depth comparison between LSS and LSA to detect 
ROI-ROI correlation differences between conditions.
We compared LSA and LSS through realistic simulations and a participant data-set.
While the simulations suggested LSS is a more powerful method,
the results from the participant data do not show whether LSS or LSA is the more powerful method.
We detail the conclusions from the simulations and the participant data and provide
suggestions for future avenues of research.

\subsection{Simulation Conclusions}
\label{discussion:simulation-conclusions}

The main finding from the simulations is that LSS has greater detection power than LSA,
supporting other findings from the literature comparing LSS and LSA using related analyses such as
multivariate pattern analysis, representational similarity analysis, and precision of correlations~\cite{Mumford2012,Mumford2014a,Abdulrahman2016,Turner2012a}.
While we cannot control AVNR and CNR in our experiments, we can control the experimental design.
Thus we can offer several suggestions concerning experimental design based on our simulations.
Increasing the average IEI up to 6 seconds improves detection power between conditions substantially,
but increasing the average IEI beyond 6 seconds offers only a modest improvement in detection power.
Increasing the number of events per condition to 30 offers the largest benefit in detection power,
mirroring previous findings regarding the number of trials needed to detect brain activation~\cite{Huettel2001}.
It is important to note these recommendations are based on optimized designs made with neurodesign,
and may not generalize to completely random designs.

Abdulrahman \& Henson's (2016) work also varied IEIs, AVNRs, and noise coherency between voxels
revealing several key intersections with the present paper.
Increasing the IEI beyond 6 seconds did not improve their measure, precision of sample correlation.
Precision of sample correlation measures how accurate the estimated correlation is to the true
simulated correlation.
If the error of the observed correlation is evenly distributed around the
true correlation, then precision of sample correlations would closely mirror our measure of
significant correlation differences between event conditions (e.g., $repeat - single$).
However, if there was a systematic bias in the observed correlations, then precision of sample correlation
would be low, but the correlation difference between event conditions could still be high.
For example, if the true correlations were 0.2 for condition $A$ and 0.3 for condition $B$, but
the observed correlations were 0.1 and 0.2, respectively, then precision of sample correlations would
decrease, but the difference between conditions remains the same.

Another conclusion from Abdulrahman \& Henson's (2016) paper suggested using
LSA when event variability is greater than scan noise (AVNR $>$ 1) for short IEIs (2-5 seconds).
All of our simulations set AVNR greater than or equal to scan noise (AVNR $>=$ 1) and we saw
LSS significantly outperformed LSA for our measure of detection power with IEIs greater than 2 seconds.
Theoretically when AVNR is 1, LSS and LSA would perform similarly, but in our simulations,
LSS still had more power to detect a difference between conditions.
The difference in conclusions may be due to our different measures (i.e., precision of sample correlations versus condition difference)
or simulation methods (i.e., Gaussian noise with random designs versus autocorrelated noise with optimized designs).

Signal and noise coherency did not impact results as they did in the work of Abdulrahman \& Henson (2016)~\cite{Abdulrahman2016}.
When scan noise is more coherent across voxels than event variability,
their work states LSA should perform better than LSS.
However, their paper only investigated perfect coherency or no coherency.
In the present simulations, beta series "coherence" was varied between 0.0 and 0.9 Pearson's R correlation,
and the scan noise coherency remained around 0.67 Pearson's R correlation.
For the majority of our simulations, scan noise coherency was greater than beta series
coherence, yet LSS was better at detecting differences between conditions.
It may be the case scan noise must be identical or near identical between voxels
for LSA to perform better than LSS.

The current simulations have improved on previous work by incorporating a more
realistic noise structure using fmrisim and used CNR/AVNR values calculated with participant data.
However, the simulations we performed differ from participant data in several key areas:
the contrasts between event conditions,
variation in BOLD response onset, and preprocessing of the signal.
As mentioned in \nameref{methods:bsc-simulations}, each simulation represents
either a different participant or separate runs from the same participant.
The $task$ and $null$ conditions come from the task switching task and resting state,
respectively, representing two runs.
The contrasts in the simulations are therefore most analogous to the $task - null$
contrast illustrated in Figure~\ref{fig:main-result}.
Additionally, each simulation contains two conditions whose BOLD responses
are independent of each other, that is, the BOLD response for one event
does not influence the BOLD response for a subsequent event.
There is likely temporal autocorrelation of BOLD responses across events,
which is not represented in our simulations~\cite{Abdulrahman2016}.

We also did not simulate variations in BOLD response onset, which is likely to occur
as all BOLD responses to a stimulus do not occur at the time of stimulus onset~\cite{DEsposito2003}.
Model mismatch through variations is detrimental to beta estimation, 
but there is no reason to believe that LSA would be differently impacted relative to LSS~\cite{Turner2012a}.
Future work could investigate variable BOLD responses and include derivatives for each regressor to account for
the variable BOLD responses.
Including derivatives could make LSA unsolvable as every event would have at least two regressors, necessitating
more than twice the volumes than events collected during the BOLD run
for the GLM to be solvable.

While the simulations represented data without any preprocessing applied,
the participant data had several variables included in the model: motion outliers, non-steady state volumes,
CSF, and white matter signals.
The additional regressors in the model reduce the degrees of freedom
and could impact the ability of the model to fit the data.
This would likely impact LSA more than LSS, since LSA already contains
a large number of regressors representing each event.

Future work could use fmrisim to simulate entire brains which could be preprocessed using fmriprep,
making the processing pipeline more similar between participant data and simulations.

\subsection{Participant Data Conclusions}
\label{discussion:taskswitching-conclusions}

The analysis of the participant data suggests LSS and LSA perform similarly.
Based on the number of statistically significantly different ROI-ROI pair correlations alone,
LSS and LSA cannot be easily distinguished.
Overall, we have evidence that LSA and LSS can detect differences between
blocks of events ($task - null$, $dual - single$, $repeat - single$), but not an event-related contrast ($switch - repeat$).
This suggests our sample of 40 older adults may not have been large enough to detect a reliable event-related effect,
which should caution researchers to perform power analyses to determine an adequate sample size.
% false positives?
Contrary to the simulations where LSS was found to be more powerful,
for both the activation atlas and the SchaeferTop20 atlas LSS and LSA performed similarly.
LSA was prone to a higher rate of false positives as determined by the analyses performed on the null data within the SchaeferTop20 atlas.
However, LSS appeared to have a greater magnitude of false positives than LSA when using the entire Schaefer atlas.
Furthermore, there is some evidence of LSS having fewer statistically significant ROI-ROI pairs than expected through chance alone
for the contrast $switch - repeat$.
This pattern can be seen for both the real and null data, suggesting there is a property inherent to LSS
leading to this pattern.
Since the beta estimates calculated by LSS are not orthogonal to adjacent events,
the ROI-ROI beta series correlation for one condition is influenced by the other interleaved condition,
resulting in a greater difficulty to detect differences between conditions.
This is likely the source of the poor performance of LSS in event-related contrasts.

Surprisingly, LSA and LSS results did not have much overlap between significant
ROI-ROI pair correlation differences between conditions.
The lack of overlap is surprising because both LSS and LSA are purported to
measure the same underlying process of task related connectivity.
To investigate their differences further, we correlated the beta series of LSA with LSS and plotted their relationship with
average framewise displacement and temporal signal to noise (TSNR) for all participants ($N$=61) (Figure~\ref{fig:lss_lsa_correlation}).
As the average framewise displacement increases and temporal signal to noise (TSNR)
decreases, the agreement between LSS and LSA decreases.
In other words, as noise in the data increases, the more divergent LSS and LSA become.
This suggests one reason for the disagreement is the noise present in the included
data.
There appears to be a cluster of participants with an average framewise displacement of
less than 0.2mm that have a high correlation between LSS and LSA.
The simulation results would suggest when LSS and LSA disagree, the estimate for LSS should be
trusted, but since we observed a significant number of condition modulated ROI-ROI pair correlations for both
LSS and LSA, it is difficult to say whether LSA or LSS would be "correct".

\begin{figure}[H]
  \centering
  \includegraphics{lss_lsa_noise_relationship}
  \caption[LSS/LSA noise correlation]{
    The average correlation between LSA/LSS beta series across
    all ROIs in the activation atlas.
    Orange dots represent 21 participants that were not included
    in the original analysis and blue dots are the 40
    participants that were included.
    The size of the dots represent the temporal signal to noise
    ratio (TSNR), higher is better.
    The general pattern shows good correspondence between LSA and LSS
    when the average framewise displacement is low and TSNR is high.
  }
  \label{fig:lss_lsa_correlation}
\end{figure}

Another interesting aspect of our analysis of the participant data was the inclusion of
null (resting state) data where the participants simply stared at a fixation cross.
Using the null data we were able to dissociate the performance of LSS and LSA using the
SchaeferTop20 atlas because LSA showed many more false positives
relative to LSS (Figure~\ref{fig:null-schaeferbest}).
It could be argued the resting state data does not provide an adequate null model
to compare to the real task data because there is presumably no BOLD response at any
of the onset times.
Trying to model the BOLD response with no expectation of a BOLD response existing could lead
to large misfits and deviating beta estimates.
To test this, we evaluated average CNR and AVNR within the Schaefer and activation atlases in
the null data and compared it to the CNR and AVNR in the real data.
If the null data had much larger deviations in beta estimates, CNR and AVNR would be higher
in the null data relative to the real data.
For both LSS and LSA, the Schaefer atlas had statistically significantly higher
CNR/AVNR in the null data relative to the real data, whereas the activation atlas
did not show a statistically significant difference between null and real data (Table~\ref{table2}).

\begin{table}[H]
  \centering
  \caption[CNR/AVNR in real data]{
  {\bf Differences in CNR/AVNR between real and null data}}
  \begin{tabular}{|l+l+l|l|l|l|}
  \hline
  Atlas & Method & CNR (t-value) & CNR (p-value) & AVNR (t-value) & AVNR (p-value)\\
  $Schaefer$ & $LSS$ & 3.163 & \textbf{0.003} & 3.659 & \textbf{0.001}\\ \hline
  $Activation$ & $LSS$ & 0.105 & 0.917 & 1.528 & 0.134\\ \hline
  $Schaefer$ & $LSA$ & 2.740 & \textbf{0.009} & 2.893 & \textbf{0.006}\\ \hline
  $Activation$ & $LSA$ & 0.306 & 0.761 & 0.927 & 0.360\\ \hline
  \end{tabular}
  A t-test comparing average CNR/AVNR across all ROIs between real data and null data.
  A statistically significant p-value ($p < 0.05$) suggests the CNR/AVNR value in the real data
  is different from the null data.
  Only CNR/AVNR from the Schaefer atlas shows statistically significant results.
  \label{table2}
\end{table}

The table suggests model misfit may be a driving factor for spurious results in the Schaefer atlas(Table~\ref{table2}).
We protected against extreme beta estimates by detecting and removing outliers, but model misfit
could still drive spurious results.
A proper null model would have BOLD responses at the onset times, but the bold responses
would be the same amplitude at every event such that the only deviance in the simulated
BOLD responses would come from the underlying resting state fluctuations.

All of these insights are tempered from the full Schaefer atlas, which showed mostly a similar pattern,
but several key differences as well~\ref{fig:significant-contrasts6}.
While LSS maintained the expected number of false positives for the motivated selection of
ROIs for the activation and SchaeferTop20 atlases, LSS's percentage of false positives is
higher than LSA when using the full Schaefer atlas.
PPI's false positive percentage remained the highest in the full Schaefer atlas.
This could indicate a relative advantage in specificity for LSA when CNR is low.
Previous work indicates LSA would outperform LSS when CNR is greater than 1,
and when scan noise is more consistent across voxels than the beta series estimates~\cite{Abdulrahman2016}.
Our results in the Schaefer atlas contradict the first statement since the average CNR in the Schaefer atlas
is at or below 1 (Table~\ref{table1}), suggesting LSS should have the advantage.
Scan noise may be more correlated between brain areas than the beta series correlations, but this is unlikely
since motion artifacts and large uniform changes in the signal were censored during the beta series modeling steps.
The reason for these discrepancies could be due to the differences in outcome measures used in previous work and
this thesis.
Namely, for the first point, they used the precision of correlation metric, with which the precision
of the correlation is orthogonal to the ability to detect a difference between two correlations.
The second point used classification performance, which was determined by the mean amplitude difference
between voxels, but not the correlation between two voxels.

\subsection{Future Directions}

There are several immediate next steps that could be taken to provide a more concrete answer
on when one should use LSA or LSS when looking at ROI-ROI pair correlation differences between event
conditions.

With the publicly available NiBetaSeries package, researchers could replicate the
results on their own data using the same methods in this paper.
Furthermore, there are several analytical choices that could be varied using NiBetaSeries such as:
using a t-statistic instead of a raw beta estimate, including derivatives of the hemodynamic response function,
and performing a spatial-temporal analysis using finite impulse responses.
The benefit of using a t-statistic is the added stability of the estimates.
The t-statistic will divide outlier beta estimates by their uncertainty giving more stability
towards the beta series estimates.
Since LSA is more likely to produce high variance beta estimates, using a t-statistic would likely impact
how well LSA performs.
No other tool can calculate the t-statistic instead of the raw beta estimate to the knowledge
of the authors.
Another straight-forward addition would be adding temporal and/or dispersion derivatives to each beta
estimate to account for potential BOLD response delays~\cite{Calhoun2004,Gottlich2015}.
This strategy may work well for populations with variable BOLD responses or when the onset of the BOLD
response is not precisely known.
Including derivatives would also likely impact LSA more than LSS since there would be either twice or
three times the number of regressors included in the LSA model, which in a fast event-related design
would heavily impact the degrees of freedom in the model.
Finally, a more complex but potentially fruitful option is to use the finite impulse response model.
Finite impulse responses allow the researcher to observe both the spatial and temporal pattern of
condition specific correlations without imposing an expected shape of the hemodynamic response~\cite{Turner2012a}.
For example, the researcher could be able to determine the relationship between 2 event conditions
2, 4, 6, and 8 seconds post stimulus, and identify how that relationship changes across
that time frame.
The finite impulse response model can only be estimated using LSS, giving LSS the advantage if researchers
want to perform this type of analysis.

Network measures of brain organization are becoming widely adopted~\cite{Rubinov2010}.
Network measures offer a perspective on the multidimensional organization of ROI-ROI pairs, instead of
interrogating individual ROI-ROI pairs as we did in the present work.
Previous work has found greater global efficiency, smaller mean clustering coefficients, and lower modularity in
task relative to rest~\cite{Di2013}.
However, this finding has not been replicated using beta series correlations and has just begun
to be investigated between tasks and event conditions within a task~\cite{Di2019a}.
The largely non-overlapping results from LSS and LSA suggest that LSS and LSA may differ
in their network measures as well.

\section{Conclusion}

Overall, our work leads to four main conclusions:
1) simulations suggest increasing average IEI to 6 seconds and the number of events to 30 per condition will detect a difference between conditions, 
2) simulations suggest LSS has more power than LSA to detect differences between conditions (between blocks),
3) participant data suggests LSS and LSA perform comparably but results are dependent on which atlas is selected,
4) LSA may have a slight advantage for event-related contrasts,
but it is difficult for both LSS and LSA to detect condition differences when events are interleaved instead of occurring in separate blocks.
This work guides and cautions cognitive neuroscience researchers as they design their tasks and decide
which analysis path they should take amid the forking paths of researcher degrees of freedom.

\section{Supporting Information}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{avnr-1_fpr}}

  \subfloat{\includegraphics[width=\textwidth]{avnr-2_fpr}}

  \caption[Simulations of false positive rate for LSS/LSA]{
    LSA/LSS both show a \%5 false positive rate for all conditions.
    Each bar represents a sample of 50 pairs of correlations (with no true difference)
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:res_sim_fpr}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-both_type-brain_atlas-activation_contrast-taskXnull}}

  \subfloat{\includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-dualXsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-repeatXsingle}}

  \caption[All contrasts for all atlases for all data...]{
   The statistically significant ROI-ROI pairs in the activation atlas for the contrasts $task - null$, $dual - single$,
   and $repeat - single$ in the real data.
   The glass brains show the anatomical locations of each ROI,
   labeled with its identifying number.
   The edges between ROIs represent significant correlation differences
   between conditions for LSA (blue), LSS (orange), or both (pink).
   The contrast $task - null$ has 25 statistically significant ROI-ROI
   pairs for LSA, 27 statistically significant ROI-ROI pairs
   for LSS with 10 overlapping ROI-ROI pairs for both LSS and LSA.
   The contrast $dual - single$ has 9 statistically significant ROI-ROI
   pairs for LSA, 19 statistically significant ROI-ROI pairs
   for LSS with 2 overlapping ROI-ROI pairs for both LSS and LSA.
   The contrast $repeat - single$ has 21 statistically significant ROI-ROI
   pairs for LSA, 16 statistically significant ROI-ROI pairs
   for LSS with 3 overlapping ROI-ROI pairs for both LSS and LSA.
  }
  \label{fig:significant-contrasts1}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-switchxrepeat}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-dualXsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatXsingle}}

  \caption[All contrasts for all atlases for all data continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas for the contrasts
      $switch - repeat$ in the real data, and the contrasts $dual - single$ and $repeat - single$
      in the null data.
      The contrast $switch - repeat$ has 15 statistically significant ROI-ROI
      pairs for LSA, 6 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
      The contrast $dual - single$ has 14 statistically significant ROI-ROI
      pairs for LSA, 11 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $repeat - single$ has 10 statistically significant ROI-ROI
      pairs for LSA, 12 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
  }
  \label{fig:significant-contrasts2}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-switchxrepeat}}

  \subfloat{\includegraphics[width=\textwidth]{data-both_type-brain_atlas-schaeferbest_contrast-taskXnull}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle}}

  \caption[All contrasts for all atlases for all data continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas for the contrasts
      $switch - repeat$ in the null data and the SchaeferTop20 atlas
      contrasts $task - null$ and $dual - single$ in the real data.
      The contrast $switch - repeat$ has 12 statistically significant ROI-ROI
      pairs for LSA, 3 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
      The contrast $task - null$ has 40 statistically significant ROI-ROI
      pairs for LSA, 28 statistically significant ROI-ROI pairs
      for LSS with 17 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $dual - single$ has 24 statistically significant ROI-ROI
      pairs for LSA, 16 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
  }
  \label{fig:significant-contrasts3}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle}}

  \caption[All contrasts for all atlases for all data continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the contrasts $repeat - single$ and $switch - repeat$ in the real data and
      the contrast $dual - single$ in the null data.
      The contrast $repeat - single$ has 24 statistically significant ROI-ROI
      pairs for LSA, 21 statistically significant ROI-ROI pairs
      for LSS with 3 overlapping ROI-ROI pair for both LSS and LSA.
      The contrast $switch - repeat$ has 8 statistically significant ROI-ROI
      pairs for LSA, 8 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $dual - single$ has 17 statistically significant ROI-ROI
      pairs for LSA, 7 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
  }
  \label{fig:significant-contrasts4}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-switchxrepeat}}

  \caption[All contrasts for all atlases for all data continued...]{
      The statistically significant ROI-ROI pairs in the top SchaeferTop20 atlas
      for the contrasts $repeat - single$ and $switch - repeat$ in the null data.
      The contrast $repeat - single$ has 24 statistically significant ROI-ROI
      pairs for LSA, 9 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $switch - repeat$ has 30 statistically significant ROI-ROI
      pairs for LSA, 6 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
  }
  \label{fig:significant-contrasts5}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=0.7\textwidth]{data-real_atlas-schaefer_participants-filtered_permutation_summary}}

  \subfloat{\includegraphics[width=0.7\textwidth]{data-null_atlas-schaefer_participants-filtered_permutation_summary}}

  \caption[LSS/LSA comparison using real data in the full Schaefer atlas]{
      The overall results for the full Schaefer Atlas.
      Since there were 79800 unique ROI-ROI pairs, it became more likely
      to see unexpected results.
      Looking at magnitudes alone, LSS appears to have a slightly
      higher false positive rate than LSA in the null data, and 
      LSA has a slight sensitivity advantage in the real data, 
      except for the $task - null$ contrast.
  }
  \label{fig:significant-contrasts6}
\end{figure}

%=============================================================================
\chapter{PPI versus BSC}
%=============================================================================

While BSC was originally created to detect context-dependent functional connectivity
differences in 2004, there was another method
that preceded BSC in 1997 named psychophysiological
interaction (PPI) analysis ~\cite{Friston1997}. 
PPI analyses are designed to identify brain areas that are differently functionally connected
during specific contexts relative to other contexts.
If this sounds like the same goal as BSC, you would be correct, although PPI
analyses take a different approach.
There are three necessary components to any PPI.
The first is the psychological variable of interest, such as when a participant
either needs to read a word or nonword.
The second is the physiological variable, such as the BOLD signal from
the motor cortex.
The third variable is the PPI itself, which represents a multiplication
between the psychological variable (e.g., word)
and the physiological variable (e.g., motor cortex BOLD signal).
If our dependent variable is the BOLD signal in the medial frontal gyrus,
then we can answer the question if the motor cortex and medial frontal gyrus
are differently functionally connected during word reading events relative
to nonword reading events, potentially isolating the process of
lexical processing.

PPI analyses have undergone several innovations since their inception in 1997 including:
1) deconvolution~\cite{Gitelman2003}, 2) including three or more 
psychological variables~\cite{McLaren2012}, and 3) correcting 
imperfect deconvolution~\cite{Di2017}.
I will cover each of these innovations in turn.

The necessity of deconvolution was investigated by Gitelman~\cite{Gitelman2003} who demonstrated
that calculating a PPI at the BOLD level is not mathematically equivalent to calculating
a PPI at the neural level.
I will cover why after setting up some context.
The BOLD signal is the result of an underlying neural response convolved (i.e., smeared)
with a hemodynamic response function (HRF)(Equation~\ref{eq:intro_conv_bold}).
\begin{equation}
  BOLD = HRF \circledast neural
  \label{eq:intro_conv_bold}
\end{equation}
Thus to calculate a PPI, there are two options:
1) deconvolve the BOLD signal to represent the neural signal
(right hand side of equation~\ref{eq:intro_conv_bold}) or
2) convolve the psychological variable with an HRF to represent BOLD signal
(left hand side of equation~\ref{eq:intro_conv_psych}),
\begin{equation}
  PSYCH_{BOLD} = HRF \circledast psych
  \label{eq:intro_conv_psych}
\end{equation}
Brain-behavior interactions occur at the neural level
(right hand side of equation~\ref{eq:neq_conv}), not at the
BOLD response level (left hand side of equation~\ref{eq:neq_conv}).
Importantly, calculating the interaction at the BOLD level is not
equivalent to calculating the interaction at the neural level~\cite{Gitelman2003}.
\begin{equation}
  (HRF \circledast neural) \cdot (HRF \circledast psych) \neq HRF \circledast (neural \cdot psych)
  \label{eq:neq_conv}
\end{equation}
While convolution is distributive with scalar multiplication (Equation~\ref{eq:conv_distributive}) and
\begin{equation}
  (HRF \circledast neural) \cdot 2 = (HRF \circledast neural \cdot 2) 
  \label{eq:conv_distributive}
\end{equation}
the cross product of the $neural$ and $psych$ vectors is distributive (Equation~\ref{eq:cross_product}),
\begin{equation}
  neural * psych = psych * neural
  \label{eq:cross_product}
\end{equation}
convolution is not distributive over vector cross products (Equation~\ref{eq:neq_conv}).
Since convolution is related to the integral,
we demonstrate the inequality with a small example in
equations~\ref{eq:familiar_int} and~\ref{eq:familiar_int2}.
\begin{equation}
  x \cdot \int 2x = x \cdot x^2 = x^3
  \label{eq:familiar_int}
\end{equation}
\begin{equation}
   \int 2x \cdot x = \int 2x^2 = 2x^3 / 3
  \label{eq:familiar_int2}
\end{equation}
Thus the inequity of calculating the PPI at the BOLD level versus
the neural level coupled with the fact the interaction of interest
occurs at the neural level motivates the
need to deconvolve the BOLD signal (option 1).
Deconvolution of the BOLD signal is not a well defined problem since
we do not know the exact neural process that gave rise to the BOLD signal.
Therefore we have to rely on regularized regression with an over-complete
basis set.
Over-complete meaning there are more columns (the basis set) than there
are rows (the BOLD signal).
In other words, there are more predictors than there are samples.
Since the BOLD signal is noisy and the assumed hemodynamic response function
may not match the data, some software packages simply do not attempt
deconvolution and swallow the error from multiplying the physiological and psychological
variables at the BOLD level.
Other software packages attempt deconvolution through a variant of
regularized regression.
In block designs where contexts are not intermixed the difference between
deconvolving or not appears inconsequential, but with rapid event-related designs,
deconvolution is essential to separate the influence of intermixed contexts.
The implementation used in this thesis work performs deconvolution.

The second innovation of PPI analyses came from McLaren et al. (2012)~\cite{McLaren2012}.
Their goal was to properly represent experiments with more than two experimental conditions, like
in task switching, where there are three event conditions of interest:
$Switch$, $Repeat$, and $Single$.
Traditionally, the psychological variable used to calculate a PPI
was a contrast between two event conditions, such as
$Switch - Repeat$.
McLaren et al. (2012) suggested an alternative strategy where researchers could
calculate a separate PPI for each psychological variable independently and then
perform contrasts between the $\beta$ estimates for the PPIs
to find differences in context-dependent functional connectivity.
This method is known as generalized PPI (gPPI) analysis.
The implementation used in this thesis work performs gPPI.

The third innovation of PPI analyses to date involves a peculiarity from the combination of
deconvolution and not centering the psychological variable when computing a PPI~\cite{Di2017}.
To conceptually understand this process we need to accept that deconvolution is imperfect, and if I
deconvolved and reconvolved the physiological BOLD signal,
I would not get the same BOLD signal (Equation~\ref{eq:decon_recon}).

\begin{equation}
  \begin{aligned}
    BOLD \circledast^{-1} HRF = neural \\
    neural \circledast HRF = BOLD_{reconvolved} \\
    BOLD_{reconvolved} \neq BOLD
  \end{aligned}
 \label{eq:decon_recon}
\end{equation}

Additionally, we need to accept that a non-centered variable ($psych^*$)
is a centered variable plus a constant ($psych + c$) (Equation~\ref{eq:pysch_center}).

\begin{equation}
  psych^* = psych + c
 \label{eq:pysch_center}
\end{equation}

Thus, if we deconvolve the physiological BOLD signal and multiply the deconvolved
BOLD signal ($neural$) with a centered psychological variable and a constant
($psych + c$), we have the neural PPI ($psych \cdot neural$)
as well as scaled multiple of the physiological deconvolved BOLD signal
($c \cdot neural$) (Equation~\ref{eq:ppi_bad}).

\begin{equation}
  \begin{aligned}
    PPI^* = (psych^* \cdot neural) \circledast HRF \\
    = [(psych + c) \cdot neural] \circledast HRF \\
    = (psych \cdot neural) \circledast HRF + (c \cdot neural) \circledast HRF \\
    = PPI + (c \cdot BOLD_{reconvolved}) \\
  \end{aligned}
 \label{eq:ppi_bad}
\end{equation}

When we reconvolve the neural PPI (and the implicit scaled neural signal included in the PPI),
we have the PPI we want and a deconvolved/reconvolved physiological BOLD signal that is not equivalent to the
original physiological BOLD signal (Equation~\ref{eq:decon_recon}).
Even if we include the original $BOLD$ signal in the model, it will not fully account for the 
$BOLD_{reconvolved}$ component since the reconvolved BOLD signal is not equivalent to
the original BOLD signal.
It turns out the unique variance of $BOLD_{reconvolved}$ still resembles the original BOLD signal
meaning the $PPI^*$ term also measures the baseline correlation between the BOLD signal in the model
and the BOLD signal we are predicting.
If we do not use deconvolution, then the original $BOLD$ signal included in the model fully accounts
for the $BOLD$ signal also included in the $PPI^*$ term.
Thus to create correct PPIs using deconvolution, the psychological variables must be centered.

BSC methods and PPI analyses have been compared previously~\cite{Cisler2012,Di2019}.
Cisler et al. (2012) found BSC to be more powerful in event-related designs
and PPI analyses to be more powerful in block designs, whereas Di et al. (2019)
found PPI analyses to be more powerful in both block and event-related designs,
thus it remains an open question whether PPI is more powerful in
event-related designs.
Additionally, previous work only used the LSS implementation of BSC.
Since LSA and LSS have largely non-overlapping results, it will be informative
to identify which BSC method is most correlated with PPI analysis.
Finally, previous work used different quantitative measures
(i.e., number of detected clusters from a seed region analysis)
and did not include null data to compare their results against, so it is
difficult to test if false positives drove the
conclusion in previous work comparing LSA/LSS/PPI.

To expand on previous work by including a null data and
including both LSA and LSS, in this chapter we ask:
1) whether BSC methods or PPI analyses are more sensitive,
2) whether BSC methods or PPI analyses are more specific, and
3) which BSC method correlates most with PPI analysis.

\section{Materials and Methods}

\subsection{Participant Data}
\label{methods:task-switch2}

We used an unpublished data-set
of older adults ($N$=61, 31 female,\newline
age=71.75$\pm$4.77, education=17.07$\pm$2.66)
performing a mixed design task switching task.
Numbers reported are mean$\pm$standard deviation.
Before any experimentation, participants provided verbal and written consent
to participate in the research presented in this manuscript, which was approved
by the University of Iowa's Institutional Review Board.
N=21 participants were excluded in the primary analysis for having over
0.5mm of total movement (framewise displacement) in 100 volumes or more,
resulting in a final $N$ of 40.
We chose 100 volumes to keep the number of regressors in LSA
(which already includes as many regressors as events) a reasonable size
for single event beta estimation since we included each outlier volume
as a regressor as well.
Task switching was performed in a mixed block/event-related design containing
5 blocks (2 single task blocks and 3 dual task blocks).
There was a 30 second rest between each block.
There were 30 events during each single event block,
and for the 3 dual blocks there were 48 repeat events and 39 switch events total.
The single tasks consisted of identifying a number between
1 and 10 (excluding 5) as high/low or odd/even, using their left and right index fingers
on a fiber optic response pad.
Participants were cued to which task they were performing by the color of the square
the number was presented on (blue or pink).
Each stimulus was presented for 1.5 seconds, and participants were allowed
to respond within 2.0 seconds of stimulus onset.
The average IEI was 3.5 seconds following an exponential distribution.
All stimuli were presented using E-Prime.
Participants practiced an abridged version of this task in a mock scanner
before the real scan and had 4 practice events in the real scanner immediately
before performing the task to ensure proper finger placement and data acquisition.

Participants' average accuracy and reaction time were:
single, (92\%$\pm$27\%, 792ms$\pm$225ms); repeat, (89\%$\pm$31\%, 1001ms$\pm$278ms);
and switch, (83\%$\pm$36.8\%,\newline
1108ms$\pm$289ms).
Due to data collection error, behavioral data were not collected for 3 participants
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/summarizeBehavior/summarize_behavior.ipynb}{see here for relevant code})

The task switch bold \emph{fmriprep} output in MNI152NLin2009cAsym space
was analyzed with \emph{Nistats} for first and second level analyses.
We used mean white matter signal, mean cerebrospinal fluid signal,
discrete cosine basis filter (high pass filter), framewise displacement, the first four non-steady volumes, and
all identified motion outliers as regressors in the first level model for each participant
in addition to event onsets convolved with a double gamma function~\cite{Glover1999}.
Each image was smoothed with a 6mm full-wide half-max kernel.
We derived 3 contrasts of interest: $switch - repeat$, $dual- single$, and $repeat - single$.
The $dual$ condition is the weighted average of $switch$ and $repeat$ to represent the
dual cost (the cost of performing two tasks at once relative to one)~\cite{Wylie2000,Verhaeghen2003}.
We ignored the correctness of the participant's response since it was not essential to
separate condition and error processing to compare BSC with PPI.

Second level analyses were a summary of the first level results presenting which
regions were robustly activated among participants.
For each contrast, the alpha was set to 0.01 with a cluster threshold of 10 voxels using
false discovery rate error control (Figure~\ref{fig:stat_maps}).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth,height=0.8\paperheight,keepaspectratio]{contrast_summary}
  \caption[Univariate statistical maps]{
    Univariate statistical maps of second level results representing
    all contrasts of interest, $dual - single$, $repeat - single$, $switch - repeat$}
  \label{fig:stat_maps2}
\end{figure}

In addition to the task switching task, participants also completed
two 8 minute resting state runs.
We used the resting state runs as a null model for task switching as done
in other reports validating analyses~\cite{Eklund2016,Olszowy2019}.
While the task switch data had 471 volumes, each resting state run only had
240 volumes.
To match the length of the resting state data with the task data, we concatenated
the two resting state runs while cutting off the first 10 volumes of the second run
and interpolating 1 volume between the two runs, resulting in 471 volumes.
The interpolation helps transition the bold series from one run to the next,
analogous to interpolation performed when scrubbing high motion volumes~\cite{Power2014a}. 
The null task data were treated equivalently to the task switching data for the
beta series correlation analysis.
(\href{https://github.com/jdkent/validateBetaSeries/tree/195ad5b4201971038dbbf8f73a3c537caf032743}{see relevant code here})

\subsection{Scanner Parameters}
\label{methods:scanner2}

MRI data were collected on a 3T GE Discovery 750w using a 32 channel head coil.
The anatomical T1w images were collected using a SPoiled Gradient-Recalled (SPGR) sequence
sagittally with a flip angle of 8$^{\circ}$, echo time of 3.168ms,
repetition time of 8.388ms, inversion time of 900ms, isometric voxel sizes of 1mm,
[256x256] acquisition matrix with 196 slices, field of view 25.6cm x 25.6cm.
The functional bold images were collected using a Gradient Echo sequence axially from
the bottom up sequentially with a flip angle of 80$^{\circ}$, echo time of 30ms,
repetition time of 2000ms, voxel sizes of 3.44x3.44x4.00mm on a [64x64] acquisition matrix
with 37 slices, field of view 22cm x 22cm.

\subsection{Preparing fMRI}
\label{methods:fmriprep2}

Results included in this manuscript come from preprocessing performed
using \emph{fMRIPrep} 1.5.7 (\cite{fmriprep1}; \cite{fmriprep2}; RRID:SCR\_016216),
which is based on \emph{Nipype} 1.4.0
(\cite{nipype1}; \cite{nipype2}; RRID:SCR\_002502).


\subsubsection{Anatomical data preprocessing}
\label{methods:anat2}

The T1-weighted (T1w) image was corrected for intensity non-uniformity
(INU) with \texttt{N4BiasFieldCorrection} \cite{n4}, distributed with
ANTs 2.2.0 \cite[RRID:SCR\_004757]{ants}, and used as T1w-reference
throughout the workflow.
The T1w-reference was then skull-stripped with a \emph{Nipype} implementation
of the \texttt{antsBrainExtraction.sh} workflow (from ANTs), using OASIS30ANTs
as a target template.
Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and
gray-matter (GM) was performed on the brain-extracted T1w using
\texttt{fast} \cite{fsl_fast} [FSL 5.0.9, RRID:SCR\_002823,][].
Brain surfaces were reconstructed using \texttt{recon-all} \cite{fs_reconall},
[FreeSurfer 6.0.1, RRID:SCR\_001847,][] and the brain mask estimated
previously was refined with a custom variation of the method to
reconcile ANTs-derived and FreeSurfer-derived segmentations of the
cortical gray-matter of Mindboggle \cite[RRID:SCR\_002438,]{mindboggle}.
Volume-based spatial normalization to standard space (MNI152NLin2009cAsym)
was performed through nonlinear registration with \texttt{antsRegistration}
(ANTs 2.2.0), using brain-extracted versions of both T1w reference and the T1w template.
The following templates were selected for spatial normalization: \emph{ICBM 152 Nonlinear
Asymmetrical template version 2009c} {[}\cite{mni152nlin2009casym},
RRID:SCR\_008796; TemplateFlow ID: MNI152NLin2009cAsym{]}.

\subsubsection{Functional data preprocessing}
\label{methods:func2}

For each of the two BOLD runs (task switch and null data) per subject,
the following preprocessing was performed.
First, a reference volume and its skull-stripped version were generated
using a custom methodology of \emph{fMRIPrep}.
Susceptibility distortion correction (SDC) was omitted.
The BOLD reference was then co-registered to the T1w reference using \texttt{bbregister}
(FreeSurfer) which implements boundary-based registration \cite{bbr}.
Co-registration was configured with 6 degrees of freedom.
Head-motion parameters with respect to the BOLD reference (transformation matrices,
and 6 corresponding rotation and translation parameters) are estimated before any
spatiotemporal filtering using \texttt{mcflirt} \cite[FSL 5.0.9,]{mcflirt}.
The BOLD time-series were resampled into a standard space, correspondingly
generating the following \emph{spatially-normalized, preprocessed BOLD runs}:
MNI152NLin2009cAsym.
Several confounding time-series were calculated based on the \emph{preprocessed BOLD}:
% only used a subset of the confounding variables
framewise displacement and two region-wise global signals.
framewise displacement was calculated for each functional run, using its
implementation in \emph{Nipype} following the definitions
by Power et al. (2014)\cite{power_fd_dvars}.
The two global signals were extracted within the
cerebrospinal fluid and the white matter masks.
High-pass filtering of the \emph{preprocessed BOLD} time-series was done using
a discrete cosine filter with 128s cut-off.
The head-motion estimates calculated in
the correction step were also placed within the corresponding confounds file. 
Frames that exceeded a threshold of 0.5 mm framewise displacement or 1.5 standardized DVARS
were annotated as motion outliers.
An additional 4 frames at the beginning of each run were also
annotated as outliers to allow the magnet to reach equilibrium.

All resamplings were performed with \emph{a single interpolation step} by composing all the pertinent
transformations (i.e.~head-motion transform matrices, co-registrations to anatomical
and output spaces).
Gridded (volumetric) resamplings were performed using \texttt{antsApplyTransforms} (ANTs),
configured with Lanczos interpolation to minimize the smoothing effects of other kernels
\cite{lanczos}.

\subsection{Beta Series Modeling}
\label{methods:bsc_model2}

The LSS models were generated for each event in
the task following the method described in \cite[Turner (2012)]{Turner2012a}, using
Nistats 0.0.1b2.\\
Before modeling, preprocessed data were masked, and mean-scaled over
time.
Mean scaling was not applied when calculating CNR and AVNR so the
beta estimates would be in the original BOLD units.
For each event, preprocessed data were subjected to a GLM
in which the event was modeled with its own regressor, while
all other events from that condition were modeled in a second regressor,
and other conditions were modeled in their own regressors.
So if the task has 3 conditions, 
a single GLM would have 4 event regressors, 1 for the target
event, and 3 for the remaining conditions.

The LSA model was generated following the method described in
\cite[Rissman (2004)]{Rissman2004}, using Nistats 0.0.1b2.
Each event was given its own regressor in a single GLM, such that
if the experiment had 100 events, there would be 100 regressors in the GLM.

Each event regressor was convolved with a Glover hemodynamic response
function~\cite{Glover1999}.
In addition to event regressors, average white matter signal, average CSF signal,
cosine basis set high pass regressors, the initial four non steady-state volumes, 
and motion outliers were included
in the model as calculated in \nameref{methods:func}.
AR(1) prewhitening was applied in each model to account
for temporal autocorrelation.

After fitting each model, the parameter estimate (i.e., beta) map
associated with the target event's regressor was retained and
concatenated into a 4D image with all other events from the same
condition, resulting in a set of $X$ 4D images where $X$ refers to the
number of conditions in the task.
The number of volumes in each 4D beta series image
represents the number of events in that condition.


\subsection{Psychophysiological Interaction Modeling}

The computation of psychophysiological interactions underwent multiple steps:
1) extraction and cleaning of an ROI time series,
2) deconvolution of an ROI time series~\cite{Gitelman2003},
3) centering of the psychological variable~\cite{Di2017},
4) up-sampling of both the deconvolved ROI time series and psychological variable,
5) multiplication of the deconvolved ROI time series and psychological variable, and
6) convolution of the resulting interaction term in step 5.
A simplified visualization of deconvolution, multiplication,
and reconvolution process is in Figure~\ref{fig:ppi_method_overview}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{ppi_method_overview}
  \caption[Example computation of several PPIs]{
    The overall process of generating a PPI.
    The $\circledast$ symbol between plots represents convolution.
    First, the BOLD time series is deconvolved (inverse of convolution)
    to represent the theoretical neuronal time course.
    Next, the neuronal time series is then multiplied with each of the psychological
    conditions, generating neural PPIs seen in the middle row.
    Finally, each neural PPI is convolved with a hemodynamic response function
    to represent the context-dependent BOLD signal for their respective psychological
    condition.
  }
  \label{fig:ppi_method_overview}
\end{figure}

Extraction and cleaning of the ROI time series was completed using nilearn,
including white matter and cerebral spinal fluid signal, framewise displacement,
motion outliers, a high pass filter (cosine basis set), and the first four non-steady state
volumes as confounds regressed from the time series.
We deconvolved the ROI time series using a Fourier basis set convolved with
SPM's hemodynamic response function as predictors using ridge regression.
Ridge regression was implemented in Scikit-Learn setting the alpha (regularization)
parameter to 0.0001, but keeping all other parameters at their default values.
Independently, we took each psychological condition of interest ($Switch$, $Repeat$, and $Single$)
represented as a stick function (i.e., 1's where the stimulus was "on" and 0's everywhere else)
and mean centered each psychological condition separately.
The stimuli were presented for less time (1.5 seconds) than the acquisition of
a volume (2.0 seconds), thus to accurately represent the duration
of the stimulus, each of the psychological conditions and deconvolved ROI time series was up-sampled to
a resolution of 0.1 seconds.
Next, we multiplied each of the up-sampled psychological conditions with the deconvolved/up-sampled
ROI time series creating a "neural" PPI for each of the
psychological conditions~\cite{McLaren2012}.
We down-sampled the "neural" PPI back to a resolution of 2 seconds and convolved the signal with
SPM's hemodynamic response function representing the PPI in the original BOLD time-course.

The creation of the PPIs resulted in the full regression model in Equation~\ref{eq:full_ppi}

\begin{equation}
	\begin{multlined}[b]
    Y = \beta_{intercept}X_{intercept} + \beta_{switch}X_{switch} + \beta_{repeat}X_{repeat} + \\
	      \beta_{single}X_{single} + \beta_{firsttrial}X_{firsttrial} + \beta_{ROI}X_{ROI} + \\
		\beta_{switch\_ppi}X_{switch\_ppi} + \beta_{repeat\_ppi}X_{repeat\_ppi} + \\
		\beta_{single\_ppi} X_{single\_ppi} + \epsilon
  \end{multlined}
  \label{eq:full_ppi}
\end{equation}

Where the $\beta$s represent the model estimates/coefficients and $X$ represents
the design column.
$Y$ represents the ROI BOLD signal we want to explain.
$\beta_{intercept}$ refers to the baseline estimate (implicit rest) during the task,
where $X_{intercept}$ is a column of ones.
$\beta_{switch}$, $\beta_{repeat}$, $\beta_{single}$, and $\beta_{firsttrial}$
are the coefficients representing the main effect of each of the event conditions.
$X_{switch}$, $X_{repeat}$, $X_{single}$, and $X_{firsttrial}$ indicate the
times when the events for condition occurred.
$\beta_{ROI}$ is the coefficient representing the baseline connectivity between
this particular ROI and the ROI BOLD signal we want to explain, and
$X_{ROI}$ is the time series from the particular ROI.
$\beta_{switch\_ppi}$, $\beta_{repeat\_ppi}$, and $\beta_{single\_ppi}$
represent the context dependent functional connectivity estimates for
each event condition.
$X_{switch\_ppi}$, $X_{repeat\_ppi}$, and $X_{single\_ppi}$ represent
the interaction between the ROI time series and each event condition.
An example design matrix is illustrated in Figure~\ref{fig:example_ppi_design}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{example_ppi_design}
  \caption[An example PPI analysis design]{
    An example PPI analysis design.
    The $physio$ column represents BOLD signal from an ROI.
    The event type $firsttrial$ was not of interest in the contrasts,
    but included in the model for completeness.
    The $constant$ column can also be referred to as the intercept.
  }
  \label{fig:example_ppi_design}
\end{figure}

The contrasts of interests taken from this model were:\\
$((switch\_ppi + repeat\_ppi) / 2) - single\_ppi$, $repeat\_ppi - single\_ppi$,
and $switch\_ppi - repeat\_ppi$ to measure each context-dependent difference in functional connectivity. 
This equation was run for every unique ROI-ROI pair in both directions
(e.g., $Y$ and $X_{ROI}$ swap places) resulting in an
asymmetrical correlation matrix for each of the mentioned contrasts.
For reference, the first term in the first listed contrast ($((switch\_ppi + repeat\_ppi) / 2)$)
is referred to as the $Dual$ condition because it represents the functional connectivity during the
two-task blocks.

\subsection{Atlas Generation}
\label{methods:atlas-corr-analysis2}

In the participant data; two atlases were used to generate ROI-to-ROI correlation matrices.
We created an activation atlas representing regions that were
consistently activated across event conditions (see \nameref{methods:task-switch}).
The activation atlas was generated based on an F-test across the switch, repeat, and single conditions
to identify regions that were reliably activated for all participants (Table~\ref{table:clusters2}).
5mm spheres were drawn around each statistical peak (21 peaks total) (Figure~\ref{fig:methroimap2}).
This atlas has coverage across several cortical and subcortical regions.
The second atlas, Schaefer Atlas (400 parcels, 17 networks)\cite{Schaefer2017}, was
used to comprehensively cover the cortex and test robustness of results.


\begin{table}[H]
  \csvautotabular[separator=tab, no check column count]{./data/cluster_table.tsv}
  \caption[Peak activation coordinates]{
    The peak MNI coordinates/Z-statistic identifying clusters/sub-clusters from the overall
    response contrast.
    These peaks were used to create regions of interest (ROIs) to form an atlas representative
    of the most consistently activated regions across conditions.
  }
  \label{table:clusters2}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{stat-map-overall_resp_with_rois}
  \caption[Activation atlas]{
    ROIs drawn from the peak Z-score table, placing a sphere with a 5mm radius
    at each peak coordinate.
    The clusters are identified in their approximate locations
    with their ID.
  }
  \label{fig:methroimap2}
\end{figure}

\begin{table}[H]
  \csvautotabular[separator=tab]{./data/schaeferbest_rois.tsv}
  \caption[Top CNR coordinates]{
    The top 20 ROIs from the Schaefer 400 (17 Network) identified with a highest CNR as measured by
    both LSS and LSA.
  }
  \label{table:parcels2}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{schaefer_high_cnr_rois}
  \caption[SchaeferTop20 atlas]{
    20 ROIs selected from the Schaefer 400 parcels; 17 network atlas for having the
    highest CNR for both LSS and LSA.
  }
  \label{fig:schaefertopmap2}
\end{figure}

To increase the likelihood of being able to detect a real result using the Schaefer atlas,
we selected the top 25 ROIs with the highest CNR using LSA and LSS separately
(see \nameref{methods:bsc-simulations} for how we calculated CNR).
We then took the intersection of the two ROI sets resulting in 20 ROIs that have a high CNR
as measured by LSA and LSS (Table~\ref{table:parcels2},Figure~\ref{fig:schaefertopmap2}).
We refer to this subset of ROIs as the SchaeferTop20 Atlas for the rest of the manuscript.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/cnr_trial_variability.ipynb}{see here for relevant code}).
The results for the entire 400 ROI atlas are shown in the supplementals.

\subsection{BSC Analysis}

Outlier beta estimate volumes were identified and discarded using a
modified Nipype function for outlier detection
(\href{https://github.com/HBClab/NiBetaSeries/blob/a45c0a1f/src/nibetaseries/interfaces/nilearn.py#L153}{see here}) \cite{Crosby1994}.
The correlation coefficient estimator used for generating correlation matrices
was empirical covariance, as implemented in Nilearn 0.4.2~\cite{nilearn}.
Correlation coefficients were converted to normally-distributed z-values using
Fisher's r-to-z conversion~\cite{Fisher1915}.

BSC generated correlation matrices for each condition (dual, switch, repeat, single),
each method, (LSA and LSS), each data type (real and null), and each participant (N=40).
A paired t-test was run on each ROI-ROI pair for the activation atlas, totaling 210 comparisons
between task and null.
We contrasted $Dual - Single$, $Repeat - Single$, and $Switch - Repeat$, for LSS/LSA in both
real and null data.

\subsection{PPI Analysis}

To create symmetric correlation matrices similar to BSC using PPI, the asymmetric matrices generated for
each contrast were transposed, added to the original, and divided by two, as done in previous work~\cite{Di2019a}.
The resulting symmetric matrices were comparable to the contrast matrices generated from BSC.

\subsection{BSC and PPI Comparison}

Since we do not have a ground truth for which ROI-ROI pairs should be different between conditions,
we used a binomial test across all ROI-ROI pairs to discover if the number of observed significant ROI-ROI pairs was greater
than 5\%.
We did not use false discovery rate correction on the observed p-values since we were not interested in
which specific ROI-ROI pair correlations were likely to be true positives, but rather if the number of positives
observed would be expected by chance alone or if LSS/LSA/PPI likely detected an overall difference between event conditions.

With three separate methods being compared, we also measured agreement through convergence by correlating the
context-dependent functional connectivity differences across all unique ROI-ROI pairs for each of the contrasts.
For example, we compared the estimated connectivity differences between $Switch - Repeat$ for each unique
ROI-ROI pair for every method (LSA, LSS, and PPI).
The difference estimates for PPI were correlated with the difference estimates for LSS and LSA, providing
evidence whether LSS or LSA is more similar to PPI~\cite{Steiger1980}.

We also describe the number of significant positive and negative condition correlation differences
for the contrasts $Dual - Single$, $Repeat - Single$, and $Switch - Repeat$
in both the real and null data.
If the data are null, we would expect the the number of positive and negative
differences to be equal, however, the real data could demonstrate a pattern
of results with more positive or negative differences.
To test if the number of positive/negative differences is different from a $50/50$
split we used a binomial test with the expected ratio of 50\%.
We displayed the 95\% confidence interval to easily see if the interval
overlaps with the expected 50\% ratio of positive differences.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/2e5d7d2443795133770383daaa401cf70cc03f29/PPITest/compare_bsc_ppi.ipynb}{see here for relevant code}).

\subsection{Software Dependencies}
\label{methods:software-dependencies2}

The results in this manuscript are dependent on many open source
libraries, while we have inevitably missed providing all due credit,
we would like to acknowledge some of the main libraries used in 
\emph{fMRIPrep} 1.5.7\cite{fmriprep1} and \emph{NiBetaSeries} 0.6.0\cite{Kent2018}.

Many internal operations of \emph{fMRIPrep} use \emph{Nilearn} 0.6.1
\cite[RRID:SCR\_001362]{nilearn}, mostly within the functional
processing workflow. For more details of the pipeline, see
\href{https://fmriprep.readthedocs.io/en/latest/workflows.html}{the
section corresponding to workflows in \emph{fMRIPrep}'s documentation}.

Additional libraries used in the \emph{NiBetaSeries} workflow include
\emph{Pybids} 0.9.5 \cite{Yarkoni2019}, \emph{Niworkflows} 1.0.4,
\emph{Nibabel} 2.4.1, \emph{Pandas} 0.24.2 \cite{McKinney2010}, and
\emph{Numpy} 1.18.1 \cite{VanDerWalt2011, Oliphant2006}.

In addition to the data analysis, visualization of results depended
on matplotlib\cite{Hunter2007}, seaborn\cite{Waskom2020}, nilearn,
jupyter notebooks\cite{Kluyver2016a}, and the packages they depend on.

\section{Results}
We analyzed the data from three different perspectives:
1) identifying whether each method found more significant results than expected,
2) finding which method estimates are more closely related, and
3) describing the pattern of positive and negative context-dependent functional connectivity
differences in the significant ROI-ROI pairs for each method.


\subsection{Number of Significant Results}

\begin{figure}[H]
  \centering
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-activation_participants-filtered_permutation_summary_ppi} 
  \label{fig:real-activationppi}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-activation_participants-filtered_permutation_summary_ppi} 
  \label{fig:null-activationppi}}
  \vfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-schaeferbest_participants-filtered_permutation_summary_ppi} 
  \label{fig:real-schaeferbestppi}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-schaeferbest_participants-filtered_permutation_summary_ppi} 
  \label{fig:null-schaeferbestppi}}
  \caption[Comparison of LSA/LSS/PPI using participant data]{
    Percentage of statistically significant ROI-ROI pairs found
    in the contrasts $dual - single$, $repeat - single$, and
    $switch - repeat$.
    The red dotted line represents the expected 5\% false positive rate
    and the shaded red region is the 95\% confidence interval.
    Left panels \ref{fig:real-activationppi} and \ref{fig:real-schaeferbestppi}
    are results from the real data.
    Right panels \ref{fig:null-activationppi} and \ref{fig:null-schaeferbestppi} are results
    from the null data.
    PPI consistently has a greater number of significant context-dependent differences between ROI-ROI pairs
    than expected, except for the $switch - repeat$ contrast.
  }
\label{fig:main-resultppi}
\end{figure}

We found LSS, LSA, and PPI had a greater number of statistically significant ROI-ROI pairs than expected by chance
for different contrasts in the activation atlas with real data: $dual - single$ (LSA: 4.29\%; $p = 0.727$,
LSS: 9.05\%; $p < 0.010$, PPI: 10.48\%; $p = 0.001$),
$repeat - single$ (LSA: 10.00\%; $p = 0.002$, LSS: 7.62\%; $p = 0.063$, PPI: 11.90\%; $p < 0.001$), and
$switch - repeat$ (LSA: 7.14\%; $p = 0.106$, LSS: 2.86\%; $p = 0.954$, PPI: 8.57\%; $p = 0.019$) (Figure~\ref{fig:real-activationppi}).

Within the activation atlas with null data, only PPI had significant results:
$dual - single$ (LSA: 5.24\%; $p = 0.480$, LSS: 4.29\%; $p = 0.727$, PPI: 9.52\%; $p = 0.005$),
$repeat - single$ (LSA: 4.76\%; $p = 0.607$, LSS: 5.71\%; $p = 0.360$, PPI: 11.49\%; $p < 0.001$), and
$switch - repeat$ (LSA: 5.71\%; $p = 0.360$, LSS: 1.43\%; $p = 0.998$, PPI: 6.19\%; $p = 0.254$) (Figure~\ref{fig:null-activationppi}).

Within the SchaeferTop20 atlas with real data, PPI analyses yielded an extraordinary number of results
relative to LSS and LSA for the block contrasts:
$dual - single$ (LSA: 7.89\%; $p = 0.055$, LSS: 10.53\%; $p = 0.001$, PPI: 26.84\%; $p < 0.001$),
$repeat - single$ (LSA: 12.63\%; $p < 0.001$, LSS: 11.05\%; $p = 0.001$, PPI: 31.05\%; $p < 0.001$), and
$switch - repeat$ (LSA: 4.21\%; $p = 0.738$, LSS: 4.21\%; $p = 0.738$, PPI: 6.84\%; $p = 0.158$) (Figure~\ref{fig:real-schaeferbestppi}).

Within the SchaeferTop20 atlas with null data, both PPI and LSA had significant number of false positives:
$dual - single$ (LSA: 8.94\%; $p = 0.015$, LSS: 3.68\%; $p = 0.842$, PPI: 13.68\%; $p < 0.001$),
$repeat - single$ (LSA: 12.63\%; $p < 0.001$, LSS: 4.74\%; $p = 0.613$, PPI: 12.63\%; $p < 0.001$), and
$switch - repeat$ (LSA: 15.79\%; $p < 0.001$, LSS: 3.16\%; $p = 0.917$, PPI: 5.26\%; $p = 0.480$) (Figure~\ref{fig:null-schaeferbestppi}).
These results are qualitatively similar to the full Schaefer atlas with the same two notable exceptions
as stated in Chapter 2:
1) the $switch - repeat$ contrast using LSA found more statistically significant
ROI-ROI pair correlation differences between conditions relative to chance,
but LSS and PPI did not and
2) LSS has higher false positive rate than LSA, but still less than PPI (Figure~\ref{fig:schaefer_binomial_ppi}).

\subsection{Correlations Between LSA/LSS/PPI}

To find whether PPI was more similar to LSA or LSS, we correlated the contrast estimates for all of the contrasts
($dual - single$, $repeat - single$, and $switch - repeat$),
for all the atlases (activation atlas, SchaeferTop20 atlas, and the full Schaefer atlas), and
for each of the data sources (real and null).
PPI ROI-ROI contrast estimates significantly correlated more strongly with LSS relative to LSA
for nearly all contrasts ($dual - single$, $repeat - single$, and $switch - repeat$),
atlases (activation atlas, SchaeferTop20 atlas, and the full Schaefer atlas),
and the real and null data ($p < 0.05$) except the $switch - repeat$
contrast in the SchaeferTop20 Atlas (real: $p = 0.541$, null: $p = 0.064$)
(Figures~\ref{fig:atlas-activation_correlations}~\ref{fig:atlas-schaeferbest_correlations}~\ref{fig:atlas-schaefer_correlations}).
The overall average correlation between LSS and PPI is $r = 0.55$, LSA and PPI is $r = 0.29$,
and LSS and LSA is $r = 0.34$.
The overall average correlation difference between $Corr(LSS, PPI)$ versus $Corr(LSA, PPI)$ is $0.26$,
indicating a medium effect size of the correlation between LSS and PPI is stronger than the
correlation between LSA and PPI.
The similarity between LSS and PPI is stronger for the block contrasts ($dual - single$ and $repeat - single$)
relative to the event-related contrast ($switch - repeat$), regardless of data (real/null) or atlas.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{atlas-activation_estimate_correlations}
  \caption[Correlation between LSA/LSS and PPI in the activation atlas]{
    Correlations of LSS/LSA context-dependent functional correlation difference estimates with
    estimates from PPI from the activation atlas
  }
  \label{fig:atlas-activation_correlations}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{atlas-schaeferbest_estimate_correlations}
  \caption[Correlation between LSA/LSS and PPI in the SchaeferTop20 atlas]{
    Correlations of LSS/LSA context-dependent functional correlation difference estimates with
    estimates from PPI from the SchaeferTop20 atlas.
  }
  \label{fig:atlas-schaeferbest_correlations}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{atlas-schaefer_estimate_correlations}
  \caption[Correlation between LSA/LSS and PPI in the Schaefer atlas]{
    Correlations of LSS/LSA context-dependent functional correlation difference estimates with
    estimates from PPI from the Schaefer atlas.
    \textbf{NOTE}: the scatter plot points were binned to reduce figure size, but
    this does not impact the slopes of the regression lines.
    If all dots were plotted, the dots would be equivalently 
    distributed relative to the other atlases.
  }
  \label{fig:atlas-schaefer_correlations}
\end{figure}

\subsection{Proportion of Positive Condition Differences}

Another descriptive variable we tracked was the proportion of significant ROI-ROI pairs
that had positive or negative context-dependent connectivity differences.
In the null data, we would expect the false positives to be split $50/50$ between
positive and negative context-dependent functional connectivity differences.
Whereas the real data may show a tendency for positive or negative condition differences.
The specific measure I used was $positives / (positives + negatives)$
from the significant ROI-ROI pairs~\ref{fig:positive_bias}.

\begin{figure}[H]
  \centering
  \subfloat[][]{\includegraphics[width=0.45\linewidth]{
    data-real_atlas-activation_positive_bias} 
  \label{fig:real-activationbias}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.45\linewidth]{
    data-null_atlas-activation_positive_bias} 
  \label{fig:null-activationbias}}
  \vfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-schaeferbest_positive_bias} 
  \label{fig:real-schaeferbestbias}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-schaeferbest_positive_bias} 
  \label{fig:null-schaeferbestbias}}
  \caption[Proportion of positive condition differences in LSA/LSS/PPI using participant data]{
    An illustration of the proportion of positive condition differences
    for significant ROI-ROI pairs ($positives / (positives + negatives)$).
    The center black bar represents having an equal number of positive
    and negative condition differences in significant
    ROI-ROI pairs.
    The bars around the points indicate the 95\% confidence interval
    of the observed ratio.
    The block contrasts ($Dual - Single$ and $Repeat - Single$) have mostly
    negative conditions differences, suggesting the context-dependent functional
    connectivity decreases when comparing $Dual$ or $Repeat$ to $Single$.
    The event-related contrast ($Switch - Repeat$) has more positive
    condition differences in both the real and null data.
  }
\label{fig:positive_bias}
\end{figure}

The proportion of positive differences is generally lower in the real data relative
to the null data for the mixed block/event contrasts,
providing further evidence suggesting the results represent a true context-dependent
correlation difference.
The positivity bias from the event-related contrast however does not
reliably distinguish the real and null data.

\section{Discussion}
We provided the first in-depth comparison between LSA, LSS, and PPI.
We showed while PPI generally found more results relative to LSA and LSS in the real data,
PPI also found a large number of results in the null data.
Given the greater agreement between LSS and PPI, we recommend using PPI
for event-related contrasts, and either PPI or LSS for mixed event-related/block contrasts.
With LSS, you may have fewer results relative to PPI, but based on this data-set,
LSS is less prone towards finding spurious results relative to both LSA and PPI.

The choice of atlas did not have a strong impact on LSS's and LSA's correlation with
PPI analyses.
LSS was almost always more correlated with PPI than LSA was correlated with PPI indicating
LSS and PPI are more related than LSA and PPI.
The stronger relationship between LSS and PPI could be
due to both methods being influenced by adjacent
events.
The deconvolution of the BOLD signal used in PPI analysis
does not remove the event to event variances of adjacent events.
Similarly, in LSS the $\beta$ estimate for the event of interest
is not forced to be orthogonal to adjacent events and as such
influence the $\beta$ estimate for the target event.
In contrast, LSA only keeps the unique event variance and any
shared variance with adjacent events is not given to any event.
This does not explain why LSS would have poor performance with event-related contrasts
and why PPI would perform relatively well. 
Additionally, the higher correlation between LSS and PPI analyses estimates
did not translate to a large agreement of which ROI-ROI pairs were found
significant between LSS and PPI (Figure ~\ref{fig:data-null_type-brain_atlas-activation_contrast-dualxsingle}).
This implies while LSS and PPI estimates are often in the same direction, the magnitude
of the estimates are different.
If the magnitude is different between LSS and PPI estimates,
one method may reach significance for a particular ROI-ROI pair while the other method
may not reach the threshold.
Thus, there is still significant variance between LSA/LSS/PPI producing unique results
depending on which method is chosen.

An intriguing result is the large percentage of significant ROI-ROI pairs found by
PPI analysis in Figure~\ref{fig:real-schaeferbestppi}.
The top CNR regions were chosen using LSA and LSS, with no input from PPI.
This suggests LSS/LSA could be used as a data driven approach to select ROIs
for PPI analyses, as opposed to the traditional method of selecting
highly activated regions.
The derivation of CNR does not select for ROIs that have context-dependent
connectivity differences so this strategy does not suffer from
double-dipping~\cite{Kriegeskorte2009}.
However, this strategy did not help with the event-related contrast ($Switch - Repeat$)
suggesting CNR is not the only factor at play to increase the sensitivity of
detecting context-dependent functional connectivity differences.

There was a greater proportion of negative context-dependent functional connectivity
differences for the contrasts
$Dual - Single$ and $Repeat - Single$ in the real data (relative to the null data)
(Figure~\ref{fig:positive_bias}).
This finding agrees with previous work looking at
context-dependent functional connectivity during various task states
~\cite{Cole2014a,Spadone2015,Di2019a,He2013,Ito2019,Hearne2020}.
While the previous work emphasized the difference between task and rest, we extend
the evidence to comparing a more cognitively demanding state ($Dual$ or $Repeat$)
relative to a less cognitively demanding state ($Single$).
Recent work has observed a negative correlation between the activation of an ROI
and it's task evoked connectivity ~\cite{Hearne2020}.
The hypothesis put forward is the decreased correlations represent less redundancy of
information being transferred between ROIs and increased capacity to encode unique information.
Since the activation atlas and the SchaeferTop20 atlas represent
regions of high activity, their large proportion of negative
context-dependent functional connectivity differences
is congruent with the above hypothesis.
Their work even shows across a majority of cortical
regions a task state reduces
connectivity between ROIs relative to rest~\cite{Ito2019},
matching the negative context-dependent functional connectivity differences
found in the Schaefer atlas as well~\ref{fig:positive_bias_schaefer}.
The $Switch - Repeat$ contrast presents a challenge to the theory since
the switch events are typically viewed as being more cognitively demanding than repeat events,
suggesting the $Switch - Repeat$ contrast should follow the same pattern as the others.
There could be some idiosyncrasy in the design of the experiment since the null data are also
biased to show increased context-dependent functional connectivity results as well.
Additionally, there were often fewer significant ROI-ROI pairs for the $Switch - Repeat$ contrast,
giving lower confidence whether an actual
trend exists (e.g., flipping a coin 3 times and getting all heads
is less surprising than flipping a coin 20 times and getting all heads).

PPI may be the better method for detecting context-dependent functional connectivity
differences, and as such could be extended to include spatiotemporal relationship as BSC methods
have been expanded~\cite{Turner2012a}.
Specifically, PPIs could be calculated using a finite impulse response (FIR) model, where instead of assuming
a hemodynamic response function shape, there is a separate regressor for each time point peri-stimulus.
This analysis strategy would require significant data per person since the number of regressors would be
$2 * (\#FIRs * \#conditions) + 1_{physio}$, where FIRs could reasonably go up to 8
and the number of conditions could
be 3, creating 49 regressors in the model related to the task.

BSC methods may still have an advantage over PPI when looking at event conditions in isolation.
The PPI $\beta$ estimates represent the event condition of interest relative to rest and all other
event conditions.
BSC methods, on the other hand, purportedly measure the event condition independent
of all other event conditions.
Thus, one could summarize the individual event conditions using network measures before contrasting event conditions,
while performing the same analysis using PPI is potentially ambiguous on what the network measure represents.

\subsection{Limitations and Future Directions}

This work is subject to several limitations.
The implementation of PPI used in this manuscript is based on
a home-grown analysis pipeline and has not been vigorously tested
as other tools in existence (SPM's \href{https://www.nitrc.org/projects/gppi}{gPPI toolbox}
and AFNI's \href{https://afni.nimh.nih.gov/CD-CorrAna}{Context Dependant Correlation Analysis}).
In support of the homegrown pipeline, we did find a similar correlation between LSS and PPI as
other work ~\cite{Di2019a}.
Future work could compare SPM, AFNI, and python implementations of PPI to measure the similarity
between the pipelines.

Due to the high levels of motion several participants were removed from this analysis.
According to the LSA/LSS power analysis, our results were moderately under powered for the BSC analysis,
increasing the difficulty to compare LSA, LSS, and PPI.
However, even with the smaller sample size, several striking patterns emerged in our data.
Future work should attempt to replicate our findings in an independent data-set.

It could be argued the resting state data does not provide an adequate null model
to compare to the real task data because there is presumably no BOLD response at any
of the onset times.
Trying to model the BOLD response with no expectation of a BOLD response existing could lead
to large misfits and deviating beta estimates for BSC and a lesser extent PPI.
A proper null model would insert uniform BOLD responses across all onsets, such that
the only context-dependent differences that could be detected would be driven by the
resting state BOLD oscillations.

While the data suggest that mixed event/block contrasts are more likely to show results relative to event-related contrasts,
we did not control for the cognitive effort difference between the conditions.
We cannot rule out the possibility that the difference in cognitive effort for
$Switch$ and $Repeat$ is less than the difference between $Repeat$ and $Single$.
In fact, in the context of an older adult population like the one used here,
age tends to impact global switch costs (i.e., $Repeat - Single$) more than local
switch costs (i.e., $Switch - Repeat$), possibly resulting in greater difficulty to detect
differences between the two conditions~\cite{Wasylyshyn2011}.
Future work could incorporate a study using younger adults with several runs of the same task, where
the contrast would be calculated between events of the same run (e.g., $Switch_{run1} - Repeat_{run1}$
and between the events in separate runs (e.g., $Switch_{run1} - Repeat_{run2}$).
This design would control for cognitive effort differences while contrasting event conditions that are adjacent
to each other versus from separate runs.

\subsection{Conclusions}
Overall we have 3 main conclusions from this work:
1) PPI is the most sensitive, but the least specific method,
2) LSS is more closely related to PPI than LSA, and
3) contrasts from events between blocks detect more changes
in context-dependent functional connectivity than contrasts
from interleaved events.

\subsection{Supplemental Material}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-dualxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI]{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Dual - Single$ contrast in the real data.
      LSA has a total of 9 results, 2 overlapping with PPI,
      LSS has a total of 19 results, 4 overlapping with PPI and
      PPI has a total of 22 results.
  }
  \label{fig:data-real_type-brain_atlas-activation_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-dualxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Dual - Single$ contrast for null data.
      LSA has a total of 11 results, 2 overlapping with PPI,
      LSS has a total of 9 results, 4 overlapping with PPI,
      and PPI has a total of 20 results.
  }
  \label{fig:data-null_type-brain_atlas-activation_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-repeatxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Repeat - Single$ contrast for real data.
      LSA has a total of 21 results, 4 overlapping with PPI,
      LSS has a total of 16 results, 4 overlapping with PPI and
      PPI has a total of 25 results.
  }
  \label{fig:data-real_type-brain_atlas-activation_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the contrasts $Repeat - Single$ contrast for null data.
      LSA has a total of 10 results, 2 overlapping with PPI,
      LSS has a total of 12 results, 5 overlapping with PPI,
      and PPI has a total of 24 results.
  }
  \label{fig:data-null_type-brain_atlas-activation_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-switchxrepeat_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-switchxrepeat_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Switch - Repeat$ contrast for real data.
      LSA has a total of 15 results, 2 overlapping with PPI,
      LSS has a total of 6 results, 1 overlapping with PPI and
      PPI has a total of 18 results.
  }
  \label{fig:data-real_type-brain_atlas-activation_contrast-switchxrepeat}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-switchxrepeat_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-switchxrepeat_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the contrasts $Switch - Repeat$ contrast for null data.
      LSA has a total of 12 results, 1 overlapping with PPI,
      LSS has a total of 3 results, 1 overlapping with PPI,
      and PPI has a total of 13 results.
  }
  \label{fig:data-null_type-brain_atlas-activation_contrast-switchxrepeat}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Dual - Single$ contrast in the real data.
      LSA has a total of 15 results, 8 overlapping with PPI,
      LSS has a total of 20 results, 10 overlapping with PPI and
      PPI has a total of 51 results.
  }
  \label{fig:data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Dual - Single$ contrast for null data.
      LSA has a total of 17 results, 3 overlapping with PPI,
      LSS has a total of 7 results, 5 overlapping with PPI,
      and PPI has a total of 26 results.
  }
  \label{fig:data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Repeat - Single$ contrast for real data.
      LSA has a total of 24 results, 12 overlapping with PPI,
      LSS has a total of 21 results, 10 overlapping with PPI and
      PPI has a total of 59 results.
  }
  \label{fig:data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the contrasts $Repeat - Single$ contrast for null data.
      LSA has a total of 24 results, 2 overlapping with PPI,
      LSS has a total of 9 results, 4 overlapping with PPI,
      and PPI has a total of 24 results.
  }
  \label{fig:data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Switch - Repeat$ contrast for real data.
      LSA has a total of 8 results, 1 overlapping with PPI,
      LSS has a total of 8 results, 1 overlapping with PPI and
      PPI has a total of 13 results.
  }
  \label{fig:data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lssxppi}}

  \caption[All contrasts for all atlases for all data for LSA/LSS versus PPI continued...]{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the contrasts $Switch - Repeat$ contrast for null data.
      LSA has a total of 30 results, 1 overlapping with PPI,
      LSS has a total of 6 results, 1 overlapping with PPI,
      and PPI has a total of 30 results.
  }
  \label{fig:data-null_type-brain_atlas-schaeferbest_contrast-switchxrepeat}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=0.7\textwidth]{data-real_atlas-schaefer_participants-filtered_permutation_summary_ppi}}

  \subfloat{\includegraphics[width=0.7\textwidth]{data-null_atlas-schaefer_participants-filtered_permutation_summary_ppi}}

  \caption[Comparison of LSA/LSS/PPI using participant data and the Schaefer atlas]{
      The overall results for the full Schaefer Atlas.
      Since there were 79800 unique ROI-ROI pairs, it became more likely
      to see unexpected results.
      Looking at magnitudes alone, PPI has more results in the real data
      and the null data.
  }
  \label{fig:schaefer_binomial_ppi}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=0.49\textwidth]{data-real_atlas-schaefer_positive_bias}}
  \hfill
  \subfloat{\includegraphics[width=0.49\textwidth]{data-null_atlas-schaefer_positive_bias}}

  \caption[Positive bias of LSA/LSS/PPI in Schaefer Atlas]{
    An illustration of the positive bias for the significant ROI-ROI pairs
    ($positives / (positives + negatives)$).
    The center black bar represents having an equal number of significant
    ROI-ROI pairs that are increasing and decreasing their context-dependent
    functional connectivity.
    The bars around the points indicate the 95\% confidence interval
    of the observed ratio.
  }
  \label{fig:positive_bias_schaefer}
\end{figure}

%=============================================================================
\chapter{General Discussion}
%=============================================================================

In the course of this thesis I validated and compared two BSC methods (LSS and LSA) and compared
the BSC methods with the older and more accepted PPI analysis to investigate
which method is best able to detect context-dependent functional
connectivity differences.
Overall, I have found PPI is the most sensitive, but least specific method, LSS
is the least sensitive, but most specific method, and LSA sits in the middle.
Additionally, I have discovered PPI contrast estimates are more correlated
with LSS contrast estimates relative to LSA contrast estimates, suggesting
LSS and PPI methods are more related.
Several additional key insights are listed in Table~\ref{table:comparison}.

\begin{table}[H]
  \centering
  \caption[Comparisons of LSA/LSS/PPI]{
  {\bf Comparisons of LSA/LSS/PPI}}
  \begin{tabular}{|p{0.7\textwidth}|c|c|c|}
  \hline
  \textbf{Query} & \textbf{LSA} & \textbf{LSS} & \textbf{PPI}\\ \hline
  Good for event-related contrasts & \xmark & \xmark & \cmark\\ \hline
  Good for mixed event/block contrasts & \cmark & \cmark & \cmark\\ \hline
  Maintains expected false positive rate (with high activation/CNR ROI sets) & \xmark & \cmark & \xmark\\ \hline
  Maintains expected false positive rate (with full cortex coverage ROI set) & \xmark & \xmark & \xmark\\ \hline
  Provides an estimate for a condition with fewer than 3 events & \xmark & \xmark & \cmark\\ \hline
  \end{tabular}

  Considerations for choosing LSA, LSS, or PPI when calculating context-dependent
  functional connectivity differences.
  \label{table:comparison}
\end{table}

\section{Network Measures}
\label{network-measures}

Network measures could be used to compare real data from null data such as: participation coefficient,
modularity, and clustering coefficient~\cite{Rubinov2010}.
The participation coefficient measures how strongly one ROI is correlated with other ROIs within its
network and with ROIs outside of its network.
If the participation coefficient was 0 the ROI would be equally
correlated with all other ROIs regardless of which network the
ROI was assigned to, and at the other extreme, the ROI would only be correlated with other ROIs within its
network.
As cognitive effort increases, I would expect the participation coefficient to broadly decrease, where ROIs
would decrease the correlation with ROIs within their own network and increase correlations with ROIs outside
their network~\cite{Ito2019,Gonzalez-Castillo2018}.
Modularity provides an overall metric of how well the brain can be partitioned into networks to maximize
within network correlations and minimize between network correlations.
As opposed to the participation coefficient which gives a measure per ROI, modularity gives a global metric.
As with participation coefficient, I would suspect modularity to decrease
as cognitive effort increases~\cite{Gonzalez-Castillo2018}.
Clustering coefficient measures the number of nodes that form triangles of correlations, that is, groups of three
ROIs that exhibit increased correlations.
Broadly, the clustering coefficient measures how efficiently information flows between local nodes.
I would expect this measure to decrease as well as cognitive effort increases since cognitive effort is likely
sustained by a more distributed effort~\cite{Di2013}.

As for calculating the network measures, BSC methods have a straightforward interpretation as each
event condition is represented independently.
However, PPI analyses are less straightforward since the $\beta$ estimate for each PPI represents
the event condition of interest minus the average of all other conditions.
Thus it is difficult to interpret the modularity of an implicit difference of the contextual functional connectivity
of one event condition with the average of all other conditions.
It remains an open question whether these network measures calculated with PPI would agree with or be interpretable relative
to the network measures measured with BSC.
Moving forward, there is at least a baseline of expected similarity between LSA/LSS/PPI from the work presented
in the present thesis.

\section{Negative Context-Dependent Functional Correlation Differences}

The high proportion of negative contextual functional connectivity differences deserves
further discussion (Figures ~\ref{fig:positive_bias} \& ~\ref{fig:positive_bias_schaefer}).
A common interpretation would be that a low correlation between two ROIs reflects less information
sharing between the two ROIs and that a high correlation
reflects greater information transfer~\cite{Gonzalez-Castillo2018}.
However, a recent theory suggests that any deviation from spontaneous resting activity
(either activation or deactivation) should result in a decreased correlation between ROIs~\cite{Ito2019}.
Their theory pulls from electrophysiological recordings in animals where
spike count correlations between neuron spikes typically decrease during events,
particularly for task responsive neurons~\cite{Ruff2014,Cohen2009}.
The decrease in spike count correlations during events improves performance,
suggesting the decreased correlations improve information encoding of task
relevant features.
Ito et al. (2019) extended the finding from animals to human fMRI
using data from the Human Connectome Project, showing decreased variability
in their "task-state" measure as well as a majority of ROI-ROI pairs decreasing their
correlations relative to rest.
Instances of increased functional connectivity relative to rest primarily occurred between
networks that have low correlations during rest (e.g., Default Mode Network and Cingulo-Opercular Network).
It is important to note Ito et al. (2019) used the residual correlations method for analyzing
their task data preventing them from investigating changes in cognitive load within a task.
The current thesis largely corroborates and extends the work by Ito et al. (2019),
showing a tendency for significant ROI-ROI context-dependent correlations to decrease
when comparing a lower cognitive load ($Single$) to a higher cognitive load ($Repeat$ and $Dual$).
The $Switch - Repeat$ contrast however showed an increase in context-dependent functional connectivity
for the majority of significant ROI-ROI pairs in both the real and null data.
The increased context-dependent functional connectivity in the null data suggests
the increase may be an artifact of the experimental design and does not represent
a cognitive process.
Replication using different event-related tasks is required to make a more definitive
claim.

\section{Including Behavior}

Future work should combine context-dependent functional connectivity measures and behavior.
A common way to connect brain function and behavior is through correlating the brain measure
with a behavioral measure and observe individual differences.
Assessing changes in context-dependent functional connectivity coulped with changes in
reaction time or accuracy could provide more nuanced theories of the cognitive process under investigation.
However, careful thought has to be given for the number of participants and experimental design,
and analysis choices to reliably detect this relationship.
Most cognitive tasks have focused on showing robust experimental effects which led to the side effect
of low between subject variance~\cite{Hedge2018}.
The equation for intraclass correlations~\cite{Stanish1983}
(ICC)---a common measure of reliability---will
decrease when measurement error increases ($ErrorVariance$),
but notably ICC will also decrease if the variance between Individuals
decreases (holding other factors constant)(Equation~\ref{eq:icc}).
\begin{equation}
  \fontsize{10}{12}\selectfont
  ICC = \frac{Variance Between Individuals}{Variance Between Individuals + Error Variance + Variance Between Sessions}
  \label{eq:icc}
\end{equation}
Furthermore, often the measure of interest is a difference score, which
generally has a lower reliability than their component scores~\cite{Edwards2001},
compounding the issue.
The main task used in this thesis, task switching falls under the family of tasks that prioritize
group differences, but not individual differences and whose main outcomes are
difference scores ($Dual - Single$, $Repeat - Single$, $Switch - Repeat$) and thus
likely does not meet the threshold for clinically relevant reliability~\cite{Barch2008}.
Hedge et al. (2018)~\cite{Hedge2018} found an average reliability (as measured with ICC)
of 0.5 among common cognitive tasks, below the recommended reliability for clinically relevant measures~\cite{Barch2008}.
With the reliability of fMRI hovering around 0.5 as well, an adequately powered fMRI study
would require 100's of participants to measure individual differences~\cite{Bennett2010,Hedge2018}.

Besides (or in addition to) increasing sample size, there are alternative methods to
calculate and analyze the measures of interest to improve reliability.
Incorporating both reaction time costs and accuracy into a composite measure in task switching was
a better predictor of performance in an antisaccade task than reaction time costs alone~\cite{Hughes2014}.
Additionally, modeling reaction time and accuracy using a drift-diffusion model could improve 
reliability, but it is unknown if it offers any benefit in
reliability above using a composite score~\cite{Schmitz2012,Ratcliff1978,Lerche2017}.
Using linear mixed effects models or structural equation models could also better account
for distributional assumptions in the data and provide better reliability, although
such choices require training to use appropriately, and could lead to an inaccurate
model of the data~\cite{West2008,Bates2015}.

Finally, changes in experimental design would improve reliability.
The simulations in this thesis suggest using 45 events per condition
with an average IEI of 6 seconds as the optimal design.
In contrast, the data from Hedge et al. (2018) suggest over 100 events per condition
is necessary to achieve sufficient reliability for related tasks such as Flanker and
Stroop~\cite{Hedge2018}.
To reasonably accommodate the requirement for behavioral reliability,
participants should complete the task in the scanner as well as outside
the scanner to increase the reliability of the behavioral measurements.
Overall, while it is important to consider behavior in combination with brain function,
there are several important considerations to assure a proper analysis.

\section{Unique Abilities of BSC and PPI Analyses}

Beyond detecting changes in context-dependent functional connectivity in two discrete
conditions, BSC and PPI methods have unique capabilities that set them apart.
BSC has been extended to perform spatiotemporal analyses~\cite{Turner2012a}.
Under the spatio-temporal framework BSC does not assume the shape of the HRF,
and instead estimates the BOLD signal at specific time points following an event.
Spatiotemporal BSC could return 5 separate estimates for each event, and
one could create 5 different correlation maps; one for each time point.
The 5 separate estimates are different from traditional (spatial) BSC,
where each event only gets one estimate.
Having multiple estimates per event opens the door to more complex analyses,
and more detailed features for machine learning applications as detailed in
the paper that introduced this method~\cite{Turner2012a}.
There is no apparent reason PPI analysis could not also be applied in a similar manner
where each PPI represents a particular time after the event.
As with BSC, spatiotemporal analyses with PPI would require a large number
of parameters to model meaning a lot of data per participant would need to be
collected.

A unique feature of PPI analyses that cannot be mirrored by BSC is
measuring parametric designs, such as modeling word length.
The PPI would represent a pair of ROIs that parametrically increase
their correlation which each other as a function of the event magnitude.
For example, two ROIs may not be correlated when word length is short,
but their correlation may increase as word length increases.
BSC methods currently do not accommodate parametric experimental designs
since there is no straightforward way to split the events into categories
and correlate the $\beta$ estimates within each category.
To this author's knowledge, no one has attempted to use a parametric design
in conjunction with a PPI analysis, but it should be possible.

PPI analyses can also extend to factorial designs.
For example, if in addition to the word and nonword conditions,
the color of the word (or nonword) could represent a cue to speak or read silently.
This experiment is a 2 (word or nonword) by 2 (speak or read) factorial design.
PPI analyses are extensible to include a psycho-psycho-physiological interaction (PPPI),
where the interaction of the two factors (word or nonword and speak or read) can also be
multiplied with a physiological variable.
All lower order interactions must be included in the model as well, increasing the number
of parameters in the model.
BSC can theoretically model a factorial design by treating all combinations of the factors
as separate event conditions.
Thus, BSC would generate beta series for: 1) word-speak, 2) word-read, 3) nonword-speak,
and 4) nonword-read.
However, treating each factor combination as an independent event condition does not model the
interaction occurring between the factors.
Thus I would predict PPI analyses and BSC would diverge on their estimates.

\section{Improving Simulations}

Simulated data are a gold standard for method validation, but as demonstrated in my
thesis, careful consideration must be taken to ensure what the simulations represent.
While the simulations concluded LSS was the more powerful method, the 
participant data showed a relative weakness for LSS to detect a
context-dependent functional connectivity difference for an
event-related contrast.
The reason for this discrepancy was because of how the simulated
beta series correlation conditions were subtracted.
The simulated beta series correlations were generated with another condition
of non-interest interleaved with the condition of interest, but the calculated
correlation was subtracted from a correlation that was
generated from another simulation.
Thus while the simulations reflected the difficulty of comparing two conditions
with overlapping BOLD responses, the two conditions being compared did not come
from the same simulation instance and so I was not measuring the impact
of comparing two conditions from the same simulation.
Whether or not the conditions were from the same simulation
turned out to be important to generalize the event-related contrast
in the participant data.
A smaller simulation confirmed the importance of comparing conditions
that come from the same simulation instance
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/49e95ff36721abc66fde67202a34866979af0954/nibsAnalysis/investigate_induced_correlations.ipynb}{see code here}).

In addition to improving the simulations used to compare LSS/LSA,
an important next step is to include PPI analysis.
Since various experimental parameters were tested between LSS/LSA,
it would be informative to know if the correlation between LSS and PPI
is stronger under a variety of experimental conditions or if
the correlation between LSS and PPI breaks down in certain situations.
Furthermore, if the methods disagree, I can see which method
is more likely to be correct since I know the ground truth from
the simulations.

Once a variety of experimental conditions are compared, more complex
simulations can be used to measure how network dynamics could change.
These more complex simulations would offer insight into how the PPI
$\beta$ estimates capture the ground truth network dynamics.
As mentioned in \nameref{network-measures}, the PPI $\beta$ estimate
represents an implicit difference between the condition of interest
and an average of all other conditions, potentially obscuring the network
dynamics for that condition.
These simulations would help identify if PPI $\beta$ estimates could be
interpretable when calculating network measures.

The more complex simulations could also include spatial and temporal
noise sources.
Temporal sources of noise were already included in this thesis work,
but the impact of spatial noise has been ignored.
fmrisim~\cite{Ellis2020} can simulate spatial and
temporal noise builtin making the extension to include these simulations
relatively straight forward.
From these simulations I could determine whether different aspects of
spatial and temporal noise could drive changes in network
dynamics independent of ground truth network dynamics I set.
From these simulations I could identify what types of network dynamic
changes could be driven by noise.
If the more complex simulations include whole brain simulations,
I could run the simulated brains through fmriprep~\cite{fmriprep1}
to mirror the preprocessing steps that one would normally take
to prepare their data.
After preprocessing, I could test using different combinations of
confounds to test if a certain combination better captures the
ground truth network organization.
Simulating and emulating a typical analysis workflow would
drive insights surrounding experimental design, confound selection,
and method choice to measure context-dependent functional connectivity
differences.

\section{Conclusion}

Measuring context-dependent functional connectivity differences between
event-related conditions remains a difficult challenge.
My dissertation investigated several methods that could
measure context-dependent functional connectivity
using mixed block/event-related design and discovered PPI
analysis is the most sensitive method, but is also the least specific
relative to the BSC methods (LSS and LSA).
This work highlights the importance of combining
simulations with real data to validate methods, and lays a framework
to help other researchers choose which method they should use
for their experimental design.

% \begin{itemize}
%   \item Atlas choice may matter
%   \item PPI methods can adopt to parametric and factorial designs easier
%   \item We wanted to know if our choice of method mattered and under which circumstances we should use the methods.
%   \item PPI would likely be the best choice for low frequency events since the estimate will still use all time points
%         as opposed to BSC, where if there were only 4 events, I would be stuck trying to calculate a correlation with 4 numbers
%         (possible, but not very reliable)
%   \item LSA (and to a lesser extent LSS) perform similarly (in terms of model fit) whether their are 2 or 6 event conditions
%         (but they will suffer if there are few events to make correlations with), however, for each additional PPI,
%         two regressors must be added, which could lead to increased variance in the $\beta$ estimates.
%         It is important to note that LSA already suffers from a large number of regressors (can't get much worse). 
%   \item could add a deconvolved/reconvolved physiological regressor to PPI model
%   \item all methods show more significant decreases for mixed-event block contrasts, support for information transfer occurring via less redundancy
%         (i.e., more efficient representations)?
%   \item The above suggestion may allow one use network analysis methods on PPI, nope, not true after correspondence with Dr. Di
%   \item could try deconvolving the LSA/LSS estimates to see if the results are better in neural spaces
% 	\item PPI generally is more sensitive, but less specific (e.g., shows lots of significant results whether or not data is real or null)
% 	\item LSA/LSS still only choice to look at contexts in isolation (there is implicit contrast with PPI)
% 	\item LSA/LSS could be used to choose potential regions of interest in a data driven way (CNR)
% 	\item holistic network measures could be applied
% 	\item a higher correlation between estimates does not necessarily translate to identifying same ROI-ROI pairs.
% 	\item LSA/LSS could be used to further parse the difference between "task" state and "task" evoked state.
% 	\item Since LSS is more correlated with PPI, suggests they are measuring closer to the "same" thing
% 	\item Single event estimates between LSA/LSS are highly correlated
% \end{itemize}

%=============================================================================
% bibliography
%=============================================================================
\interlinepenalty=10000	% prevents bib items from splitting across pages
\bibliographystyle{uithesis}
\bibliography{thesis} 

\end{document}

% Thesis Comments
% compare relative to PPI
% split the results into two methods, here's my added value
% add on participants for correlations to lss/lsa
% beta versus PPI (AIM 2)
% why we care about connectivity,
% and why we care about task related connectivity
% 
%Meeting Notes
%Discussion to change Aim's 1 and 2 for the pragmatic purpose
%of getting a paper submitted.
%Change Aim1:
%split dataset into two halves (compare LSS and LSA)
%Change Aim2:
%split dataset into two halves (compare LSS and PPI)