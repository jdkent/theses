% cSpell:disable
% you should only have one "documentclass" line.  the following lines
% are samples that give various options.  the nofrontmatter option is
% nice because it suppresses the title and signature pages when you want
% to focus only on the main body of the thesis
%
% Friday April 10 2010 Ray Hylock <ray-hylock@uiowa.edu>
% documentclass options:
%   abstractpage            if you want to add an internal abstract (optional)
%   ackpage                 if you would like to add an acknowledgements page (optional)
%   algorithms              if you want a list of algorithms (optional)
%   appendix                if you have an appendix (optional)
%   copyrightpage           if you wish to copyright your thesis (optional)
%   dedicationpage          if you wish to make a dedication (optional)
%   epigraphpage            if you would like to add an epigraph to the beginning of your thesis (optional)
%   examples                if you want a list of examples (this uses the ntheorem package)
%   exampleslemmas          if you want a combined list of examples and lemmas (this uses the ntheorem package) (optional)
%   examplestheorems        if you want a combined list of examples and theorems (this uses the ntheorem package) (optional)
%   exampleslemmastheorems  if you want a combined list of examples, lemmas, and theorems (this uses the ntheorem package) (optional)
%   figures                 if you have any figures (this is required if you have even one figure)
%   lemmas                  if you want a list of lemmas (this uses the ntheorem package) (optional)
%   lemmastheorems          if you want a combined list of lemmas and theorems (this uses the ntheorem package) (optional)
%   nofrontmatter           suppresses the title and signiture pages for working on the body
%   tables                  if you have any tables (this is required if you have even one table)
%   theorems                if you want a list of theorems (this uses the ntheorem package) (optional)
%   phd                     if phd student; this will add the doctoral abstract (mandatory for PhD and DMA thesis candidates only)
%

% full options
%\documentclass[phd,abstractpage,copyrightpage,dedicationpage,epigraphpage,ackpage,figures,tables,lemmas,appendix]{uithesis}

% common options
%\documentclass[phd,dedicationpage,ackpage,figures,tables,appendix]{uithesis}

% example
\documentclass[phd,appendix,figures]{uithesis}

%=============================================================================
% User packages
%=============================================================================
\usepackage{bookmark}	% [recommended] for PDF bookmark generation
\usepackage{blindtext} 	% example text generation
\usepackage[ruled,chapter]{algorithm}  % display algorithms
\usepackage[super,comma,sort,numbers]{natbib}
\usepackage{amssymb}
% to place figures/subfigures
\usepackage{graphicx}
\usepackage{subfig}
% path to figures
\graphicspath{{notebooks/}{img/}{img/Aim1/}{img/Aim2/}{img/Aim3/}{img/CurrentStudy/}{img/GeneralDiscussion/}{img/GeneralMethods/}{img/Introduction/}{./betaSeriesSimulations/outputs/}{./BetaSeriesRealDataAnalysis/nibsAnalysis/outputs/}{./BetaSeriesRealDataAnalysis/firstLevelAnalysis/outputs/}{./BetaSeriesRealDataAnalysis/introductionFigures/outputs/}{./BetaSeriesRealDataAnalysis/PPITest/outputs/}}
\usepackage{forloop} % for loops display images
\usepackage{hyperref} % to insert hyperlinks
\usepackage{textcomp} % to write degree symbols
\usepackage{float} % image placement
% for smaller captions
\usepackage[labelfont=bf]{caption}
\captionsetup{font=footnotesize}
% for including csvs
\usepackage{csvsimple}
\usepackage{array}
% multiline equations
\usepackage{mathtools}
% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% https://tex.stackexchange.com/questions/370278/is-there-any-reason-to-use-inputenc
\usepackage[utf8]{inputenc} % for non-ascii characters
\newcommand{\comment}[1]{}
%=============================================================================
% prelude
%=============================================================================

\title{Task Related Correlations}
\author{James Kent}
\dept{Neuroscience}

% multipleSupervisors=true for two advisors
\setboolean{multipleSupervisors}{false}
\advisor{Assistant Professor Dr. Michelle Voss}
% for multiple advisors; change <value> to line up the names
%\setboolean{multipleSupervisors}{true}
%\advisor{Advisor 1\\\hspace{<value>mm}Advisor 2...}
%
% edit the names below to have your committee members names appear
% on the signature page.  memberOne should be your advisor.
%
\memberOne{Michelle Voss}
\memberTwo{Eliot Hazeltine}
\memberThree{Vincent Magnotta}
\memberFour{Jatin Vaidya}
\memberFive{Jan Wessel}
\submitdate{July 2020}
\copyrightyear{2020}

\Abstract{
\blindtext
}

%\dedication{Dedication here (optional)}

%\epigraph{Epigraph here (optional)}

%\acknowledgements{Acknowledgements here (optional)}

\begin{document}

\frontmatter
% cSpell:enable
%=============================================================================
\chapter{Introduction}
%=============================================================================

\begin{itemize}
	\item cognitive neuroscience draws line between brain/cognition
	\item tasks are necessary to understand how brain networks organize
	\item need to test methods that can measure brain organization
	\item two general methods are Beta Series Correlations and PsychoPhysiological Interactions
	\item Intro to BSC
	\begin{itemize}
		\item Jesse Rissman (2004): introduced LSA
		\item Jeanette Mumford (2012): introduced LSS
		\item introduce General Linear Model
		\item Benjamin Turner (2012)
		\item Abdulrahman (2016) compared LSA/LSS
	\end{itemize}
	\item Intro to PPI
	\begin{itemize}
		\item ppi's require three items in the model: psychological regressor, physiological regressor, and
		      interaction term of psychological/physiological term.
		\item 1997: Friston introduces ppi
		\item 2003: Geitman introduces deconvolution
		\item 2012: McLaren introduces gppi
		\item 2017: Di says to center psychological variable if performing deconvolution
		\item create psychological contrast of interest in the 2-condition experiment
		\item convolve the task design with the hrf, then multiply with bold signal
		\item for event related designs, deconvolve bold signal using basis functions,
			then multiply "neural" signal with task design (unconvolved), then convolve
			the neural ppi with the hrf
		\item create separate ppi's for each condition instead of creating a
		      new model for each contrast (gppi)
		\item denoise the seed region (include covariates in the basis functions)
		\item centering the psychological variable is necessary (or add deconvolve/reconvolved regressor)
	\end{itemize}
	\item previous work has compared LSA/LSS/PPI (Cisler 2014 and Xi 2020)
	\item comparisons missing LSS/LSA/PPI using mixed event/block design
	\item Intro to networks
	\begin{itemize}
		\item olaf sporns
		\item edge
		\item node
		\item simple network measures
	\end{itemize}
	\item I compared LSS/LSA first
	\item compare LSS/LSA relative to PPI
\end{itemize}
At the heart of any cognitive neuroscientist is the desire to relate the physical
processes of the brain to cognition.
The advent of functional Magnetic Resonance Imaging (fMRI) presented an amazing opportunity
to pursue the brain/cognition relationship like never before~\cite{ogawa1990}.
The serendipitous connection between blood rushing to areas of the brain where neurons
are working hardest provided the backdrop for discovering the large scale organization
of the brain at rest and discovering which brain areas are recruited for specific tasks.
A third line of inquiry combines the previous questions to ask: How does the brain
organize to complete different tasks?
Instead of observing the brain's organization while there is no explicit task or observing
the whether a particular area is strongly recruited during a particular context,
answering the question how the brain organizes during a task represents our brain state
during the majority of our lives.
Whether it's writing an email, playing a card game, talking with colleagues; we are
often engaged in tasks throughout the day.
Thus, investigating how the brain organizes during a task grants understanding how
we operate in daily life.
What do I mean by organization?
For the context of this thesis, brain organization refers to which brain areas are communicating
with each other, which is measured by a statistical dependency between
regions like a Pearson's correlation~\cite{Uddin2019}.
The eagerness to understand brain organization during tasks has outpaced the investigations
of the methods to understand brain organization.

Understanding and comparing the methods we use is critical to move the field of
human neuroscience forward.
There are innumerable choices in every step of the analysis process in
fMRI within and between software packages~\cite{Bowring2019,Carp2012}.
Even the choice of operating system can have a non-trivial impact on
analysis outcomes~\cite{Glatard2015}.
Analysis variability is not only theoretically concerning; it impacts
results when researchers attempt to answer the same experimental questions.
An enormous study by Botvinik-Nezer et al. (2020) asked 70 independent research teams
to answer 9 scientific hypotheses when given the same dataset~\cite{Botvinik-Nezer2020}.
They found consistency of results across teams were halfway between
being completely consistant and completely random.
While not necessarily reaching the level of crisis,
analytical variability is cause for serious consideration.
Methods that purportedly measure the same underlying biological process
should be put to task to evaluate whether they are as similar
as they imply.

\textbf{In this thesis, I compared three different methods that measure brain organization during a task
and provide recommendations on which method to use.}
For consistency with existing literature, a "measure of brain organization during a task" will be
investigated as \textit{context-dependent functional connectivity}, which refers to
the statistical dependency between two or more brain areas during a specific context
(i.e., reading a book, biking on a trail, tapping your finger, etc.)~\cite{Friston1997}.
There are (at least) four classes of methods that measure context-dependent functional connectivity:
sliding windows~\cite{Shine2015}, residual correlations~\cite{Cole2014a},
Beta Series Correlations (BSC)~\cite{Rissman2004}, and Psycho-Physiological Interaction (PPI) analysis~\cite{Friston1997}.
Of these classes of methods, only BSC and PPI analysis can purportedly measure the differences
between interleaved contexts (e.g., rapidly switching between two tasks).
Sliding window and residual correlation approaches can only detect contexts that are
temporally separable and not interleaved with each other.
A large swath of existing cognitive neuroscience literature contains interleaved
contexts so the focus of this work will pertain to classes of methods
that can in theory detect differences in these contexts.

In order to understand BSC and PPI analyses, a gentle introduction to the
General Linear Model (GLM) is required.
GLMs are an extension of the more familiar linear regression.
The main goal of both linear regression and GLMs is to take
a series of observations ($X$) and scale the observations by
multiplying them by numbers ($\beta$) that make the observations
look like the outcome data ($Y$).
Since it is often impossible for the observations to look exactly like
the outcome data, there is some error $\epsilon$.
The general form of the equation is shown in Equation~\ref{eq:glm}.
\begin{equation}
  Y = \beta X + \epsilon
  \label{eq:glm}
\end{equation}
A difficulty in GLMs (and linear regression) is when separate observations are very similar to one another.
For example, if someone always says "I love you" when and only when they give you a gift,
It would be difficult to say what amount of your good feelings are due to the phrase,
"I love you" and what amount are due to the gift.
In fMRI, observations are similar when they occur close in time, so if you were to see
an apple ($X_{apple}$) and an orange ($X_orange$) immediately after, it is difficult to say whether
a brain area ($Y_{brain}$) is responding solely to the apple or if the brain area is responding solely to the orange.
Thus there could be many possible numbers given to $\beta_{apple}$ and $\beta_{orange}$
to multiply with $X_{apple}$ and $X_{orange}$ that would make a solution look similar to
$Y_{brain}$.
GLMs are central to the methods I discuss, and we will revisit this problem repeatedly.
% For example, if I measured how many cats people owned
% and their current stress level, I could have the following observations:
% $PersonA(3 cats, 2 stress)$, $PersonB(1 cats, 5 stress)$, and
% $PersonA(5 cats, 1 stress)$.
% Now, if I wanted to predict stress ($Y_{stress}$) from the number
% of cats a person owns ($X_{cats}$), I need to find some number
% ($\beta_{cats}$) that when multiplied with the number of cats ($X_{cats}$),
% looks most like that person's stress level ($Y_{stress}$).
% In this example, the optimal $\beta_{cats}$ is $-1$,
% suggesting for each additional cat acquired a person's stress
% is predicted to go down by one level.

% The GLM follows the same pattern, but instead of stress and cats,
% we use the BOLD response and experimental designs
% (and sometimes other BOLD responses).
% The difference is the BOLD response is not linear, it oscillates
% due to intrinsic patterns of activity and in response to external stimuli.
% Luckily, we have an approximation of what the BOLD response looks like
% in response to a stimulus~\cite{Glover1999}.
% With the approximate shape of the BOLD response, we can transform our observations ($X$) to look
% like the BOLD responses seen in the brain $Y$.
% After the transformation, we can treat the problem similarly to linear regression, where
% we are looking for a number ($\beta$) to multiply with our observations ($X$) to look
% like our outcome BOLD data ($Y$)
% For example, I have an experiment where I show participants multiple pictures of
% 1 or 5 cats at varying times while I measure their brain activity through an fMRI scan.
% I predict the BOLD response in the visual cortex when viewing 1 cat will be different than
% viewing 5 cats.
\subsection*{Beta Series Correlations}

Jesse Rissman~\cite{Rissman2004} was the first to publish on BSC,
describing their usage in a working memory task.
In this task, participants saw a cue, a delay, and a probe, all occurring
within a short time period (~9 seconds).
The cue was presented for one second, a delay occurred for seven seconds,
and a probe was presented for one second.
Given that the blood-oxygen-level-dependent (BOLD) response
takes approximately six seconds to reach its peak, and generally takes between
16-32 seconds to return to baseline, we can begin to see a problem~\cite{Glover1999}.
The events within the trial occur too close to each other to discern what
brain responses are related to encoding the cue, the delay, or the probe.
To identify how the activated brain regions form networks, Rissman
computed beta series correlations.
Instead of having a single regressor to describe all the cue events,
a single regressor for all the delay events, and a single regressor for all the
probe events (as is done in traditional task analysis),
there is an individual regressor for every event in the experiment.
For example, if your experiment has 40 events, each with a cue, delay, and
probe event, the model will have a total of 120 regressors, fitting a $\beta$
(i.e., parameter) estimate for each event.
Once you calculate a $\beta$ estimate for each event of a given type
(e.g., cue), you will have a four-dimensional dataset where each BOLD volume
represents the $\beta$ estimates for a particular cue event.

Having one regressor per event in a single model is known as "least squares- all" (LSA).
This method, however, has limitations in the context of fast event-related
designs (e.g., designs where the events occur less than 8
seconds apart on average).
Since each event has its own regressor, events that occur very close in time
are collinear (e.g., are very overlapping).

Jeanette Mumford's and Benjamin Turner's work~\cite{Turner2010,Mumford2012} derived a solution for
the high collinearity observed in LSA by using another
type of regression known as "least squares- separate" (LSS).
Instead of having one GLM with a regressor per event,
LSS implements a GLM per event with a minimum two regressors:
1) one for the event of interest, and 2) one for every other event in the
experiment.
In the above LSA example, instead of having 1 GLM with 120 regressors,
LSS will create 120 GLMs with 2 regressors each.
This process reduces the collinearity of the regressors and creates a more reliable
estimate for each event, but also combines all other events into a single regressor
within the design matrix, which will reduce model fit.

Benjamin Turner's subsequent work~\cite{Turner2012a} improved LSS by retaining
the original event conditions in the design matrix.
In this updated version, the event of interest is given its own regressor, but all
other events retain their position.
Again, leveraging the above example with cue, delay, and probe events,
this new LSS method would create 120 GLMs with 4 regressors each (event of interest, cue, delay, and probe).
I am refering to the improved version of LSS throughout the remainder of the thesis.

While LSS addresses the immediate problem of high colinearity between regressor, it does not come without cost.
LSS $\beta$ estimates are influenced by adjacent events such that if an event in condition A
was flanked by two events in condition B, the $\beta$ estimate for the event in condition A
is likely biased (i.e., not orthogonal) to the adjacent events in condition B.

\subsection*{Psycho-Physiological Interactions}

Psychophysiological Interaction (PPI) analyses are designed to 
identify brain areas that are differentially functionally connected
during specific contexts relative to others~\cite{Friston1997}.
If this sounds like the same goal as BSC, you would be correct, although PPI
analyses take a much different approach.
There are three necessary components to any PPI.
The first is the psychological variable of interest, such as when the participant
is responding to a cue, delay, or probe as used in the above examples.
The second is the physiological variable, such as the BOLD signal from
the hippocampus.
The third variable is the PPI itself, which represents a multiplication
between the psychological variable and the physiological variable.
If our dependent variable is the BOLD signal in the medial frontal gyrus,
then we can answer the question if the hippocampus and medial frontal gyrus
are differentially functionally connected during the probe relative to the
cue.

PPI analyses have undergone several transformations since their inception in 1997 including:
1) deconvolution~\cite{Gitelman2003}, 2) multi-conditional psychological variables~\cite{McLaren2012},
and 3) correcting imperfect deconvolution~\cite{Di2017}.
The necessity of deconvolution was investigated by Gitelman~\cite{Gitelman2003} who demonstrated
that calculating a PPI at the BOLD level is not mathematically equivalent to calculating
a PPI at the neural level.
The BOLD signal is the result of an underlying neural response convolved (i.e., smeared)
with a hemodynamic response function (HRF)(Equation~\ref{eq:intro_conv_bold}).
\begin{equation}
  BOLD = HRF \circledast neural
  \label{eq:intro_conv_bold}
\end{equation}
An HRF 
Thus to calculate a PPI, there are two options:
1) deconvolve the BOLD signal to represent the neural signal
2) convolve the psychological variable with an HRF to represent BOLD signal (Equation~\ref{eq:intro_conv_psych}).
\begin{equation}
  PSYCH_BOLD = HRF \circledast psych
  \label{eq:intro_conv_psych}
\end{equation}
Brain-behavior interactions occur at the neural level, not at the
BOLD response level, as represented in Equation~\ref{eq:intro_conv_psych}.
Importantly, calculating the interaction at the BOLD level is not
equivalent to calculating the interaction the neural level~\cite{Gitelman2003}.
\begin{equation}
	(HRF \circledast neural) \cdot (HRF \circledast psych) \neq HRF \circledast (neural \cdot psych)
\end{equation}
To get the neural signal we need to deconvolve the BOLD signal (option 1).
Deconvolution of the BOLD signal is not a well defined problem since
we do not know the exact neural process that gave rise to the BOLD signal.
Therefore we have to rely on regularized regression with an overcomplete
basis set.
Overcomplete meaning there are more columns (the basis set) than there
are rows (the BOLD signal).
Since the BOLD signal is noisy and assumed hemodynamic response function
may not match the data, some software packages simply do not attempt
deconvolution and swallow the error from multiplying the physiological and psychological
variables at the BOLD level.
Other software packages bite the bullet and attempt deconvolution.
In block designs where contexts are not intermixed the difference between
methods appears inconsequntial, but with rapid event-related designs,
deconvolution is essential to separate the influence of intermixed contexts.
The implementation used in this thesis work does perform deconvolution.

The second transformation of PPI analyses came from McLaren et al. (2012)~\cite{McLaren2012}.
Their goal was to properly represent experiments with more than two experimental conditions, like
the example in the BSC section where there were cue, delay, and probe event conditions.
Traditionally, the psychological variable was actually a contrast between two event conditions, such as
$probe - cue$ to create one PPI for analyses.
McLaren et al. (2012) presented that instead of using a contrast, researchers could
calculate a separate PPI for each psychological variable independently and then
perform contrasts between the $\beta$ estimates to find differences in contextual functional connectivity.
This method is known as generalized PPI (gPPI) analysis.
The implentation used in this thesis work performs gPPI.

The third transformation of PPI analyses to date is the necessity to account for imperfect deconvolution
through centering the psychological variables or including the deconvolved/reconvolved physiological variable
in the model~\ref{Di2017}.
These solutions are needed because of the imperfections of the deconvolution process.
Deconvolution is not an invertable process so the reconvolved PPIs regressors are not
perfectly represented at the BOLD level.
Not accounting for the imperfect deconvolution process results in the PPI regressors
containing information about the baseline functional connectivity between brain areas, biasing
PPI effects to detect regions are highly functionally connected at baseline.
The implementation used in this thesis work demeans the psychological variables.



First, there are likely multiple psychological conditions you would like to model.
In my above example, there were already two psychological conditions (congruent and incongruent)
to model.
Each pyschological condition is their own variable in the model, which also
means each condition has their own PPI.
In the example scenerio, there would be a total of 5 variables in the model,
two psychological variables for congruent and incongruent events,
one physiological variable for the hippocampal BOLD signal,
and two PPIs representing the multiplication between the hippocampal BOLD signal
and congruent and incongruent events.
Multiplying the physiological and psychological variables in BOLD space
is not mathematically equivalent to multiplication in neural space.



\textbf{Specific Aim 1}: Evaluate whether LSS or LSA is better
\newline
\newline
\textit{Rationale}: Should researchers reach to LSA for their analysis of condition specific differences
or should they use the more computationally intensive LSS?

\textit{Hypothesis}:
LSS will have more sensitivity and more specificity for both block and event-related designs.
\newline
\newline
\textit{Method}:


\textbf{Specific Aim 2}: Compare LSS/LSA to the standard method of PPI
\newline
\newline
\textit{Rationale}: PPI is considered the gold standard.
\newline
\newline
\textit{Hypothesis}:
LSS will outperform PPI
\newline
\newline
\textit{Methods}:
these methods

%=============================================================================
\chapter{Comparing LSS/LSA}
%=============================================================================

\section*{Introduction}
\label{intro}

Cognitive neuroscience blends cognitive tasks with measures of brain activity to drive discoveries.
These cognitive tasks often incorporate multiple conditions interleaved with each other,
and the cognitive process of interest is manifested as the difference between those conditions.
The most common analysis of tasks completed during functional magnetic resonance imaging (fMRI)
examines the magnitude of brain activity.
More recently, the importance of examining how brain regions act together as networks has become increasingly evident.
Broadly defined, a brain network is a collection of brain regions that share information~\cite{Uddin2019}.
Brain networks have primarily been investigated while participants are at rest, but there
is rising interest in observing brain networks while participants perform tasks~\cite{Cole2014a}.
There is also increasingly popular to measure dynamically changing correlations
within and between brain networks over time~\cite{Sakoglu2008,Hindriks2016}.
However, there has not been investigation and validation of brain networks
when participants engage in tasks with interleaved conditions that could induce
different brain networks dynamically~\cite{Di2019a}.
In other words, measuring contextual brain networks has not been validated within fast event-related designs~\cite{Buckner1998}.
We seek here to validate and compare two methods that may measure brain responses to events that occur
close in time.

The overarching method being investigated is beta series correlations (BSC)~\cite{Rissman2004,Mumford2012,Turner2012a,Abdulrahman2016}
There are two main approaches to estimate the beta series for BSC: Least Squares All (LSA) and Least Squares Separate (LSS)~\cite{Mumford2012}.
Both approaches of beta series estimation seek to derive single event estimates that represent a brain region's
(or voxel's) activity at each individual event.
An event is defined as "a stimulus or participant response recorded during a task."~\cite{Gorgolewski2016}
Where task is defined as "a set of structured activities performed by the participant."~\cite{Gorgolewski2016}
The single event estimates become difficult to estimate when events occur close together (Figure~\ref{fig:introhrf}).
Such designs are called fast event-related designs and are commonly
used in cognitive neuroscience.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{introduction-hrf}
  \caption{
    Model of the Hemodynamic Response Function (HRF)~\cite{Glover1999} at a
    typical resolution of an fMRI scan (2 seconds).
    The x-axis represents time in seconds and the y-axis is arbitrary units.
    Fast event-related designs with inter event intervals (IEIs) at or faster than time to peak
    response (e.g., 4-6 seconds), need to account for the overlapping signals.
  }
  \label{fig:introhrf}
\end{figure}

The BOLD response is an indirect measure of neuronal activity that takes approximately 6 seconds to
peak and around 16-32 seconds to effectively return to baseline~\cite{Glover1999}.
If events occur (on average) 4 seconds apart, the difficulty of single event estimation
becomes apparent.
In this situation, it is difficult to ascertain whether BOLD activity should be attributed to a target event or an
adjacent event.
LSA and LSS approach this problem differently.
LSA ignores this problem by calculating a high variance, but low bias measure by enforcing orthogonality
between events,
whereas LSS calculates a lower variance, but more biased measure, relaxing the orthogonality restriction.
To understand how LSA and LSS differ in their restrictions of orthagonality in single event estimation,
it is necessary to introduce the General Linear Model (GLM).
GLMs are a mainstay in the neuroimaging literature, allowing researchers to model
a curve that approximates the BOLD response shape and linearly scale the curve
to best match the data~\cite{Friston1995}.
The multiplicative that linearly scales the model BOLD response is known as a beta,
and provides the namesake for beta series.
This beta is often interpreted as the amplitude of the response, which is true when the
model approximates the shape of the BOLD response well, and becomes less clear when
the model does not match the shape of the BOLD response.
In a traditional GLM, events of the same type will be grouped together
to provide a robust estimate of whether a particular region or set of regions are
active relative to some baseline or another condition (Figure~\ref{fig:introGLM}).

\begin{figure}[H]
  \centering
  \includegraphics[width=0.2\textwidth]{introduction-normalGLM}
  \caption{
    An example of a design matrix seen in a traditional GLM used in fMRI~\cite{Friston1995}.
    There is a single column for each condition, resulting in two columns (intercept column ignored for clarity).
    With this design you can answer questions about which voxels are more or less active in one condition
    versus another, but you cannot see which voxels vary together over stimulus presentations.
  }
  \label{fig:introGLM}
\end{figure}

Grouping together events of the same type, however, does not tell you which regions are acting in concert
in response to the event type.
The traditional GLM produces a single beta estimate per event type, but to measure which regions
are acting in concert; you would need a beta estimate per event.
For example, it could be the case that for half of the events of the same type regions $A$ and $B$ are active,
and for the other half, regions $A$ and $C$ are active.
The traditional GLM will not be able differentiate the different pairs of regions.
LSS and LSA, on the other hand, propose to be able to identify region $A+B$ and $A+C$.
LSA takes a variant of the traditional GLM whereby instead of providing a beta
estimate for a group of events, each event gets its own beta estimate in a single GLM (Figure~\ref{fig:introlsa}).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-lsa}
  \caption{
    Left shows an example design matrix for LSA where each event gets its own column.
    Since we receive a beta estimate per column, we end up with as many beta estimates as there
    are events.
    We can combine those beta estimates to create a beta series (Right) for each condition.
    In this example we measured beta series for 2 voxels, allowing us to
    correlate the betaseries from one voxel to another.
    We can perform the correlation for the 2 conditions (Condition 0 and Condition 1).
    The arrows on the design matrix (left) correspond to the beta estimates of those events
    on the shaded regions (right).
  }
  \label{fig:introlsa}
\end{figure}

LSS differs from LSA by fitting a separate GLM for each event, where in each model a target
event is fit and the rest of the events are grouped together and given separate beta estimates (Figure~\ref{fig:introlss}).
LSS was introduced by placing all other events into a single regressor, but as shown in Figure~\ref{fig:introlss},
each event type has its own regressor, which is referred to as LSS-N in other papers~\cite{Rissman2004,Abdulrahman2016,Mumford2012}.
We will refer to LSS-N as LSS for the remainder of the manuscript.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-lss}
  \caption{
    Left shows an example design matrix for LSS where each event gets its own model
    (intercept excluded for clarity).
    The target event (outlined in red) comes from either condition 0 or 1.
    For example, if the target event is from condition 1, the remaining condition 1 events
    get their own column, and all of the condition 0 events get their own column.
    Since we receive a beta estimate per model, we end up with as many beta estimates as there
    are events.
    We can combine those beta estimates to create a beta series (Right) for each condition.
    In this example we measured a beta series for 2 voxels, allowing us to
    correlate the betaseries from one voxel to another.
    We can perform the correlation for the 2 conditions.
    The arrows on the design matrix (left) correspond to the beta estimates of those events
    on the shaded regions (right).
  }
  \label{fig:introlss}
\end{figure}

The target event estimate from each GLM is taken to form a beta series.
Harkening back to the sluggish BOLD response, LSA suffers when the events are close together,
since the GLM cannot reliably attribute which BOLD response should correspond to which event (Figure~\ref{fig:introGLM}).
LSS attempts to reduce the model confusion by having one event estimate per model,
so the non-target events have their beta estimate influenced by multiple observations, loosening the
constraint that adjacent events to the target event need to be orthogonal (i.e., independent) from each other.
While previous work has simulated beta series and evaluated beta series on participant data,
several key gaps remain~\cite{Mumford2014a,Mumford2012,Turner2012a,Abdulrahman2016,Cisler2012,Arco2018}.
One, simulations have not taken into account realistic noise structure of fMRI data such as autocorrelations, movement, and phsyiological noise.
Two, simulations have not used optimized fast event-related designs, only randomly selected designs. 
Three, empirical selections of signal to noise ratios have not been considered,
ratios were chosen without justification in previous work~\cite{Abdulrahman2016,Mumford2012}.
Four, a quantitative comparison of LSA and LSS condition contrasts for BSC has not been done.
The present work fills these gaps and provides recommendations for further research
using LSA and LSS.
Important terms used used throughout the paper are presented in Table \ref{table0}.

\begin{table}[H]
  \centering
  \caption{
  {\bf Acronym Definitions}}
  \begin{tabular}{|l|l|p{60mm}|}
  \hline
  Name & Acronym & Definition\\
  Least Squares All & $LSA$ & beta estimation method where each event gets a regressor in the same model\\ \hline
  Least Squares Separate & $LSS$ & beta estimation method where each event gets a separate model\\ \hline
  Contrast Noise Ratio & $CNR$ & $A_S/\sigma_N$, amplitude of signal ($A_S$) divided by standard deviation of the noise ($\sigma_N$)\\ \hline
  Activation Variation Noise Ratio & $AVNR$ & $\sigma_S/\sigma_N$, standard deviation of signal ($\sigma_S$) divided by standard deviation of the noise ($\sigma_N$)\\ \hline
  \end{tabular}

  Definitions of the main acronyms use in this paper.
  $CNR$ and $AVNR$ definitions are found in Welvaert (2013)\cite{Welvaert2013a}.
  \label{table0}
\end{table}

\section*{Materials and methods}
\label{methods}

Testing and validation of beta series correlations followed three stages.
First, beta series correlations were tested in simulations across different
optimized experimental designs.
Second, beta series correlations were tested in simulations using an experimental
design that was used to collect participant data.
Third, beta series correlations were validated in task data collected from
participants.
Resting state data collected from the same participants were used as a null
control for beta series correlations in stage three.
The null control measures the number of spurious results found
with BSC since there is no expectation of BSC to change
during resting state.

\subsection*{Beta Series Correlation Simulations}
\label{methods:bsc-simulations}

To assess the validity and power of beta series correlations,
we simulated 2 voxels of fMRI time-series data and convolved short (0.2 second)
task onsets with a double gamma function
and added the responses to the time-series~\cite{Glover1999,Welvaert2011}.
We used fmrisim from the brainiak toolbox\cite{Ellis2020} to generate a
2 voxel fMRI time-series containing drift, autocorrelation ($\rho$ = 0.5), physiological noise,
task related movement, and scanner noise (Figure~\ref{fig:simulation_example}).
Noise features were all weighted equally in the simulations.

\begin{figure}[H]
  \centering
  \includegraphics{methods-simulation_example}
  \caption{
    Example of predicted BOLD from a task design (thick grey line), real BOLD
    from a participant (see \nameref{methods:task-switch}), and simulated BOLD
    from fmrisim~\cite{Ellis2020}.
    The simulated BOLD appears similar to real BOLD.
  }
  \label{fig:simulation_example}
\end{figure}

For all simulations the time of repetition was set to 2 seconds.
We varied the contrast-to-noise ratio (CNR) using the amplitude of the activation
divided by the standard deviation of the noise~\cite{Welvaert2013a}.
Another parameter deemed critical by previous work is the standard deviation
of the raw beta estimates relative to the standard deviation of the noise~\cite{Abdulrahman2016},
so this measure was also varied in our analysis.
To distinguish the measure from our use of CNR,
we've decided to rename it as Activation Variance to Noise Ratio (AVNR).

To generate realistic numbers for simulating time-series at varying CNRs and AVNRs
we used an unpublished dataset on task switching in older adults (N=40).
We ran LSS/LSA to get both event estimates of activation (i.e., betas)
as well as residuals from the model.
To calculate CNR, several steps were taken.
First, we masked the beta series using two different atlases:
an "Activation" atlas based on peak BOLD responses seen in the data,
and the Schaefer Atlas\cite{Schaefer2017}(see \nameref{methods:atlas-corr-analysis}).
Second, we extracted the absolute value of all masked beta estimates for a participant.
Third, we measured the median beta estimates over all events resulting
in a median beta estimate amplitude for all regions of interest (ROIs).
Fourth, we calculated the standard deviation of the residuals for each ROI.
Fifth, we divided the median amplitude beta estimates by the standard deviation of the residuals
for each ROI.
Sixth, we selected either the mean or max CNR across all ROIs to provide a reasonable estimate
and upper bound of CNR.
Calculating AVNR followed the same procedure as CNR with the exception of the first two steps.
First, we calculated the standard deviation of the beta estimates, then we followed steps three through six above
on the standard deviation of the beta estimates (as opposed to the amplitude).
Based on these calculations used on participant data, we chose to move forward using CNR and
AVNR values of 1 and 2 as reasonable representative values (Table~\ref{table1}).
We performed subsequent analyses in parallel using all combinations of these representive values to probe the relative importance of AVNR and CNR
in influencing the power of beta series correlations.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/cnr_trial_variability.ipynb}{see here for the relevant code})

\begin{table}[H]
	\centering
	\caption{
	{\bf Summary of AVNR and CNR measures in Participant Data}}
	\begin{tabular}{|l+l+l|l|l|l|}
	\hline
	Atlas & Method & CNR (mean) & CNR (max) & AVNR (mean) & AVNR (max)\\
	$Schaefer$ & $LSS$ & 0.71 & 1.81 & 1.03 & 2.33\\ \hline
	$Activation$ & $LSS$ & 0.99 & 1.58 & 1.42 & 2.18\\ \hline
	$Schaefer$ & $LSA$ & 1.02 & 2.48 & 1.54 & 3.61\\ \hline
	$Activation$ & $LSA$ & 1.42 & 2.18 & 2.15 & 3.26\\ \hline
	\end{tabular}
	The average and maximum CNR and AVNR for both atlases (Schaefer and Activation)
	as well as estimation method (LSS and LSA).
	LSS tends to give lower CNR/AVNR since the measure sacrifices
	variance for bias, unlike LSA, which retains a high variance and a low bias.
	\label{table1}
\end{table}

The choice of onset times was varied based on average inter-event-interval (IEIs).
The IEI is the time from the previous event onset to the next event onset.
We chose average IEIs at 2, 4, 6, and 8 seconds to reflect a common range of IEIs
for fast event-related design experiments~\cite{Hennigan2015,Dichter2007,Goghari2009}.
We also varied the number of events, choosing 15, 30, 45, and 60 events per condition,
which also appears to be common selections for fast event-related design experiments.
The optimization of event onsets was done with neurodesign~\cite{Durnez2018}.
We chose to optimize A-Optimality for onset selection using the genetic algorithm implemented
in neurodesign, selecting onsets with an exponential distribution.
The top 20 designs were chosen from neurodesign to reduce the likelihood
that the simulation results would be an artifact of idiosyncrasies
of the optimized experimental design.

The beta weights for each voxel pair were chosen from a multivariate normal distribution
with a mean of 1 and with a fixed ground truth correlation between the 2 voxels 
(varying between 0.0-0.9) with AVNR of either 1 or 2.
The ground truth correlation was varied to ensure the ground truth correlations were above
and below the correlations of the noise time-series between the 2 voxels,
since both voxels had shared noise sources from simulated motion.
The beta weights were convolved with a hemodynamic response function and scaled
relative to the noise standard deviation to CNRs of 1 or 2.
(\href{https://github.com/jdkent/betaSeriesSimulations/tree/34bf1ff5b05c0eeae855f0e8e1267765bf14999a/beta_sim}{see here for simulation code})

200 simulations were run for each combination of event number
(15, 30, 45, 60) IEI (2, 4, 6, 8),  CNR (1, 2), AVNR (1, 2), condition (c0, c1),
and ground truth correlation
(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
resulting in 256,000 total simulations.
Within each 200 simulation combination, the 20 top task designs specified by
neurodesign were evenly applied to the simulations, resulting in 10 simulations
using the same design.
Each simulation of 2 voxels can be imagined as a unique participant or run from
the same participant.

To ensure interpretability of our power analyses, we tested
the expected false positive rate when there is no difference between samples.
we took 2 samples (n=50) with the same ground truth correlation (e.g., 0.1)
matching on event number, IEI, CNR, and AVNR, and ran a t-test to measure if the samples
were statistically significantly different (p $<$ 0.05).
Since the ground truth correlation is the same between samples,
we expect a false positive rate of \%5 at an alpha of 0.05.
We repeated this process 10,000 times to measure the false positive rate as
the number of statistically significant t-tests.

Once the false positive rate was established, we established power with the same method as above,
but with samples containing different ground truth correlations.
We selected 2 samples for which there was a 0.1 (Pearson's r) correlation difference.
A 0.1 correlation difference was chosen based on reported differences found in other published
reports as well as the task used in this report~\cite{Katsura2014,Lee2017,Turner2017,Lin2019,Huang2019}.
This process was also repeated 10,000 times to establish power.
Thus we detected efficacy with which correlation differences could be detected
using different task design and noise parameters.

Simulating data using the same task design as the participant data followed the same
procedure as above, varying CNR (1, 2), AVNR (1, 2), condition,
and ground truth correlation (0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9).
IEI and event number were not varied since those parameters are fixed by the
task design.
Each parameter combination was simulated 1000 times resulting in a total of 240,000 simulations.
False positive rate and power were evaluated using the same procedure as the other simulated data.

\subsection*{Participant Data Validation}
\label{methods:task-switch}

To validate the betaseries simulations we used an unpublished dataset
of older adults ($N$=61, 31 female, age=71.75$\pm$4.77, education=17.07$\pm$2.66)
performing a mixed design task switching task.
Numbers reported are mean$\pm$standard deviation.
Prior to any experimentation, participants provided verbal and written consent
to participate in the research presented in this manuscript, which was approved
by the University of Iowa's Institutional Review Board.
21 participants were excluded in the primary analysis for having over
0.5mm of total movement (framewise displacement) in 100 volumes or more,
resulting in a final $N$ of 40.
We chose 100 volumes to keep the number of regressors in LSA
(which already includes as many regressors as events) a reasonable size
for single event beta estimation since we included each outlier volume
as a regressor as well.
Task switching was performed in a mixed block/event-related design containing
5 blocks (2 single task blocks and 3 dual task blocks).
There was a 30 second rest between each block.
There were 30 events during each single event block,
and for the 3 dual blocks there were 48 repeat events and 39 switch events total.
The single tasks consisted of identifying a number between
1 and 10 (excluding 5) as high/low or odd/even, using their left and right index fingers
on a fiber optic response pad.
Participants were cued to which task they were performing by the color of the square
the number was presented on (blue or pink).
Each stimulus was presented for 1.5 seconds, and participants were allowed
to respond within 2.0 seconds of stimulus onset.
The average IEI was 3.5 seconds following an exponential distribution.
All stimuli were presented using E-Prime.
Participants practiced an abridged version of this task in a mock scanner
prior to the real scan and had 4 practice events in the real scanner immediately
prior to performing the task to ensure proper finger placement and data acquisition.

Participants' average accuracy and reaction time were:
single, (92\%$\pm$27\%, 792ms$\pm$225ms); repeat, (89\%$\pm$31\%, 1001ms$\pm$278ms);
and switch, (83\%$\pm$36.8\%, 1108ms$\pm$289ms).
Due to data collection error, behavioral data were not collected for 3 participants
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/summarizeBehavior/summarize_behavior.ipynb}{see here for relevent code})

The task switch bold \emph{fmriprep} output in MNI152NLin2009cAsym space
was analyzed with \emph{Nistats} for first and second level analyses.
We used mean white matter signal, mean cerebrospinal fluid signal,
discrete cosine basis filter (high pass filter), framewise displacement, the first four non-steady volumes, and
all identified motion outliers as regressors in the first level model for each participant
in addition to event onsets convolved with a double gamma function~\cite{Glover1999}.
Each image was smoothed with a 6mm full-wide half-max kernel.
We derived 3 contrasts of interest: $switch - repeat$, $dual- single$, and $repeat - single$.
The $dual$ condition is the weighted average of $switch$ and $repeat$ to represent the global cost~\cite{Wylie2000}.
We ignored correctness of the participant's response since it was not essential to
separate condition and error processing to validate BSC.

Second level analyses were a summary of the first level results presenting which
regions were robustly activated among participants.
For each contrast, the alpha was set to 0.01 with a cluster threshold of 10 voxels using
false discovery rate error control (Figure~\ref{fig:stat_maps}).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth,height=0.8\paperheight,keepaspectratio]{contrast_summary}
  \caption{
    Univariate statistical maps of second level results representing
    all contrasts of interest, $dual - single$, $repeat - single$, $switch - repeat$}
  \label{fig:stat_maps}
\end{figure}

In addition to the task switching task, participants also completed
two 8 minute resting state runs.
We used the resting state runs as a null model for task switching as done
in other reports validating analyses~\cite{Eklund2016,Olszowy2019}.
While the task switch data had 471 volumes, each resting state run only had
240 volumes.
In order to match the length of the resting state data with the task data, we concatenated
the two resting state runs while cutting off the first 10 volumes of the second run
and interpolating 1 volume between the two runs, resulting in 471 volumes.
The interpolation helps transition the bold series from one run to the next,
analogous to interpolation performed when scrubbing high motion volumes~\cite{Power2014a}. 
This null task data was treated equivalently to the task switching data for the
beta series correlation analysis.
(\href{https://github.com/jdkent/validateBetaSeries/tree/195ad5b4201971038dbbf8f73a3c537caf032743}{see relevant code here})

\subsection*{Scanner Parameters}
\label{methods:scanner}

MRI data were collected on a 3T GE Discovery 750w using a 32 channel head coil.
The anatomical T1w images were collected using a SPoiled Gradient-Recalled (SPGR) sequence
sagittally with a flip angle of 8$^{\circ}$, echo time of 3.168ms,
repetition time of 8.388ms, inversion time of 900ms, isometric voxel sizes of 1mm,
[256x256] acquisition matrix with 196 slices, field of view 25.6cm x 25.6cm.
The functional bold images were collected using a Gradient Echo sequence axially from
the bottom up sequentially with a flip angle of 80$^{\circ}$, echo time of 30ms,
repetition time of 2000ms, voxel sizes of 3.44x3.44x4.00mm on a [64x64] acquisition matrix
with 37 slices, field of view 22cm x 22cm.

\subsection*{Preparing fMRI}
\label{methods:fmriprep}

Results included in this manuscript come from preprocessing performed
using \emph{fMRIPrep} 1.5.7 (\cite{fmriprep1}; \cite{fmriprep2}; RRID:SCR\_016216),
which is based on \emph{Nipype} 1.4.0
(\cite{nipype1}; \cite{nipype2}; RRID:SCR\_002502).


\subsubsection*{Anatomical data preprocessing}
\label{methods:anat}

The T1-weighted (T1w) image was corrected for intensity non-uniformity
(INU) with \texttt{N4BiasFieldCorrection} \cite{n4}, distributed with
ANTs 2.2.0 \cite[RRID:SCR\_004757]{ants}, and used as T1w-reference
throughout the workflow.
The T1w-reference was then skull-stripped with a \emph{Nipype} implementation
of the \texttt{antsBrainExtraction.sh} workflow (from ANTs), using OASIS30ANTs
as target template.
Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and
gray-matter (GM) was performed on the brain-extracted T1w using
\texttt{fast} \cite{fsl_fast} [FSL 5.0.9, RRID:SCR\_002823,][].
Brain surfaces were reconstructed using \texttt{recon-all} \cite{fs_reconall},
[FreeSurfer 6.0.1, RRID:SCR\_001847,][] and the brain mask estimated
previously was refined with a custom variation of the method to
reconcile ANTs-derived and FreeSurfer-derived segmentations of the
cortical gray-matter of Mindboggle \cite[RRID:SCR\_002438,]{mindboggle}.
Volume-based spatial normalization to standard space (MNI152NLin2009cAsym)
was performed through nonlinear registration with \texttt{antsRegistration}
(ANTs 2.2.0), using brain-extracted versions of both T1w reference and the T1w template.
The following templates were selected for spatial normalization: \emph{ICBM 152 Nonlinear
Asymmetrical template version 2009c} {[}\cite{mni152nlin2009casym},
RRID:SCR\_008796; TemplateFlow ID: MNI152NLin2009cAsym{]}.

\subsubsection*{Functional data preprocessing}
\label{methods:func}

For each of the two BOLD runs (task switch and null data) per subject,
the following preprocessing was performed.
First, a reference volume and its skull-stripped version were generated
using a custom methodology of \emph{fMRIPrep}.
Susceptibility distortion correction (SDC) was omitted.
The BOLD reference was then co-registered to the T1w reference using \texttt{bbregister}
(FreeSurfer) which implements boundary-based registration \cite{bbr}.
Co-registration was configured with 6 degrees of freedom.
Head-motion parameters with respect to the BOLD reference (transformation matrices,
and 6 corresponding rotation and translation parameters) are estimated before any
spatiotemporal filtering using \texttt{mcflirt} \cite[FSL 5.0.9,]{mcflirt}.
The BOLD time-series were resampled into a standard space, correspondingly
generating the following \emph{spatially-normalized, preprocessed BOLD runs}:
MNI152NLin2009cAsym.
Several confounding time-series were calculated based on the \emph{preprocessed BOLD}:
% only used a subset of the confounding variables
framewise displacement and two region-wise global signals.
framewise displacement was calculated for each functional run, using its
implementation in \emph{Nipype} following the definitions
by Power et al. (2014)\cite{power_fd_dvars}.
The two global signals were extracted within the
cerebrospinal fluid and the white matter masks.
High-pass filtering the \emph{preprocessed BOLD} time-series was done using
a discrete cosine filter with 128s cut-off.
The head-motion estimates calculated in
the correction step were also placed within the corresponding confounds file. 
Frames that exceeded a threshold of 0.5 mm framewise displacement or 1.5 standardised DVARS
were annotated as motion outliers.
An additional 4 frames at the beginning of each run were also
annotated as outliers to allow the magnet to reach equilibrium.

All resamplings were performed with \emph{a single interpolation step} by composing all the pertinent
transformations (i.e.~head-motion transform matrices, co-registrations to anatomical
and output spaces).
Gridded (volumetric) resamplings were performed using \texttt{antsApplyTransforms} (ANTs),
configured with Lanczos interpolation to minimize the smoothing effects of other kernels
\cite{lanczos}.

\subsection*{BetaSeries Correlations}
\label{methods:bsc}

\subsubsection*{Beta Series Modeling}
\label{methods:bsc_model}

The LSS models were generated for each event in
the task following the method described in \cite[Turner (2012)]{Turner2012a}, using
Nistats 0.0.1b2.\\
Prior to modeling, preprocessed data were masked, and mean-scaled over
time.
Mean scaling was not applied when calculating CNR and AVNR so the
beta estimates would be in the original BOLD units.
For each event, preprocessed data were subjected to a GLM
in which the event was modeled with its own regressor, while
all other events from that condition were modeled in a second regressor,
and other conditions were modeled in their own regressors.
So if the task has 3 conditions, 
a single GLM would have 4 event regressors, 1 for the target
event, and 3 for the remaining conditions.

The LSA model was generated following the method described in
\cite[Rissman (2004)]{Rissman2004}, using Nistats 0.0.1b2.
Each event was given its own regressor in a single GLM, such that
if the experiment had 100 events, there would be 100 regressors in the GLM.

Each event regressor was convolved with a glover hemodynamic response
function~\cite{Glover1999}.
In addition to event regressors, average white matter signal, average csf signal,
cosine basis set high pass regressors, the initial four non steady-state volumes, 
and motion outliers were included
in the model as calculated in \nameref{methods:func}.
AR(1) prewhitening was applied in each model to account
for temporal autocorrelation.

After fitting each model, the parameter estimate (i.e., beta) map
associated with the target event's regressor was retained and
concatenated into a 4D image with all other events from the same
condition, resulting in a set of $X$ 4D images where $X$ refers to the
number of conditions in the task.
The number of volumes in each 4D beta series image
represents the number of events in that condition.

\subsubsection*{Atlas Correlation Analysis}
\label{methods:atlas-corr-analysis}

The 4D beta series image for each condition in the task was subjected to
an ROI-to-ROI correlation analysis
to produce condition-specific correlation matrices.
For the simulation data, ROI-to-ROI correlations were calculated by
treating each voxel as an ROI.
In the participant data; two atlases were used to generate ROI-to-ROI correlation matrices.
We created an activation atlas representing regions that were
consistently activated across event conditions (see \nameref{methods:task-switch}).
This atlas has coverage across several cortical and subcortical regions.
The second atlas, Schaefer Atlas (400 parcels, 17 networks)\cite{Schaefer2017}, was
used to comprehensively cover the cortex and test robustness of results.

An activation atlas was generated based on an F-test across the switch, repeat, and single conditions
to identify regions that were reliably activated for all participants (Table~\ref{table:clusters}).
5mm spheres were drawn around each statistical peak (21 peaks total) (Figure~\ref{fig:methroimap}).

\begin{table}[H]
  \csvautotabular[separator=tab, no check column count]{./data/cluster_table.tsv}
  \caption{
    The peak MNI coordinates/Z-statistic identifying clusters/sub-clusters from the overall
    response contrast.
    These peaks were used to create regions of interest (ROIs) to form an atlas representative
    of the most consistently activated regions across conditions.
  }
  \label{table:clusters}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{stat-map-overall_resp_with_rois}
  \caption{
    ROIs drawn from the peak Z-score table, placing a sphere with a 5mm radius
    at each peak coordinate.
    The clusters are identified in their approximate locations
    with their ID.
  }
  \label{fig:methroimap}
\end{figure}

\begin{table}[H]
  \csvautotabular[separator=tab]{./data/schaeferbest_rois.tsv}
  \caption{
    The top 20 ROIs from the Schaefer 400 (17 Network) identified with a highest CNR as measured by
    both LSS and LSA.
  }
  \label{table:parcels}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{schaefer_high_cnr_rois}
  \caption{
    20 ROIs selected from the Schaefer 400 parcels; 17 network atlas for having the
    highest CNR for both LSS and LSA.
  }
  \label{fig:schaefertopmap}
\end{figure}

In order to increase the likelihood of being able to detect a real result using the Schaefer atlas,
we selected the top 25 ROIs with the highest CNR using LSA and LSS separately
(see \nameref{methods:bsc-simulations} for how we calculated CNR).
We then took the intersection of the two ROI sets resulting in 20 ROIs that have a high CNR
as measured by LSA and LSS (Table~\ref{table:parcels},Figure~\ref{fig:schaefertopmap}).
We refer this subset of ROIs as the SchaeferTop20 Atlas for the rest of the manuscript.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/cnr_trial_variability.ipynb}{see here for relevant code}).
The results for the entire 400 ROI altas are shown in the supplementals.

Outlier beta estimate volumes were identified and discarded using a
modified Nipype function for outlier detection
(\href{https://github.com/HBClab/NiBetaSeries/blob/a45c0a1f/src/nibetaseries/interfaces/nilearn.py#L153}{see here}) \cite{Crosby1994}.
The correlation coefficient estimator used for generating correlation matrices
was empirical covariance, as implemented in Nilearn 0.4.2~\cite{Abraham2014}.
Correlation coefficients were converted to normally-distributed z-values using
Fisher's r-to-z conversion~\cite{Fisher1915}.

In the participant data, BSC generated correlation matrices for each condition (dual, switch, repeat, single),
each method, (LSA and LSS), each data type (real and null), and each participant (N=40).
The first check performed was contrasting the real dual condition and null dual condition
to ensure BSC from a task are different than BSC from null data.
A paired t-test was run on each ROI-ROI pair for the activation atlas, totaling 210 comparisons
between task and null.
We next contrasted $dual - single$, $repeat - single$, and $switch - repeat$, for LSS/LSA in both
real and null data.

Since we do not have a ground truth for which ROI-ROI pairs should be different between conditions,
we used a binomial test across all ROI-ROI pairs to discover if the number of observed significant ROI-ROI pairs was greater
than 5\%.
We did not use false discovery rate correction on the observed p-values since we were not interested in
which specific ROI-ROI pair correlations were likely to be true positives, but rather if the number of positives
observed would be expected by chance alone or if LSS/LSA likely detected an overall difference between event conditions.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/beta_series_analysis.ipynb}{see here for relevant code})

\subsection*{Software Dependencies}
\label{methods:software-dependencies}

The results in this manuscript are dependent on many open source
libraries, while we have inevitably missed providing all due credit,
we would like to acknowledge some of the main libraries used in 
\emph{fMRIPrep} 1.5.7\cite{fmriprep1} and \emph{NiBetaSeries} 0.6.0\cite{Kent2018}.

Many internal operations of \emph{fMRIPrep} use \emph{Nilearn} 0.6.1
\cite[RRID:SCR\_001362]{nilearn}, mostly within the functional
processing workflow. For more details of the pipeline, see
\href{https://fmriprep.readthedocs.io/en/latest/workflows.html}{the
section corresponding to workflows in \emph{fMRIPrep}'s documentation}.

Additional libraries used in the \emph{NiBetaSeries} workflow include
\emph{Pybids} 0.9.5 \cite{Yarkoni2019}, \emph{Niworkflows} 1.0.4,
\emph{Nibabel} 2.4.1, \emph{Pandas} 0.24.2 \cite{McKinney2010}, and
\emph{Numpy} 1.18.1 \cite{VanDerWalt2011, Oliphant2006}.

In addition to the data analysis, visualization of results depended
on matplotlib\cite{Hunter2007}, seaborn\cite{Waskom2020}, nilearn,
jupyter notebooks\cite{Kluyver2016a}, and the packages they depend on.

%%%%%%%%%%%%%%%%%%%%%%%%
%% RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Results}
\label{results}

\subsection*{Beta Series Correlation Simulations}
\label{results:bsc-simulations}

The first stage of BSC testing focused on simulations with varying event numbers,
IEIs, CNRs, AVNRs, and estimation method.
For proper interpretation of the power analyses, we first established whether
a 5\% false positive rate was found across all combinations of
event numbers, IEIs, CNRs, AVNRs, and estimation method.
We found a nominal \%5 false positive rate held across all combinations
of parameters (Figure~\ref{fig:res_sim_fpr}).
With the false positive rate established, we next observed how detectable a
correlation difference of 0.1 was across all parameters.

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{avnr-1_smalldiff}}

  \subfloat{\includegraphics[width=\textwidth]{avnr-2_smalldiff}}

  \caption{
    Detection power of a small difference between conditions (r=0.1).
    LSS at least marginally outperforms LSA in most simulated experimental
    designs, with a large difference in power when IEI is 4 seconds and
    CNR is high.
    LSS appears to have an advantage in low CNR scenerios across the longer IEIs
    when AVNR is high.
    Each bar represents a sample of 50 pairs of correlations
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:res_sim_smalldiff}
\end{figure}

At an IEI of 2 seconds, there is no discernable difference between LSS and LSA.
Since the simulated data were sampled at 2 second intervals, the result
corresponds to effectively presenting a stimulus during each frame.
With such overlapping simulated BOLD responses detecting a difference between conditions
is unlikely.
From an IEI of 4 seconds and upwards, LSS has greater detection power than LSA.
Increasing the number of events beyond 30 appears to increase detection power only if the CNR is greater than 1.
Increasing the CNR improves detection power more than increasing the AVNR, although increasing either
CNR or AVNR improve detection power.
% add the numbers to say what the difference between CNR and AVNR
For LSS, the 8 second IEI does not appear to greatly increase detection power beyond a 6 second IEI.

\subsection*{Participant Data Beta Series Correlations}
\label{results:bsc-taskswitch}

We simulated data using the task switching design for stage two of beta series
validation and found comparable
results to the previous simulations, with LSS outperforming LSA.
To achieve 80\% power assuming a CNR of 2 and AVNR of 2, 50 participants were sufficient for LSS, but LSA
% say what percent power 
did not approach 80\% power within our tested range of 5-60 participants.
However, it is important to note that the present analysis only included 40 participants with adequate data,
indicating all subsequent analyses will be moderately underpowered.

\begin{figure}[H]
  \includegraphics[width=\textwidth]{taskswitch-switchXrepeat_smalldiffparticipants}
  \caption{
    Simulations from the task design used to collect the real data.
    LSS achieves 80\% power when N=50, but LSA only achieves \~60\% power at N=60.
    CNR and AVNR were set to 2, meaning this is an optimistic power analysis
    for a correlation difference of 0.1.
  }
  \label{fig:taskswitch-simulation}
\end{figure}

% reword this sentence
We looked at task switching data from the most lenient
contrast ($task - null$) to several block contrasts ($dual - single$ and $repeat - single$)
to an event-related contrast ($switch - repeat$)
to assess how well LSS and LSA detect ROI-ROI correlation differences between conditions.
We performed the same contrasts (excluding $task - null$)
using null data to measure the specificity of each method.

We found both LSS and LSA had a greater number of statistically significant ROI-ROI pairs than expected by chance
for the contrasts in the activation atlas $task - null$ (LSS: 12.86\%; p $<$ 0.001, LSA: 11.90\%; p = 0.001).
LSS had a greater number of statistically significiant ROI-ROI pairs than expected by chance within the 
$dual - single$ contrast (LSS: 9.05\%; p = 0.010, LSA: 4.29\%; p = 0.727).
LSA had a greater number of statisically significant ROI-ROI pairs than expected by chance for the
$repeat - single$ contrast (LSS: 7.62\%; p = 0.063, LSA: 10.00\%, p = 0.002) (Figure~\ref{fig:main-result}).
Surprisingly, LSS found fewer significant ROI-ROI pairs than expected by chance
for the contrast $switch - repeat$ in both the real data and null data. 

The contrasts performed on the SchaeferTop20 atlas show qualitatively similar results,
with LSS and LSA achieving a greater number of significant ROI-ROI pairs
than expected by chance for the contrasts
$task - null$ (LSS: 14.74\%, p $<$ 0.001; LSA: 21.05\%, p $<$ 0.001) and
$repeat - single$ (LSS: 11.05\%, p $<$ 0.001; LSA: 12.63\% p $<$ 0.001).
LSS alone showed a greater number of significant ROI-ROI pairs than expected
for the contrast
$dual - single$ (LSS: 10.53\%, p = 0.001; LSA: 7.90\%, p = 0.055).
Both LSS and LSA did not deviate from the expected false positive rate for the contrast
$switch - repeat$.
The results with respect to the null data for the SchaeferTop20 atlas demonstrate
the possibility that LSA detects a greater number of significant ROI-ROI
pairs than expected by chance when there is no response to the model, but since this finding did not
replicate in the Activation Atlas, there may be an interaction between using the LSA method with
high CNR ROIs.
Those two contrasts indicate the success of LSS and LSA to measure
condition specific difference in ROI-ROI correlations when the events are in different blocks.
The Schaefer atlas has qualitatively similar results, with the exception of
the $switch - repeat$ contrast where LSA found more statistically significant
ROI-ROI pair correlation differences between conditions relative to chance,
but LSS did not (see supplementary figures).

\begin{figure}[H]
  \centering
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-activation_participants-filtered_permutation_summary} 
  \label{fig:real-activation}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-activation_participants-filtered_permutation_summary} 
  \label{fig:null-activation}}
  \vfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-schaeferbest_participants-filtered_permutation_summary} 
  \label{fig:real-schaeferbest}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-schaeferbest_participants-filtered_permutation_summary} 
  \label{fig:null-schaeferbest}}
  \caption{
    Percentage of statistically significant ROI-ROI pairs found
    in the contrasts $task - null$, $dual - single$, $repeat - single$, and
    $switch - repeat$.
    The red dotted line represents the expected 5\% false positive rate
    and the shaded red region is the 95\% confidence interval.
    Left panels \ref{fig:real-activation} and \ref{fig:real-schaeferbest}
    are results from the real data with the contrast $task - null$ subtracting the
    ROI-ROI correlation found in the null data from the ROI-ROI correlation found in the
    real data for the $dual$ condition.
    Right panels \ref{fig:null-activation} and \ref{fig:null-schaeferbest} are results
    from the null data.
    While in the Activation Atlas both LSS and LSA show similar performance;
    in the SchaeferTop20 atlas, LSA has an increase in false positives
    whereas LSS is closer to an expected number of false positives.
  }
\label{fig:main-result}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{
    data-real_type-brain_atlas-schaeferbest_contrast-repeatXsingle}
  \caption{
    Visualization of the significant ROI-ROI pairs detected in Figure \ref{fig:real-schaeferbest}
    for the contrast $repeat - single$.
    While LSA detected 21 significant ROI-ROI pairs and LSS detected 18 significant
    ROI-ROI pairs, the two methods only had 3 overlapping results.
  }
\label{fig:non-overlap}
\end{figure}

Although both LSS and LSA detected condition specific correlation differences;
the significant ROI-ROI pairs found with LSS are largely non-overlapping with LSA (Figure~\ref{fig:non-overlap}).

\section*{Discussion}
\label{discussion}

We provide here the first in-depth comparison between LSS and LSA to detect 
ROI-ROI correlation differences between conditions.
We compared LSA and LSS through realistic simulations and a participant dataset.
While the simulations suggested LSS is a more powerful method,
the results from the participant data do not show whether LSS or LSA is the more powerful method.
We detail the conclusions from the simulations and the participant data, and provide
suggestions for future avenues of research.

\subsection*{Simulation Conclusions}
\label{discussion:simulation-conclusions}

The main finding from the simulations is that LSS has greater detection power than LSA,
supporting other findings from the literature comparing LSS and LSA using related analyses such as
multivariate pattern analysis, representational similarity analysis, and precision of correlations~\cite{Mumford2012,Mumford2014a,Abdulrahman2016,Turner2012a}.
While we cannot control AVNR and CNR in our experiments, we can control the experimental design.
Thus we can offer several suggestions with respect to experimental design based on our simulations.
Increasing the average IEI up to 6 seconds improves detection power between conditions substantially,
but increasing the average IEI beyond 6 seconds offers only a modest improvement in detection power.
Increasing the number of events per condition to 30 offers the largest benefit in detection power,
mirroring previous findings regarding the number of trials needed to detect brain activation~\cite{Huettel2001}.
It is important to note these recommendations are based on optimized designs made with neurodesign,
and may not generalize to completely random designs.

Abdulrahman \& Henson's (2016) work also varied IEIs, AVNRs, and noise coherency between voxels
revealing several key intersections with the present paper.
Increasing the IEI beyond 6 seconds did not improve their measure, precision of sample correlation.
Precision of sample correlation measures how accurate the estimated correlation is to the true
simulated correlation.
If the error of the observed correlation is evenly distributed around the
true correlation, then precision of sample correlations would closely mirror our measure of
significant correlation differences between event conditions (e.g., $repeat - single$).
However, if there was a systematic bias in the observed correlations, then precision of sample correlation
would be low, but the correlation difference between event conditions could still be high.
For example, if the true correlations were 0.2 for condition $A$ and 0.3 for condition $B$, but
the observed correlations were 0.1 and 0.2, respectively, then precision of sample correlations would
decrease, but the difference between conditions remains the same.

Another conclusion from Abdulrahman \& Henson's (2016) paper suggested to
use LSA when event variability is greater than scan noise (AVNR $>$ 1) for short IEIs (2-5 seconds).
All of our simulations set AVNR greater than or equal to scan noise (AVNR $>=$ 1) and we saw
LSS significantly outperformed LSA for our measure of detection power with IEIs greater than 2 seconds.
Theoretically when AVNR is 1, LSS and LSA would perform similarly, but in our simulations,
LSS still had more power to detect a difference between conditions.
The difference in conclusions may be due to our different measures (i.e., precision of sample correlations versus condition difference)
or simulation methods (i.e., guassian noise with random designs versus autocorrelated noise with optimized designs).

Signal and noise coherency did not impact results as they did in the work of \cite[Abdulrahman \& Henson (2016)]{Abdulrahman2016}.
When scan noise is more coherent across voxels than event variability,
their work states LSA should perform better than LSS.
However, their paper only investigated perfect coherency or no coherency.
In the present simulations, beta series "coherence" was varied between 0.0 and 0.9 Pearson's R correlation,
and the scan noise coherency remained around 0.67 Pearson's R correlation.
For the majority of our simulations, scan noise coherency was greater than beta series
coherence, yet LSS was better at detecting differences between conditions.
It may be the case scan noise must be identical or near identical between voxels
for LSA to perform better than LSS.

The current simulations have improved on previous work by incorporating a more
realistic noise structure using fmrisim and used CNR/AVNR values calculated with participant data.
However, the simulations we performed differ from participant data in several key areas:
the contrasts between event conditions,
variation in BOLD response onset, and preprocessing of the signal.
As mentioned in \nameref{methods:bsc-simulations}, each simulation represents
either a different participant or separate runs from the same participant.
The $task$ and $null$ conditions come from the task switching task and resting state,
respectively, representing two runs.
The contrasts in the simulations are therefore most analogous to the $task - null$
contrast illustrated in Figure~\ref{fig:main-result}.
Additionally, each simulation contains two conditions whose BOLD responses
are independent of each other, that is, the BOLD response for one event
does not influence the BOLD response for a subsequent event.
There is likely temporal autocorrelation of BOLD responses across events,
which is not represented in our simulations~\cite{Abdulrahman2016}.

We also did not simulate variations in BOLD response onset, which is likely to occur
as all BOLD responses to a stimulus do not occur at the time of stimulus onset~\cite{DEsposito2003}.
Model mismatch through variations has been found to be detrimental to beta estimation, 
but there is no reason to believe that LSA would be differentially impacted relative to LSS~\cite{Turner2012a}.
Future work could investigate variable BOLD responses and include derivatives for each regressor to account for
the variable BOLD responses.
Including derivatives could make LSA unsolvable as every event would have at least two regressors, necessitating
more than twice the volumes than events collected during the BOLD run
for the GLM to be solvable.

While the simulations represented data without any preprocessing applied,
the participant data had several variables included in the model: motion outliers, non-steady state volumes,
CSF, and white matter signals.
The additional regressors in the model reduce the degrees of freedom
and could impact the ability of the model to fit the data.
This would likely impact LSA more than LSS, since LSA already contains
a large number of regressors representing each event.

Future work could use fmrisim to simulate entire brains which could be preprocessed using fmriprep,
making the processing pipeline more similar between participant data and simulations.

\subsection*{Participant Data Conclusions}
\label{discussion:taskswitching-conclusions}

The analysis of the participant data suggests LSS and LSA perform similarly.
Based on the number of statistically significantly different ROI-ROI pair correlations alone,
LSS and LSA cannot be easily distinguished.
Overall, we have evidence that LSA and LSS are able to detect differences between
blocks of events ($task - null$, $dual - single$, $repeat - single$), but not an event-related contrast ($switch - repeat$).
This suggests our sample of 40 older adults may not have been large enough to detect a reliable event related effect,
which should caution researchers to perform power analyses to determine an adequate sample size.
% false positives?
Contrary to the simulations where LSS was found to be more powerful,
for both the Activation Atlas and the SchaeferTop20 atlas LSS and LSA performed similarly.
LSA was prone to a higher rate of false positives as determined by the analyses performed on the null data within the SchaeferTop20 atlas.
However, LSS appeared to have a greater magnitude of false positives than LSA when using the entire schaefer atlas.
Furthermore, there is some evidence of LSS having fewer statistically significant ROI-ROI pairs than expected through chance alone
for the contrast $switch - repeat$.
This pattern can be seen for both the real and null data, suggesting there is a property inherent to LSS
leading to this pattern.
Since the beta estimates calculated by LSS are not orthogonal to adjacent events,
the ROI-ROI beta series correlation for one condition is influenced by the other interleaved condition,
resulting in a greater difficulty to detect differences between conditions.
This is likely the source of the poor performance of LSS in event-related contrasts.

Surprisingly, LSA and LSS results did not have much overlap between significant
ROI-ROI pair correlation differences between conditions.
The lack of overlap is suprising because both LSS and LSA are purported to
measure the same underlying process of task related connectivity.
To investigate their differences further, we correlated the beta series of LSA with LSS and plotted their relationship with
average framewise displacement and temporal signal to noise (TSNR) for all participants ($N$=61) (Figure~\ref{fig:lss_lsa_correlation}).
As the average framewise displacement increases and temporal signal to noise (TSNR)
decreases, the agreement between LSS and LSA decreases.
In other words, as noise in the data increases, the more divergent LSS and LSA become.
This suggests one reason for the disagreement is the noise present in the included
data.
There appears to be a cluster of particpants with an average framewise displacement of
less than 0.2mm that have a high correlation between LSS and LSA.
The simulation results would suggest when LSS and LSA disagree, the estimate for LSS should be
trusted, but since we observed a significant number of condition modulated ROI-ROI pair correlations for both
LSS and LSA, it is difficult to say whether LSA or LSS would be "correct".

\begin{figure}[H]
  \centering
  \includegraphics{lss_lsa_noise_relationship}
  \caption{
    The average correlation between LSA/LSS beta series across
    all ROIs in the activation atlas.
    Orange dots represent 21 participants that were not included
    in the original analysis and blue dots are the 40
    participants that were included.
    The size of the dots represent the temporal signal to noise
    ratio (TSNR), higher is better.
    The general pattern shows good correspondence between LSA and LSS
    when the average framewise displacement is low and TSNR is high.
  }
  \label{fig:lss_lsa_correlation}
\end{figure}

Another interesting aspect of our analysis of the participant data was the inclusion of
null (resting state) data where the participants simply stared at a fixation cross.
Using the null data we were able to dissociate the performance of LSS and LSA using the
SchaeferTop20 atlas because LSA showed many more false positives
relative to LSS (Figure~\ref{fig:null-schaeferbest}).
It could be argued the resting state data does not provide an adequate null model
to compare to the real task data because there is presumably no BOLD response at any
of the onset times.
Trying to model the BOLD response with no expectation of a BOLD response existing could lead
to large misfits and deviating beta estimates.
To test this, we evaluated average CNR and AVNR within the Schaefer and activation atlases in
the null data and compared it to the CNR and AVNR in the real data.
If the null data had much larger deviations in beta estimates, CNR and AVNR would be higher
in the null data relative to the real data.
For both LSS and LSA, the Schaefer atlas had statistically significantly higher
CNR/AVNR in the null data relative to the real data, whereas the activation atlas
did not show a statistically significant difference between null and real data (Table~\ref{table2}).

\begin{table}[H]
  \centering
  \caption{
  {\bf Differences in CNR/AVNR between real and null data}}
  \begin{tabular}{|l+l+l|l|l|l|}
  \hline
  Atlas & Method & CNR (t-value) & CNR (p-value) & AVNR (t-value) & AVNR (p-value)\\
  $Schaefer$ & $LSS$ & 3.163 & \textbf{0.003} & 3.659 & \textbf{0.001}\\ \hline
  $Activation$ & $LSS$ & 0.105 & 0.917 & 1.528 & 0.134\\ \hline
  $Schaefer$ & $LSA$ & 2.740 & \textbf{0.009} & 2.893 & \textbf{0.006}\\ \hline
  $Activation$ & $LSA$ & 0.306 & 0.761 & 0.927 & 0.360\\ \hline
  \end{tabular}
  A t-test comparing average CNR/AVNR across all ROIs between real data and null data.
  A statistically significant p-value ($p < 0.05$) suggests the CNR/AVNR value in the real data
  is different from the null data.
  Only CNR/AVNR from the Schaefer atlas shows statistically significant results.
  \label{table2}
\end{table}

The table suggests model misfit may be a driving factor for spurious results in the Schaefer atlas(Table~\ref{table2}).
We protected against extreme beta estimates by detecting and removing outliers, but model misfit
could still drive spurious results.
A proper null model would have BOLD responses at the onset times, but the bold responses
would be the same amplitude at every event such that the only deviance in the simulated
BOLD responses would come from the underlying resting state fluctuations.

\subsection*{Future Directions}

There are several immediate next steps that could be taken to provide a more concrete answer
on when one should use LSA or LSS when looking at ROI-ROI pair correlation differences between event
conditions.

With the publically available NiBetaSeries package, researchers could replicate the
results on their own data using the same methods in this paper.
Furthermore, there are several analytical choices that could be varied using NiBetaSeries such as:
using a t-statistic instead of a raw beta estimate, including derivatives of the hemodynamic response function,
and performing a spatial-temporal analysis using finite impulse responses.
The benefit of using a t-statistic is the added stability of the estimates.
The t-tstatistic will divide outlier beta estimates by their uncertainty giving more stability
towards the beta series estimates.
Since LSA is more likely to produce high variance beta estimates, using a t-statistic would likely impact
how well LSA performs.
No other tool has the option to calculate the t-statistic instead of the raw beta estimate to the knowlege
of the authors.
Another straight-forward addition would be adding temporal and/or dispersion derivatives to each beta
estimate to account for potential BOLD response delays~\cite{Calhoun2004,Gottlich2015}.
This strategy may work well for populations with variable BOLD responses or when the onset of the BOLD
response is not precisely known.
Including derivates would also likely impact LSA more than LSS since there would be either twice or
three times the number of regressors included in the LSA model, which in a fast event-related design
would heavily impact the degrees of freedom in the model.
Finally, a more complex but potentially fruitful option is to use the finite impulse response model.
Finite impulse responses allow the researcher to observe both the spatial and temporal pattern of
condition specific correlation without imposing an expected shape of the hemodynamic response~\cite{Turner2012a}.
For example, the researcher could be able to determine the relationship between 2 event conditions
2, 4, 6, and 8 seconds post stimulus, and identify how that relationship changes across
that time frame.
The finite impulse response model can only be estimated using LSS, giving LSS the advantage if researchers
want to perform this type of analysis.

Network measures of brain organization are becoming widely adopted~\cite{Rubinov2010}.
Network measures offer a perspective on the multidimensional organization of ROI-ROI pairs, instead of
interrogating individual ROI-ROI pairs as we did in the present work.
Previous work has found greater global efficiency, smaller mean clustering coefficients, and lower modularity in
task relative to rest~\cite{Di2013}.
However, this finding has not been replicated using beta series correlations and has just begun
to be investigated between tasks and event conditions within a task~\cite{Di2019a}.
The largely non-overlapping results from LSS and LSA suggest that LSS and LSA may differ
in their network measures as well.

\section*{Conclusion}

Overall, our work leads to four main conclusions:
1) simulations suggest increasing average IEI to 6 seconds and number of events to 30 per condition will detect a difference between conditions, 
2) simulations suggest LSS has more power than LSA to detect differences between conditions (between blocks),
3) participant data suggests LSS and LSA perform comparably but results are dependent on which atlas is selected,
4) LSA may have a slight advantage for event-related contrasts,
but it is difficult for both LSS and LSA to detect condition differences when events are interleaved instead of occuring in separate blocks.
This work guides and cautions cognitive neuroscience researchers as they design their tasks and decide
which analysis path they should take amid the forking paths of researcher degrees of freedom.

\section*{Supporting information}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{avnr-1_fpr}}

  \subfloat{\includegraphics[width=\textwidth]{avnr-2_fpr}}

  \caption{
    LSA/LSS both show a \%5 false positive rate for all conditions.
    Each bar represents a sample of 50 pairs of correlations (with no true difference)
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:res_sim_fpr}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-both_type-brain_atlas-activation_contrast-taskXnull}}

  \subfloat{\includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-dualXsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-repeatXsingle}}

  \caption{
   The statistically significant ROI-ROI pairs in the activation atlas for the contrasts $task - null$, $dual - single$,
   and $repeat - single$ in the real data.
   The glass brains show the anatomical locations of each ROI,
   labelled with its identifying number.
   The edges between ROIs represent significant correlation differences
   between conditions for LSA (blue), LSS (orange), or both (pink).
   The contrast $task - null$ has 25 statistically significant ROI-ROI
   pairs for LSA, 27 statistically significant ROI-ROI pairs
   for LSS with 10 overlapping ROI-ROI pairs for both LSS and LSA.
   The contrast $dual - single$ has 9 statistically significant ROI-ROI
   pairs for LSA, 19 statistically significant ROI-ROI pairs
   for LSS with 2 overlapping ROI-ROI pairs for both LSS and LSA.
   The contrast $repeat - single$ has 21 statistically significant ROI-ROI
   pairs for LSA, 16 statistically significant ROI-ROI pairs
   for LSS with 3 overlapping ROI-ROI pairs for both LSS and LSA.
  }
  \label{fig:significant-contrasts1}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-switchxrepeat}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-dualXsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatXsingle}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas for the contrasts
      $switch - repeat$ in the real data, and the contrasts $dual - single$ and $repeat - single$
      in the null data.
      The contrast $switch - repeat$ has 15 statistically significant ROI-ROI
      pairs for LSA, 6 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
      The contrast $dual - single$ has 14 statistically significant ROI-ROI
      pairs for LSA, 11 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $repeat - single$ has 10 statistically significant ROI-ROI
      pairs for LSA, 12 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
  }
  \label{fig:significant-contrasts2}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-switchxrepeat}}

  \subfloat{\includegraphics[width=\textwidth]{data-both_type-brain_atlas-schaeferbest_contrast-taskXnull}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas for the contrasts
      $switch - repeat$ in the null data and the SchaeferTop20 atlas
      contrasts $task - null$ and $dual - single$ in the real data.
      The contrast $switch - repeat$ has 12 statistically significant ROI-ROI
      pairs for LSA, 3 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
      The contrast $task - null$ has 40 statistically significant ROI-ROI
      pairs for LSA, 28 statistically significant ROI-ROI pairs
      for LSS with 17 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $dual - single$ has 24 statistically significant ROI-ROI
      pairs for LSA, 16 statistically significant ROI-ROI pairs
      for LSS with 1 overlapping ROI-ROI pair for both LSS and LSA.
  }
  \label{fig:significant-contrasts3}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the contrasts $repeat - single$ and $switch - repeat$ in the real data and
      the contrast $dual - single$ in the null data.
      The contrast $repeat - single$ has 24 statistically significant ROI-ROI
      pairs for LSA, 21 statistically significant ROI-ROI pairs
      for LSS with 3 overlapping ROI-ROI pair for both LSS and LSA.
      The contrast $switch - repeat$ has 8 statistically significant ROI-ROI
      pairs for LSA, 8 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $dual - single$ has 17 statistically significant ROI-ROI
      pairs for LSA, 7 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
  }
  \label{fig:significant-contrasts4}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-switchxrepeat}}

  \caption{
      The statistically significant ROI-ROI pairs in the top SchaeferTop20 atlas
      for the contrasts $repeat - single$ and $switch - repeat$ in the null data.
      The contrast $repeat - single$ has 24 statistically significant ROI-ROI
      pairs for LSA, 9 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
      The contrast $switch - repeat$ has 30 statistically significant ROI-ROI
      pairs for LSA, 6 statistically significant ROI-ROI pairs
      for LSS with 0 overlapping ROI-ROI pairs for both LSS and LSA.
  }
  \label{fig:significant-contrasts5}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=0.7\textwidth]{data-real_atlas-schaefer_participants-filtered_permutation_summary}}

  \subfloat{\includegraphics[width=0.7\textwidth]{data-null_atlas-schaefer_participants-filtered_permutation_summary}}

  \caption{
      The overall results for the full Schaefer Atlas.
      Since there were 79800 unique ROI-ROI pairs, it became more likely
      to see unexpected results.
      Looking at magnitudes alone, LSS appears to have a slightly
      higher false positive rate than LSA in the null data, and 
      LSA has a slight sensitivity advantage in the real data, 
      with the expection of the $task - null$ contrast.
  }
  \label{fig:significant-contrasts6}
\end{figure}

%=============================================================================
\chapter{PPI versus BSC}
%=============================================================================


While BSC was originally created to detect contextual functional connectivity, there was another method
that preceded BSC, named psychophysiological interaction (PPI) analysis ~\cite{Friston1997}. 
PPIs are designed to identify brain areas that are differentially functionally connected
during specific contexts relative to others.
If this sounds like the same goal as BSC, you would be correct, although PPI
analyses take a different approach.
There are three necessary components to any PPI.
The first is the psychological variable of interest, such as when a participant
responds to a red square with a finger tap or green square with a toe tap.
The second is the physiological variable, such as the BOLD signal from
the motor cortex.
The third variable is the PPI itself, which represents a multiplication
between the psychological variable and the physiological variable.
If our dependent variable is the BOLD signal in the medial frontal gyrus,
then we can answer the question if the motor cortex and medial frontal gyrus
are differentially functionally connected during finger tap events relative
to toe tap events.

There are a couple of nuances worth addressing in the simplistic example I gave above.
First, there are likely multiple psychological conditions you would like to model.
In my above example, there were already two psychological conditions (finger taps and toe taps)
to model.
Each pyschological condition is their own variable in the model, which also
means each condition has their own PPI.
In the example scenerio, there would be a total of 5 variables in the model,
two psychological variables for finger tapping and toe tapping events,
one physiological variable for the motor cortex BOLD signal,
and two PPIs representing the multiplication between the motor cortex BOLD signal
and finger and toe tapping events~\cite{McLaren2012}.

The second nuance I would like to address is the multiplication between
the psychological and physiological variable.
The BOLD signal is the result of an underlying neural response convolved (i.e., smeared)
with a HRF~\ref{eq:convolve_neural}.
\begin{equation}
  BOLD = HRF \circledast neural
  \label{eq:convolve_neural}
\end{equation}
In order to multiply the BOLD signal with the psychological variable,
the psychological variable must go through the same convolution/smearing process~\ref{eq:convolve_psych}.
\begin{equation}
  PSYCH_BOLD = HRF \circledast psych
  \label{eq:convolve_psych}
\end{equation}
Brain-behavior interactions occur at the neural level, not at the
BOLD response level, as represented above.
Importantly, calculating the interaction at the BOLD level is not
equivalent to calculating the interaction the neural level~\cite{Gitelman2003}~\ref{eq:not_equiv}.
\begin{equation}
  (HRF \circledast neural) \cdot (HRF \circledast psych) \neq HRF \circledast (neural \cdot psych)
  \label{eq:not_equiv}
\end{equation}
To get the neural signal we need to deconvolve the BOLD signal.
Deconvolution of the BOLD signal is not a well defined problem since
we do not know the exact neural process that gave rise to the BOLD signal.
Therefore we have to rely on regularized regression with an overcomplete
basis set.
Overcomplete meaning there are more columns (the basis set) than there
are rows (the BOLD signal).
Since the BOLD signal is noisy and assumed hemodynamic response function
may not match the biological BOLD response, some software packages simply do not attempt
deconvolution and swallow the error from multiplying the physiological and psychological
variables at the BOLD level.
Other software packages bite the bullet and attempt deconvolution.
In block designs where contexts are not intermixed the choice of
deconvolution appears inconsequntial, but with rapid event-related designs,
deconvolution is essential to separate the influence of intermixed contexts~\cite{Gitelman2003}.

No previous work has to this author's knowledge has compared multiple methods to calculate BSC
and PPI before.
In this chapter we demonstrate:
1) PPI is the most sensitive method,
2) LSS is the most specific method, and
3) PPI and LSS estimates correlate stronger than PPI and LSA.

\section{methods}

\subsection*{Participant Data}
\label{methods:task-switch2}

We used an unpublished dataset
of older adults ($N$=61, 31 female, age=71.75$\pm$4.77, education=17.07$\pm$2.66)
performing a mixed design task switching task.
Numbers reported are mean$\pm$standard deviation.
Prior to any experimentation, participants provided verbal and written consent
to participate in the research presented in this manuscript, which was approved
by the University of Iowa's Institutional Review Board.
21 participants were excluded in the primary analysis for having over
0.5mm of total movement (framewise displacement) in 100 volumes or more,
resulting in a final $N$ of 40.
We chose 100 volumes to keep the number of regressors in LSA
(which already includes as many regressors as events) a reasonable size
for single event beta estimation since we included each outlier volume
as a regressor as well.
Task switching was performed in a mixed block/event-related design containing
5 blocks (2 single task blocks and 3 dual task blocks).
There was a 30 second rest between each block.
There were 30 events during each single event block,
and for the 3 dual blocks there were 48 repeat events and 39 switch events total.
The single tasks consisted of identifying a number between
1 and 10 (excluding 5) as high/low or odd/even, using their left and right index fingers
on a fiber optic response pad.
Participants were cued to which task they were performing by the color of the square
the number was presented on (blue or pink).
Each stimulus was presented for 1.5 seconds, and participants were allowed
to respond within 2.0 seconds of stimulus onset.
The average IEI was 3.5 seconds following an exponential distribution.
All stimuli were presented using E-Prime.
Participants practiced an abridged version of this task in a mock scanner
prior to the real scan and had 4 practice events in the real scanner immediately
prior to performing the task to ensure proper finger placement and data acquisition.

Participants' average accuracy and reaction time were:
single, (92\%$\pm$27\%, 792ms$\pm$225ms); repeat, (89\%$\pm$31\%, 1001ms$\pm$278ms);
and switch, (83\%$\pm$36.8\%, 1108ms$\pm$289ms).
Due to data collection error, behavioral data were not collected for 3 participants
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/summarizeBehavior/summarize_behavior.ipynb}{see here for relevent code})

The task switch bold \emph{fmriprep} output in MNI152NLin2009cAsym space
was analyzed with \emph{Nistats} for first and second level analyses.
We used mean white matter signal, mean cerebrospinal fluid signal,
discrete cosine basis filter (high pass filter), framewise displacement, the first four non-steady volumes, and
all identified motion outliers as regressors in the first level model for each participant
in addition to event onsets convolved with a double gamma function~\cite{Glover1999}.
Each image was smoothed with a 6mm full-wide half-max kernel.
We derived 3 contrasts of interest: $switch - repeat$, $dual- single$, and $repeat - single$.
The $dual$ condition is the weighted average of $switch$ and $repeat$ to represent the global cost~\cite{Wylie2000}.
We ignored correctness of the participant's response since it was not essential to
separate condition and error processing to compare BSC with PPI.

Second level analyses were a summary of the first level results presenting which
regions were robustly activated among participants.
For each contrast, the alpha was set to 0.01 with a cluster threshold of 10 voxels using
false discovery rate error control (Figure~\ref{fig:stat_maps}).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth,height=0.8\paperheight,keepaspectratio]{contrast_summary}
  \caption{
    Univariate statistical maps of second level results representing
    all contrasts of interest, $dual - single$, $repeat - single$, $switch - repeat$}
  \label{fig:stat_maps2}
\end{figure}

In addition to the task switching task, participants also completed
two 8 minute resting state runs.
We used the resting state runs as a null model for task switching as done
in other reports validating analyses~\cite{Eklund2016,Olszowy2019}.
While the task switch data had 471 volumes, each resting state run only had
240 volumes.
In order to match the length of the resting state data with the task data, we concatenated
the two resting state runs while cutting off the first 10 volumes of the second run
and interpolating 1 volume between the two runs, resulting in 471 volumes.
The interpolation helps transition the bold series from one run to the next,
analogous to interpolation performed when scrubbing high motion volumes~\cite{Power2014a}. 
This null task data was treated equivalently to the task switching data for the
beta series correlation analysis.
(\href{https://github.com/jdkent/validateBetaSeries/tree/195ad5b4201971038dbbf8f73a3c537caf032743}{see relevant code here})

\subsection*{Scanner Parameters}
\label{methods:scanner2}

MRI data were collected on a 3T GE Discovery 750w using a 32 channel head coil.
The anatomical T1w images were collected using a SPoiled Gradient-Recalled (SPGR) sequence
sagittally with a flip angle of 8$^{\circ}$, echo time of 3.168ms,
repetition time of 8.388ms, inversion time of 900ms, isometric voxel sizes of 1mm,
[256x256] acquisition matrix with 196 slices, field of view 25.6cm x 25.6cm.
The functional bold images were collected using a Gradient Echo sequence axially from
the bottom up sequentially with a flip angle of 80$^{\circ}$, echo time of 30ms,
repetition time of 2000ms, voxel sizes of 3.44x3.44x4.00mm on a [64x64] acquisition matrix
with 37 slices, field of view 22cm x 22cm.

\subsection*{Preparing fMRI}
\label{methods:fmriprep2}

Results included in this manuscript come from preprocessing performed
using \emph{fMRIPrep} 1.5.7 (\cite{fmriprep1}; \cite{fmriprep2}; RRID:SCR\_016216),
which is based on \emph{Nipype} 1.4.0
(\cite{nipype1}; \cite{nipype2}; RRID:SCR\_002502).


\subsubsection*{Anatomical data preprocessing}
\label{methods:anat2}

The T1-weighted (T1w) image was corrected for intensity non-uniformity
(INU) with \texttt{N4BiasFieldCorrection} \cite{n4}, distributed with
ANTs 2.2.0 \cite[RRID:SCR\_004757]{ants}, and used as T1w-reference
throughout the workflow.
The T1w-reference was then skull-stripped with a \emph{Nipype} implementation
of the \texttt{antsBrainExtraction.sh} workflow (from ANTs), using OASIS30ANTs
as target template.
Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and
gray-matter (GM) was performed on the brain-extracted T1w using
\texttt{fast} \cite{fsl_fast} [FSL 5.0.9, RRID:SCR\_002823,][].
Brain surfaces were reconstructed using \texttt{recon-all} \cite{fs_reconall},
[FreeSurfer 6.0.1, RRID:SCR\_001847,][] and the brain mask estimated
previously was refined with a custom variation of the method to
reconcile ANTs-derived and FreeSurfer-derived segmentations of the
cortical gray-matter of Mindboggle \cite[RRID:SCR\_002438,]{mindboggle}.
Volume-based spatial normalization to standard space (MNI152NLin2009cAsym)
was performed through nonlinear registration with \texttt{antsRegistration}
(ANTs 2.2.0), using brain-extracted versions of both T1w reference and the T1w template.
The following templates were selected for spatial normalization: \emph{ICBM 152 Nonlinear
Asymmetrical template version 2009c} {[}\cite{mni152nlin2009casym},
RRID:SCR\_008796; TemplateFlow ID: MNI152NLin2009cAsym{]}.

\subsubsection*{Functional data preprocessing}
\label{methods:func2}

For each of the two BOLD runs (task switch and null data) per subject,
the following preprocessing was performed.
First, a reference volume and its skull-stripped version were generated
using a custom methodology of \emph{fMRIPrep}.
Susceptibility distortion correction (SDC) was omitted.
The BOLD reference was then co-registered to the T1w reference using \texttt{bbregister}
(FreeSurfer) which implements boundary-based registration \cite{bbr}.
Co-registration was configured with 6 degrees of freedom.
Head-motion parameters with respect to the BOLD reference (transformation matrices,
and 6 corresponding rotation and translation parameters) are estimated before any
spatiotemporal filtering using \texttt{mcflirt} \cite[FSL 5.0.9,]{mcflirt}.
The BOLD time-series were resampled into a standard space, correspondingly
generating the following \emph{spatially-normalized, preprocessed BOLD runs}:
MNI152NLin2009cAsym.
Several confounding time-series were calculated based on the \emph{preprocessed BOLD}:
% only used a subset of the confounding variables
framewise displacement and two region-wise global signals.
framewise displacement was calculated for each functional run, using its
implementation in \emph{Nipype} following the definitions
by Power et al. (2014)\cite{power_fd_dvars}.
The two global signals were extracted within the
cerebrospinal fluid and the white matter masks.
High-pass filtering the \emph{preprocessed BOLD} time-series was done using
a discrete cosine filter with 128s cut-off.
The head-motion estimates calculated in
the correction step were also placed within the corresponding confounds file. 
Frames that exceeded a threshold of 0.5 mm framewise displacement or 1.5 standardised DVARS
were annotated as motion outliers.
An additional 4 frames at the beginning of each run were also
annotated as outliers to allow the magnet to reach equilibrium.

All resamplings were performed with \emph{a single interpolation step} by composing all the pertinent
transformations (i.e.~head-motion transform matrices, co-registrations to anatomical
and output spaces).
Gridded (volumetric) resamplings were performed using \texttt{antsApplyTransforms} (ANTs),
configured with Lanczos interpolation to minimize the smoothing effects of other kernels
\cite{lanczos}.

\subsection*{BetaSeries Correlations}
\label{methods:bsc2}

\subsubsection*{Beta Series Modeling}
\label{methods:bsc_model2}

The LSS models were generated for each event in
the task following the method described in \cite[Turner (2012)]{Turner2012a}, using
Nistats 0.0.1b2.\\
Prior to modeling, preprocessed data were masked, and mean-scaled over
time.
Mean scaling was not applied when calculating CNR and AVNR so the
beta estimates would be in the original BOLD units.
For each event, preprocessed data were subjected to a GLM
in which the event was modeled with its own regressor, while
all other events from that condition were modeled in a second regressor,
and other conditions were modeled in their own regressors.
So if the task has 3 conditions, 
a single GLM would have 4 event regressors, 1 for the target
event, and 3 for the remaining conditions.

The LSA model was generated following the method described in
\cite[Rissman (2004)]{Rissman2004}, using Nistats 0.0.1b2.
Each event was given its own regressor in a single GLM, such that
if the experiment had 100 events, there would be 100 regressors in the GLM.

Each event regressor was convolved with a glover hemodynamic response
function~\cite{Glover1999}.
In addition to event regressors, average white matter signal, average csf signal,
cosine basis set high pass regressors, the initial four non steady-state volumes, 
and motion outliers were included
in the model as calculated in \nameref{methods:func}.
AR(1) prewhitening was applied in each model to account
for temporal autocorrelation.

After fitting each model, the parameter estimate (i.e., beta) map
associated with the target event's regressor was retained and
concatenated into a 4D image with all other events from the same
condition, resulting in a set of $X$ 4D images where $X$ refers to the
number of conditions in the task.
The number of volumes in each 4D beta series image
represents the number of events in that condition.


\subsubsection*{Psychophysiological Interaction Modeling}

The computation of Psychophysiological interactions underwent multiple steps:
1) extraction and cleaning of an ROI time series,
2) deconvolution of an ROI time series~\cite{Gitelman2003},
3) centering of the psychological variable~\cite{Di2017},
4) upsampling of both the deconconvoled ROI time series and psychological variable,
5) multiplication of the deconvolved ROI time series and psychological variable, and
6) convolution of the resulting multiplicative in step 5.
A simplified visualization of this process is in Figure~\ref{fig:ppi_method_overview}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{ppi_method_overview}
  \caption{
    The overall process of generating a PPI.
    First, the BOLD time series is deconvolved to represent the theoretical
    neuronal timecourse.
    Next, the neuronal time series is then multiplied with each of the psychological
    conditions, generating neural PPIs.
    Finally, each neural PPI is convolved with a hemodynamic response function
    to represent the contextual BOLD signal.
  }
  \label{fig:ppi_method_overview}
\end{figure}

% insert figure for this process
Extraction and cleaning of the ROI time series was completed using nilearn,
including white matter and cerebral spinal fluid signal, framewise displacement,
motion outliers, a high pass filter (cosine basis set), and the first four non-steady state
volumes as confounds regressed from the time series.
We deconvolved the ROI timeseries using a fourier basis set convolved with
SPM's hemodynamic response function as predictors using ridge regression.
Ridge regression was implemented in Scikit-Learn seeting the alpha (regularization)
parameter to 0.0001, but keeping all other parameters at their default values.
Independently, we took each psychological condition of interest ($switch$, $repeat$, and $single$)
represented as a stick function (i.e., 1's where the stimulus was "on" and 0's everywhere else)
and mean centered each psychological condition separately.
The stimuli were presented for less time than the acquisition of a volume
(e.g., 1.5 seconds verus 2.0 seconds), thus to accurately represent the duration
of the stimulus, each of the psychological conditions and deconvolved ROI time series were upsampled to
a resolution of 0.1 seconds.
Next, we multiplied each of the upsampled psychological conditions with the deconvolved/upsampled
ROI time series creating a "neural" PPI for each of the
psychological conditions~\cite{McLaren2012}.
We downsampled the "neural" PPI back to a resolution of 2 seconds and convolved the signal with
SPM's hemodynamic response function representing the PPI in the original BOLD timecourse.

After all PPIs were created, the full regression model was represented in Equation~\ref{eq:full_ppi}

\begin{equation}
	\begin{multlined}[b]
    Y = \beta_{intercept}X_{intercept} + \beta_{switch}X_{switch} + \beta_{repeat}X_{repeat} + \\
	      \beta_{single}X_{single} + \beta_{firsttrial}X_{firsttrial} + \beta_{ROI}X_{ROI} + \\
		\beta_{switch\_ppi}X_{switch\_ppi} + \beta_{repeat\_ppi}X_{repeat\_ppi} + \\
		\beta_{single\_ppi} X_{single\_ppi} + \epsilon
  \end{multlined}
  \label{eq:full_ppi}
\end{equation}

Where the $\beta$s represent the model estimates/coefficients and $X$ represents
the design column.
$Y$ represents the ROI BOLD signal we want to explain.
$\beta_{intercept}$ refers to the baseline estimate (implicit rest) during the task,
where $X_{intercept}$ is a column of ones.
$\beta_{switch}$, $\beta_{repeat}$, $\beta_{single}$, and $\beta_{firsttrial}$
are the coeficients representing the main effect of each of the event conditions.
$X_{switch}$, $X_{repeat}$, $X_{single}$, and $X_{firsttrial}$ indicate the
times when the events for condition occurred.
$\beta_{ROI}$ is the coefficient representing the baseline connectivity between
this particular ROI and the ROI BOLD signal we want to explain, and
$X_{ROI}$ is the time series from the particular ROI.
$\beta_{switch\_ppi}$, $\beta_{repeat\_ppi}$, and $\beta_{single\_ppi}$
represent the context dependent functional connectivity estimates for
each event condition.
$X_{switch\_ppi}$, $X_{repeat\_ppi}$, and $X_{single\_ppi}$ represent
the multiplicative between the ROI time series and each event condition.
An example design matrix is illustrated in Figure~\ref{fig:example_ppi_design}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{example_ppi_design}
  \caption{
    An example PPI design.
    The event type $firsttrial$ was not of interest in the contrasts,
    but included in the model for completeness.
    The $constant$ column can also be refered to as the intercept.
  }
  \label{fig:example_ppi_design}
\end{figure}

The contrasts of interests taken from this model were:\\
$((switch\_ppi + repeat\_ppi) / 2) - single\_ppi$, $repeat\_ppi - single\_ppi$,
and $switch\_ppi - repeat\_ppi$ to measure each contextual difference in functional connectivity. 
This equation was run for every unique ROI-ROI pair in both directions
(e.g., $Y$ and $X_{ROI}$ swap places) resulting in an
asymmetrical correlation matrix for each of the mentioned contrasts.
For reference, the first term in the first listed contrast ($((switch\_ppi + repeat\_ppi) / 2)$)
is refered to as the $dual$ condition because it represents the functional connecitivty during the
two-task blocks.

\subsubsection*{Atlas Correlation Analysis}
\label{methods:atlas-corr-analysis2}

The 4D beta series image for each condition in the task was subjected to
an ROI-to-ROI correlation analysis
to produce condition-specific correlation matrices.
For the simulation data, ROI-to-ROI correlations were calculated by
treating each voxel as an ROI.
In the participant data; two atlases were used to generate ROI-to-ROI correlation matrices.
We created an activation atlas representing regions that were
consistently activated across event conditions (see \nameref{methods:task-switch}).
This atlas has coverage across several cortical and subcortical regions.
The second atlas, Schaefer Atlas (400 parcels, 17 networks)\cite{Schaefer2017}, was
used to comprehensively cover the cortex and test robustness of results.

An activation atlas was generated based on an F-test across the switch, repeat, and single conditions
to identify regions that were reliably activated for all participants (Table~\ref{table:clusters2}).
5mm spheres were drawn around each statistical peak (21 peaks total) (Figure~\ref{fig:methroimap2}).

\begin{table}[H]
  \csvautotabular[separator=tab, no check column count]{./data/cluster_table.tsv}
  \caption{
    The peak MNI coordinates/Z-statistic identifying clusters/sub-clusters from the overall
    response contrast.
    These peaks were used to create regions of interest (ROIs) to form an atlas representative
    of the most consistently activated regions across conditions.
  }
  \label{table:clusters2}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{stat-map-overall_resp_with_rois}
  \caption{
    ROIs drawn from the peak Z-score table, placing a sphere with a 5mm radius
    at each peak coordinate.
    The clusters are identified in their approximate locations
    with their ID.
  }
  \label{fig:methroimap2}
\end{figure}

\begin{table}[H]
  \csvautotabular[separator=tab]{./data/schaeferbest_rois.tsv}
  \caption{
    The top 20 ROIs from the Schaefer 400 (17 Network) identified with a highest CNR as measured by
    both LSS and LSA.
  }
  \label{table:parcels2}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{schaefer_high_cnr_rois}
  \caption{
    20 ROIs selected from the Schaefer 400 parcels; 17 network atlas for having the
    highest CNR for both LSS and LSA.
  }
  \label{fig:schaefertopmap2}
\end{figure}

In order to increase the likelihood of being able to detect a real result using the Schaefer atlas,
we selected the top 25 ROIs with the highest CNR using LSA and LSS separately
(see \nameref{methods:bsc-simulations} for how we calculated CNR).
We then took the intersection of the two ROI sets resulting in 20 ROIs that have a high CNR
as measured by LSA and LSS (Table~\ref{table:parcels2},Figure~\ref{fig:schaefertopmap2}).
We refer this subset of ROIs as the SchaeferTop20 Atlas for the rest of the manuscript.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/b18b44321edf7b662a1e5ea635f64452c8d3644c/nibsAnalysis/cnr_trial_variability.ipynb}{see here for relevant code}).
The results for the entire 400 ROI altas are shown in the supplementals.

Outlier beta estimate volumes were identified and discarded using a
modified Nipype function for outlier detection
(\href{https://github.com/HBClab/NiBetaSeries/blob/a45c0a1f/src/nibetaseries/interfaces/nilearn.py#L153}{see here}) \cite{Crosby1994}.
The correlation coefficient estimator used for generating correlation matrices
was empirical covariance, as implemented in Nilearn 0.4.2~\cite{Abraham2014}.
Correlation coefficients were converted to normally-distributed z-values using
Fisher's r-to-z conversion~\cite{Fisher1915}.

BSC generated correlation matrices for each condition (dual, switch, repeat, single),
each method, (LSA and LSS), each data type (real and null), and each participant (N=40).
The first check performed was contrasting the real dual condition and null dual condition
to ensure BSC from a task are different than BSC from null data.
A paired t-test was run on each ROI-ROI pair for the activation atlas, totaling 210 comparisons
between task and null.
We next contrasted $dual - single$, $repeat - single$, and $switch - repeat$, for LSS/LSA in both
real and null data.

To create symmetric correlation matrices similar to BSC using PPI, the asymmetric matrices generated for
each contrast were transposed, added to the original, and divided by two, as done in previous work~\cite{Di2019a}.
The resulting symmetric matrices were comparable to the contrast matrices generated from BSC.

Since we do not have a ground truth for which ROI-ROI pairs should be different between conditions,
we used a binomial test across all ROI-ROI pairs to discover if the number of observed significant ROI-ROI pairs was greater
than 5\%.
We did not use false discovery rate correction on the observed p-values since we were not interested in
which specific ROI-ROI pair correlations were likely to be true positives, but rather if the number of positives
observed would be expected by chance alone or if LSS/LSA/PPI likely detected an overall difference between event conditions.

We provided a description of the number of significant ROI-ROI pairs with increased contextual functional connectivity and
decreased contextual functional connectivity to identify if contextual connectivity tends to increase or decrease overall
for the contrasts $dual - single$, $repeat - single$, and $switch - repeat$, and see if the pattern replicates
in the null data. 
The ratio of positive results will help identify whether biases for increased/decreased contextual functional connectivity
in real data are also seen in null data.

With three separate methods being compared, we also measured agreement through convergence by correlating the
contextual differences across all unique ROI-ROI pairs for each of the contrasts.
For example, we compared the estimated connectivity differences between $switch - repeat$ for each unique
ROI-ROI pair for every method (LSA, LSS, and PPI).
The difference estimates for PPI were correlated with the difference estimates for LSS and LSA, providing
evidence whether LSS or LSA are more similar to PPI~\cite{Steiger1980}.
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/2e5d7d2443795133770383daaa401cf70cc03f29/PPITest/compare_bsc_ppi.ipynb}{see here for relevant code}).

\subsection*{Software Dependencies}
\label{methods:software-dependencies}

The results in this manuscript are dependent on many open source
libraries, while we have inevitably missed providing all due credit,
we would like to acknowledge some of the main libraries used in 
\emph{fMRIPrep} 1.5.7\cite{fmriprep1} and \emph{NiBetaSeries} 0.6.0\cite{Kent2018}.

Many internal operations of \emph{fMRIPrep} use \emph{Nilearn} 0.6.1
\cite[RRID:SCR\_001362]{nilearn}, mostly within the functional
processing workflow. For more details of the pipeline, see
\href{https://fmriprep.readthedocs.io/en/latest/workflows.html}{the
section corresponding to workflows in \emph{fMRIPrep}'s documentation}.

Additional libraries used in the \emph{NiBetaSeries} workflow include
\emph{Pybids} 0.9.5 \cite{Yarkoni2019}, \emph{Niworkflows} 1.0.4,
\emph{Nibabel} 2.4.1, \emph{Pandas} 0.24.2 \cite{McKinney2010}, and
\emph{Numpy} 1.18.1 \cite{VanDerWalt2011, Oliphant2006}.

In addition to the data analysis, visualization of results depended
on matplotlib\cite{Hunter2007}, seaborn\cite{Waskom2020}, nilearn,
jupyter notebooks\cite{Kluyver2016a}, and the packages they depend on.

\section{Results}
We analyzed the data from three different perspectives:
1) identifying whether each method found more significant results than expected,
2) finding which method estimates are more closely related, and
3) describing the pattern of increases and decreases of contextual functional connectivity
   in the significant ROI-ROI pairs.

\begin{figure}[H]
  \centering
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-activation_participants-filtered_permutation_summary_ppi} 
  \label{fig:real-activationppi}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-activation_participants-filtered_permutation_summary_ppi} 
  \label{fig:null-activationppi}}
  \vfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-real_atlas-schaeferbest_participants-filtered_permutation_summary_ppi} 
  \label{fig:real-schaeferbestppi}}
  \hfill
  \subfloat[][]{\includegraphics[width=0.49\linewidth]{
    data-null_atlas-schaeferbest_participants-filtered_permutation_summary_ppi} 
  \label{fig:null-schaeferbestppi}}
  \caption{
    Percentage of statistically significant ROI-ROI pairs found
    in the contrasts $dual - single$, $repeat - single$, and
    $switch - repeat$.
    The red dotted line represents the expected 5\% false positive rate
    and the shaded red region is the 95\% confidence interval.
    Left panels \ref{fig:real-activationppi} and \ref{fig:real-schaeferbestppi}
    are results from the real data.
    Right panels \ref{fig:null-activationppi} and \ref{fig:null-schaeferbestppi} are results
    from the null data.
    PPI consistently has a greater number of significant contextual differences between ROI-ROI pairs
    than expected, except for the $switch - repeat$ contrast.
  }
\label{fig:main-resultppi}
\end{figure}

We found LSS, LSA, and PPI had a greater number of statistically significant ROI-ROI pairs than expected by chance
for different contrasts in the activation atlas with real data: $dual - single$ (LSA: 4.29\%; $p = 0.727$,
LSS: 9.05\%; $p < 0.010$, PPI: 10.48\%; $p = 0.001$),
$repeat - single$ (LSA: 10.00\%; $p = 0.002$, LSS: 7.62\%; $p = 0.063$, PPI: 11.90\%; $p < 0.001$), and
$switch - repeat$ (LSA: 7.14\%; $p = 0.106$, LSS: 2.86\%; $p = 0.954$, PPI: 8.57\%; $p = 0.019$) (Figure~\ref{fig:real-activationppi}).

Within the activation atlas with null data, only PPI had significant results:
$dual - single$ (LSA: 5.24\%; $p = 0.480$, LSS: 4.29\%; $p = 0.727$, PPI: 9.52\%; $p = 0.005$),
$repeat - single$ (LSA: 4.76\%; $p = 0.607$, LSS: 5.71\%; $p = 0.360$, PPI: 11.49\%; $p < 0.001$), and
$switch - repeat$ (LSA: 5.71\%; $p = 0.360$, LSS: 1.43\%; $p = 0.998$, PPI: 6.19\%; $p = 0.254$) (Figure~\ref{fig:null-activationppi}).

Within the SchaeferTop20 atlas with real data, PPI analyses yielded an extraordinary number of results
relative to LSS and LSA for the block contrasts:
$dual - single$ (LSA: 7.89\%; $p = 0.055$, LSS: 10.53\%; $p = 0.001$, PPI: 26.84\%; $p < 0.001$),
$repeat - single$ (LSA: 12.63\%; $p < 0.001$, LSS: 11.05\%; $p = 0.001$, PPI: 31.05\%; $p < 0.001$), and
$switch - repeat$ (LSA: 4.21\%; $p = 0.738$, LSS: 4.21\%; $p = 0.738$, PPI: 6.84\%; $p = 0.158$) (Figure~\ref{fig:real-schaeferbestppi}).

Within the SchaeferTop20 atlas with null data, both PPI and LSA had significant number of false positives:
$dual - single$ (LSA: 8.94\%; $p = 0.015$, LSS: 3.68\%; $p = 0.842$, PPI: 13.68\%; $p < 0.001$),
$repeat - single$ (LSA: 12.63\%; $p < 0.001$, LSS: 4.74\%; $p = 0.613$, PPI: 12.63\%; $p < 0.001$), and
$switch - repeat$ (LSA: 15.79\%; $p < 0.001$, LSS: 3.16\%; $p = 0.917$, PPI: 5.26\%; $p = 0.480$) (Figure~\ref{fig:null-schaeferbestppi}).
These results are qualitatively similar to the full Schaefer atlas (Supplemental Figure~\ref{fig:schaefer_binomial_ppi})

To find whether PPI was more similar to LSA or LSS, we correlated the contrast estimates for all of the contrasts
($dual - single$, $repeat - single$, and $switch - repeat$), for all the atlases (activation atlas, SchaeferTop20 atlas, and the full Schaefer atlas), and
for each of the data sources (real and null).
PPI ROI-ROI contrast estimates significantly correlated more strongly with LSS relative to LSA
for nearly all contrasts ($dual - single$, $repeat - single$, and $switch - repeat$),
atlases (activation atlas, SchaeferTop20 atlas, and the full Schaefer atlas),
and the real and null data ($p < 0.05$) except the $switch - repeat$
contrast in the SchaeferTop20 Atlas (real: $p = 0.541$, null: $p = 0.064$).
The overall average correlation between LSS and PPI is $r = 0.55$, LSA and PPI is $r = 0.29$,
and LSS and LSA is $r = 0.34$.
The overall average correlation difference between LSS+PPI versus LSA+PPI is $0.26$,
indicating a medium effect size.
The similarity between LSS and PPI is stronger for the block contrasts ($dual - single$ and $repeat - single$)
relative to the event-related contrast ($switch - repeat$), regardless of data (real/null) or atlas.

We measured the distribution of $positives / (positives + negatives)$ results from the significant ROI-ROI pairs~\ref{table_bias}.
\begin{table}[H]
  \centering
  \caption{
  {\bf Differences in positive bias between real and null data}}
  \begin{tabular}{|l|l+l|l|}
  \hline
  Contrast & Estimator & Real Data & Null Data\\ \hline
  $Dual - Single$ & $LSA$ & 0.04 & 0.24\\ \hline
  $Dual - Single$ & $LSS$ & 0.27 & 0.51\\ \hline
  $Dual - Single$ & $PPI$ & 0.10 & 0.44\\ \hline
  $Repeat - Single$ & $LSA$ & 0.03 & 0.22\\ \hline
  $Repeat - Single$ & $LSS$ & 0.24 & 0.46\\ \hline
  $Repeat - Single$ & $PPI$ & 0.09 & 0.41\\ \hline
  $Switch - Repeat$ & $LSA$ & 0.91 & 0.72\\ \hline
  $Switch - Repeat$ & $LSS$ & 0.71 & 0.75\\ \hline
  $Switch - Repeat$ & $PPI$ & 0.79 & 0.81\\ \hline
  \end{tabular}

  A description of the positive bias for the results $positives / (positives + negatives)$.
  The block contrasts ($Dual - Single$ and $Repeat - Single$) have a strong negative
  bias in the real data and a smaller negative bias in the null data.
  The event-related contrast ($Switch - Repeat$) positivity ratio is
  similar between the real and null data for LSS and PPI, while LSA
  has a larger positivity bias in the real data relative to the null.
  \label{table_bias}
\end{table}

\section{Discussion}
We provided the first in-depth comparison between LSA, LSS, and PPI.
We showed while PPI generally found more results relative to LSA and LSS in the real data,
PPI also found a large number of results in the null data as well.
Given the greater agreement between LSS and PPI, we recommend using PPI
for event-related contrasts, and either PPI or LSS for block contrasts.
With LSS, you may have fewer results relative to PPI, but based on this dataset,
LSS is less prone towards finding spurious results relative to both LSA and PPI.

The choice of atlas did not have a strong impact on LSS's and LSA's relationship with
the PPI analysis.
LSS was almost always more correlated with PPI than LSA was correlated with PPI indicating
LSS and PPI are more related than LSA and PPI.
However, the higher correlation between LSS and PPI analyses estimates
did not translate to a large agreement of which ROI-ROI pairs were found
significant between LSS and PPI (Figure ~\ref{fig:data-null_type-brain_atlas-activation_contrast-dualxsingle}).
Thus, there is still significant variance between LSA/LSS/PPI producing unique results,
depending on which method is chosen.

An intriguing result is the large percentage of significant ROI-ROI pairs found by
PPI analysis in Figure~\ref{fig:real-schaeferbestppi}.
The top CNR regions were chosen using LSA and LSS, with no influence from PPI.
This suggests LSS/LSA could be used as a data driven approach to select ROIs
for PPI analyses, as opposed to the traditional method of selecting
highly activated regions.
The derivation of CNR does not select for ROIs that have contextual
connectivity differences so this strategy does not suffer from
double-dipping~\cite{Kriegeskorte2009}.
This strategy did not help with the event-related contrast ($Switch - Repeat$)
suggesting CNR is not the only factor at play to increase sensitivity of
the tests.

The decrease of contextual functional connectivity seen in the contrasts
$Dual - Single$ and $Repeat - Single$ for the real data agrees with previous
work looking at contextual functional connectivity during various task states~cite{Cole2014a,Spadone2015}.
The SchaeferTop20 atlas is overrepresented with ROIs from the visual cortex, which have been shown
to reduce their functional connectivity in response to a task~\cite{Spadone2015}.

PPI may arguably be the better method for detecting contextual functional connectivity
differences, and as such could be extended to include spatiotemporal relationship as BSC methods
have been expanded~\cite{Turner2012a}.
Specifically, PPIs could be calculated using a finite impulse response (FIR) model, where instead of assuming
a hemodynamic response function shape, there is a separate regressor for each time point peri-stimulus.
This analysis strategy would require significant data per person since the number of regressors would be
$2 * (\#FIRs * \#conditions) + 1_{physio}$, where FIRs could reasonbly go up to 8 and number of conditions could
be 3, resulting 49 regressors in the model related to the task.

\subsection{Limitations}
This work is subject to a number of limitations.
The implementation of PPI used in this manuscript is based on
home-grown analysis pipeline and has not been vigorously tested
as other tools in existance (SPM's \href{https://www.nitrc.org/projects/gppi}{gPPI toolbox}
and AFNI's \href{https://afni.nimh.nih.gov/CD-CorrAna}{Context Dependant Correlation Analysis}).
In support of the homegrown pipeline, we did find a similar correlation between LSS and PPI as
other work ~\cite{Di2019a}.
Future work could compare SPM, AFNI, and python implementations of PPI to measure the similarity
between the pipelines.

Due to the high levels of motion several participants were removed from this analysis.
According the LSA/LSS power analysis, our results were moderately underpowered for the BSC analysis,
increasing the difficulty to compare LSA, LSS, and PPI.
However, even with the smaller sample size, several striking patterns emerged in our data.
Future should attempt to replicate our findings in an independent dataset.

It could be argued the resting state data does not provide an adequate null model
to compare to the real task data because there is presumably no BOLD response at any
of the onset times.
Trying to model the BOLD response with no expectation of a BOLD response existing could lead
to large misfits and deviating beta estimates for BSC and to a lesser extent PPI.
A proper null model would insert uniform BOLD responses across all onsets, such that
the only contextual differences that could be detected would be driven by the
resting state BOLD oscillations.

While the data suggest that block contrasts are more likely to show results relative to event-related contrasts,
we did not control for the cognitive effort difference between the conditions.
We cannot rule out the possibility that the difference in cognitive effort for
$switch$ and $repeat$ is less than the difference between $repeat$ and $single$.
In fact, in the context of an older adult population like the one used here,
age tends to impact global switch costs (i.e., $repeat - single$) more than local
switch cost (i.e., $switch - repeat$), possibly resulting in greater difficulty to detect
differences between the two conditions~\cite{Wasylyshyn2011}.
Future work could incorporate a study with several runs of the same task, where
the contrast would be calculated between events of the same run (e.g., $switch_{run1} - repeat_{run1}$
and between the events in separate runs (e.g., $switch_{run1} - repeat_{run2}$).

\subsection{Conclusions}
Overall we have 3 main conclusions from this work:
1) PPI is the most sensitive, but least specific method,
2) LSS is more closely related to PPI than LSA, and
3) contrasts from events between blocks detect more results than contrasts
from interleaved events (whether there is a change or not)

\subsection{Supplemental Material}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-dualxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Dual - Single$ contrast in the real data.
      LSA has a total of 9 results, 2 overlapping with PPI,
      LSS has a total of 19 results, 4 overlapping with PPI and
      PPI has a total of 22 results.
  }
  \label{fig:data-real_type-brain_atlas-activation_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-dualxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Dual - Single$ contrast for null data.
      LSA has a total of 11 results, 2 overlapping with PPI,
      LSS has a total of 9 results, 4 overlapping with PPI,
      and PPI has a total of 20 results.
  }
  \label{fig:data-null_type-brain_atlas-activation_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-repeatxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Repeat - Single$ contrast for real data.
      LSA has a total of 21 results, 4 overlapping with PPI,
      LSS has a total of 16 results, 4 overlapping with PPI and
      PPI has a total of 25 results.
  }
  \label{fig:data-real_type-brain_atlas-activation_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the contrasts $Repeat - Single$ contrast for null data.
      LSA has a total of 10 results, 2 overlapping with PPI,
      LSS has a total of 12 results, 5 overlapping with PPI,
      and PPI has a total of 24 results.
  }
  \label{fig:data-null_type-brain_atlas-activation_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-switchxrepeat_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-activation_contrast-switchxrepeat_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the $Switch - Repeat$ contrast for real data.
      LSA has a total of 15 results, 2 overlapping with PPI,
      LSS has a total of 6 results, 1 overlapping with PPI and
      PPI has a total of 18 results.
  }
  \label{fig:data-real_type-brain_atlas-activation_contrast-switchxrepeat}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the activation atlas
      for the contrasts $Switch - Repeat$ contrast for null data.
      LSA has a total of 12 results, 1 overlapping with PPI,
      LSS has a total of 3 results, 1 overlapping with PPI,
      and PPI has a total of 13 results.
  }
  \label{fig:data-null_type-brain_atlas-activation_contrast-switchxrepeat}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Dual - Single$ contrast in the real data.
      LSA has a total of 15 results, 8 overlapping with PPI,
      LSS has a total of 20 results, 10 overlapping with PPI and
      PPI has a total of 51 results.
  }
  \label{fig:data-real_type-brain_atlas-schaeferbest_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Dual - Single$ contrast for null data.
      LSA has a total of 17 results, 3 overlapping with PPI,
      LSS has a total of 7 results, 5 overlapping with PPI,
      and PPI has a total of 26 results.
  }
  \label{fig:data-null_type-brain_atlas-schaeferbest_contrast-dualxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Repeat - Single$ contrast for real data.
      LSA has a total of 24 results, 12 overlapping with PPI,
      LSS has a total of 21 results, 10 overlapping with PPI and
      PPI has a total of 59 results.
  }
  \label{fig:data-real_type-brain_atlas-schaeferbest_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the contrasts $Repeat - Single$ contrast for null data.
      LSA has a total of 24 results, 2 overlapping with PPI,
      LSS has a total of 9 results, 4 overlapping with PPI,
      and PPI has a total of 24 results.
  }
  \label{fig:data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the $Switch - Repeat$ contrast for real data.
      LSA has a total of 8 results, 1 overlapping with PPI,
      LSS has a total of 8 results, 1 overlapping with PPI and
      PPI has a total of 13 results.
  }
  \label{fig:data-real_type-brain_atlas-schaeferbest_contrast-switchxrepeat}
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lsaxppi}}

  \subfloat{\includegraphics[width=\textwidth]{data-null_type-brain_atlas-schaeferbest_contrast-repeatxsingle_compare-lssxppi}}

  \caption{
      The statistically significant ROI-ROI pairs in the SchaeferTop20 atlas
      for the contrasts $Switch - Repeat$ contrast for null data.
      LSA has a total of 30 results, 1 overlapping with PPI,
      LSS has a total of 6 results, 1 overlapping with PPI,
      and PPI has a total of 30 results.
  }
  \label{fig:data-null_type-brain_atlas-schaeferbest_contrast-switchxrepeat}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=0.7\textwidth]{data-real_atlas-schaefer_participants-filtered_permutation_summary_ppi}}

  \subfloat{\includegraphics[width=0.7\textwidth]{data-null_atlas-schaefer_participants-filtered_permutation_summary_ppi}}

  \caption{
      The overall results for the full Schaefer Atlas.
      Since there were 79800 unique ROI-ROI pairs, it became more likely
      to see unexpected results.
      Looking at magnitudes alone, PPI has more results in the real data
      and the null data.
  }
  \label{fig:schaefer_binomial_ppi}
\end{figure}

%=============================================================================
\chapter{General Discussion}
%=============================================================================

\begin{itemize}
	\item PPI generally is more sensitive, but less specific (e.g., shows lots of postives)
	\item LSA/LSS still only choice to look at contexts in isolation (there is implicit contrast with PPI)
	\item LSA/LSS could be used to choose potential regions of interest in a data driven way (CNR)
	\item wholisitic network measures could be applied
	\item LSA/LSS could be used to further parse the difference between "task" state and "task" evoked state.
	\item Since LSS is more correlated with PPI, suggests they are measuring closer to the "same" thing
	\item Single event estimates between LSA/LSS are highly correlated
\end{itemize}
%=============================================================================
\appendix
%=============================================================================

%=============================================================================
\chapter{Appendix}

\section{Appendix One}
Should I use this?

%=============================================================================
% bibliography
%=============================================================================
\interlinepenalty=10000	% prevents bib items from splitting across pages
\bibliographystyle{uithesis}
\bibliography{thesis} 

\end{document}

% Thesis Comments
% compare relative to PPI
% split the results into two methods, here's my added value
% add on participants for correlations to lss/lsa
% beta versus PPI (AIM 2)
% why we care about connectivity,
% and why we care about task related connectivity
% 
%Meeting Notes
%Discussion to change Aim's 1 and 2 for the pragmatic purpose
%of getting a paper submitted.
%Change Aim1:
%split dataset into two halves (compare LSS and LSA)
%Change Aim2:
%split dataset into two halves (compare LSS and PPI)